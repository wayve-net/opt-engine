{
  "github_files": [
    {
      "repo": "requests/requests",
      "filename": "HISTORY.md",
      "path": "HISTORY.md",
      "content": "Release History\n===============\n\ndev\n---\n\n- \\[Short description of non-trivial change.\\]\n\n2.32.5 (2025-08-18)\n-------------------\n\n**Bugfixes**\n\n- The SSLContext caching feature originally introduced in 2.32.0 has created\n  a new class of issues in Requests that have had negative impact across a number\n  of use cases. The Requests team has decided to revert this feature as long term\n  maintenance of it is proving to be unsustainable in its current iteration.\n\n**Deprecations**\n- Added support for Python 3.14.\n- Dropped support for Python 3.8 following its end of support.\n\n2.32.4 (2025-06-10)\n-------------------\n\n**Security**\n- CVE-2024-47081 Fixed an issue where a maliciously crafted URL and trusted\n  environment will retrieve credentials for the wrong hostname/machine from a\n  netrc file.\n\n**Improvements**\n- Numerous documentation improvements\n\n**Deprecations**\n- Added support for pypy 3.11 for Linux and macOS.\n- Dropped support for pypy 3.9 following its end of support.\n\n\n2.32.3 (2024-05-29)\n-------------------\n\n**Bugfixes**\n- Fixed bug breaking the ability to specify custom SSLContexts in sub-classes of\n  HTTPAdapter. (#6716)\n- Fixed issue where Requests started failing to run on Python versions compiled\n  without the `ssl` module. (#6724)\n\n2.32.2 (2024-05-21)\n-------------------\n\n**Deprecations**\n- To provide a more stable migration for custom HTTPAdapters impacted\n  by the CVE changes in 2.32.0, we've renamed `_get_connection` to\n  a new public API, `get_connection_with_tls_context`. Existing custom\n  HTTPAdapters will need to migrate their code to use this new API.\n  `get_connection` is considered deprecated in all versions of Requests>=2.32.0.\n\n  A minimal (2-line) example has been provided in the linked PR to ease\n  migration, but we strongly urge users to evaluate if their custom adapter\n  is subject to the same issue described in CVE-2024-35195. (#6710)\n\n2.32.1 (2024-05-20)\n-------------------\n\n**Bugfixes**\n- Add missing test certs to the sdist distributed on PyPI.\n\n\n2.32.0 (2024-05-20)\n-------------------\n\n**Security**\n- Fixed an issue where setting `verify=False` on the first request from a\n  Session will cause subsequent requests to the _same origin_ to also ignore\n  cert verification, regardless of the value of `verify`.\n  (https://github.com/psf/requests/security/advisories/GHSA-9wx4-h78v-vm56)\n\n**Improvements**\n- `verify=True` now reuses a global SSLContext which should improve\n  request time variance between first and subsequent requests. It should\n  also minimize certificate load time on Windows systems when using a Python\n  version built with OpenSSL 3.x. (#6667)\n- Requests now supports optional use of character detection\n  (`chardet` or `charset_normalizer`) when repackaged or vendored.\n  This enables `pip` and other projects to minimize their vendoring\n  surface area. The `Response.text()` and `apparent_encoding` APIs\n  will default to `utf-8` if neither library is present. (#6702)\n\n**Bugfixes**\n- Fixed bug in length detection where emoji length was incorrectly\n  calculated in the request content-length. (#6589)\n- Fixed deserialization bug in JSONDecodeError. (#6629)\n- Fixed bug where an extra leading `/` (path separator) could lead\n  urllib3 to unnecessarily reparse the request URI. (#6644)\n\n**Deprecations**\n\n- Requests has officially added support for CPython 3.12 (#6503)\n- Requests has officially added support for PyPy 3.9 and 3.10 (#6641)\n- Requests has officially dropped support for CPython 3.7 (#6642)\n- Requests has officially dropped support for PyPy 3.7 and 3.8 (#6641)\n\n**Documentation**\n- Various typo fixes and doc improvements.\n\n**Packaging**\n- Requests has started adopting some modern packaging practices.\n  The source files for the projects (formerly `requests`) is now located\n  in `src/requests` in the Requests sdist. (#6506)\n- Starting in Requests 2.33.0, Requests will migrate to a PEP 517 build system\n  using `hatchling`. This should not impact the average user, but extremely old\n  versions of packaging utilities may have issues with the new packaging format.\n\n\n2.31.0 (2023-05-22)\n-------------------\n\n**Security**\n- Versions of Requests between v2.3.0 and v2.30.0 are vulnerable to potential\n  forwarding of `Proxy-Authorization` headers to destination servers when\n  following HTTPS redirects.\n\n  When proxies are defined with user info (`https://user:pass@proxy:8080`), Requests\n  will construct a `Proxy-Authorization` header that is attached to the request to\n  authenticate with the proxy.\n\n  In cases where Requests receives a redirect response, it previously reattached\n  the `Proxy-Authorization` header incorrectly, resulting in the value being\n  sent through the tunneled connection to the destination server. Users who rely on\n  defining their proxy credentials in the URL are *strongly* encouraged to upgrade\n  to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy\n  credentials once the change has been fully deployed.\n\n  Users who do not use a proxy or do not supply their proxy credentials through\n  the user information portion of their proxy URL are not subject to this\n  vulnerability.\n\n  Full details can be read in our [Github Security Advisory](https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q)\n  and [CVE-2023-32681](https://nvd.nist.gov/vuln/detail/CVE-2023-32681).\n\n\n2.30.0 (2023-05-03)\n-------------------\n\n**Dependencies**\n- \u26a0\ufe0f Added support for urllib3 2.0. \u26a0\ufe0f\n\n  This may contain minor breaking changes so we advise careful testing and\n  reviewing https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html\n  prior to upgrading.\n\n  Users who wish to stay on urllib3 1.x can pin to `urllib3<2`.\n\n2.29.0 (2023-04-26)\n-------------------\n\n**Improvements**\n\n- Requests now defers chunked requests to the urllib3 implementation to improve\n  standardization. (#6226)\n- Requests relaxes header component requirements to support bytes/str subclasses. (#6356)\n\n2.28.2 (2023-01-12)\n-------------------\n\n**Dependencies**\n\n- Requests now supports charset\\_normalizer 3.x. (#6261)\n\n**Bugfixes**\n\n- Updated MissingSchema exception to suggest https scheme rather than http. (#6188)\n\n2.28.1 (2022-06-29)\n-------------------\n\n**Improvements**\n\n- Speed optimization in `iter_content` with transition to `yield from`. (#6170)\n\n**Dependencies**\n\n- Added support for chardet 5.0.0 (#6179)\n- Added support for charset-normalizer 2.1.0 (#6169)\n\n2.28.0 (2022-06-09)\n-------------------\n\n**Deprecations**\n\n- \u26a0\ufe0f Requests has officially dropped support for Python 2.7. \u26a0\ufe0f (#6091)\n- Requests has officially dropped support for Python 3.6 (including pypy3.6). (#6091)\n\n**Improvements**\n\n- Wrap JSON parsing issues in Request's JSONDecodeError for payloads without\n  an encoding to make `json()` API consistent. (#6097)\n- Parse header components consistently, raising an InvalidHeader error in\n  all invalid cases. (#6154)\n- Added provisional 3.11 support with current beta build. (#6155)\n- Requests got a makeover and we decided to paint it black. (#6095)\n\n**Bugfixes**\n\n- Fixed bug where setting `CURL_CA_BUNDLE` to an empty string would disable\n  cert verification. All Requests 2.x versions before 2.28.0 are affected. (#6074)\n- Fixed urllib3 exception leak, wrapping `urllib3.exceptions.SSLError` with\n  `requests.exceptions.SSLError` for `content` and `iter_content`. (#6057)\n- Fixed issue where invalid Windows registry entries caused proxy resolution\n  to raise an exception rather than ignoring the entry. (#6149)\n- Fixed issue where entire payload could be included in the error message for\n  JSONDecodeError. (#6036)\n\n2.27.1 (2022-01-05)\n-------------------\n\n**Bugfixes**\n\n- Fixed parsing issue that resulted in the `auth` component being\n  dropped from proxy URLs. (#6028)\n\n2.27.0 (2022-01-03)\n-------------------\n\n**Improvements**\n\n- Officially added support for Python 3.10. (#5928)\n\n- Added a `requests.exceptions.JSONDecodeError` to unify JSON exceptions between\n  Python 2 and 3. This gets raised in the `response.json()` method, and is\n  backwards compatible as it inherits from previously thrown exceptions.\n  Can be caught from `requests.exceptions.RequestException` as well. (#5856)\n\n- Improved error text for misnamed `InvalidSchema` and `MissingSchema`\n  exceptions. This is a temporary fix until exceptions can be renamed\n  (Schema->Scheme). (#6017)\n\n- Improved proxy parsing for proxy URLs missing a scheme. This will address\n  recent changes to `urlparse` in Python 3.9+. (#5917)\n\n**Bugfixes**\n\n- Fixed defect in `extract_zipped_paths` which could result in an infinite loop\n  for some paths. (#5851)\n\n- Fixed handling for `AttributeError` when calculating length of files obtained\n  by `Tarfile.extractfile()`. (#5239)\n\n- Fixed urllib3 exception leak, wrapping `urllib3.exceptions.InvalidHeader` with\n  `requests.exceptions.InvalidHeader`. (#5914)\n\n- Fixed bug where two Host headers were sent for chunked requests. (#5391)\n\n- Fixed regression in Requests 2.26.0 where `Proxy-Authorization` was\n  incorrectly stripped from all requests sent with `Session.send`. (#5924)\n\n- Fixed performance regression in 2.26.0 for hosts with a large number of\n  proxies available in the environment. (#5924)\n\n- Fixed idna exception leak, wrapping `UnicodeError` with\n  `requests.exceptions.InvalidURL` for URLs with a leading dot (.) in the\n  domain. (#5414)\n\n**Deprecations**\n\n- Requests support for Python 2.7 and 3.6 will be ending in 2022. While we\n  don't have exact dates, Requests 2.27.x is likely to be the last release\n  series providing support.\n\n2.26.0 (2021-07-13)\n-------------------\n\n**Improvements**\n\n- Requests now supports Brotli compression, if either the `brotli` or\n  `brotlicffi` package is installed. (#5783)\n\n- `Session.send` now correctly resolves proxy configurations from both\n  the Session and Request. Behavior now matches `Session.request`. (#5681)\n\n**Bugfixes**\n\n- Fixed a race condition in zip extraction when using Requests in parallel\n  from zip archive. (#5707)\n\n**Dependencies**\n\n- Instead of `chardet`, use the MIT-licensed `charset_normalizer` for Python3\n  to remove license ambiguity for projects bundling requests. If `chardet`\n  is already installed on your machine it will be used instead of `charset_normalizer`\n  to keep backwards compatibility. (#5797)\n\n  You can also install `chardet` while installing requests by\n  specifying `[use_chardet_on_py3]` extra as follows:\n\n    ```shell\n    pip install \"requests[use_chardet_on_py3]\"\n    ```\n\n  Python2 still depends upon the `chardet` module.\n\n- Requests now supports `idna` 3.x on Python 3. `idna` 2.x will continue to\n  be used on Python 2 installations. (#5711)\n\n**Deprecations**\n\n- The `requests[security]` extra has been converted to a no-op install.\n  PyOpenSSL is no longer the recommended secure option for Requests. (#5867)\n\n- Requests has officially dropped support for Python 3.5. (#5867)\n\n2.25.1 (2020-12-16)\n-------------------\n\n**Bugfixes**\n\n- Requests now treats `application/json` as `utf8` by default. Resolving\n  inconsistencies between `r.text` and `r.json` output. (#5673)\n\n**Dependencies**\n\n- Requests now supports chardet v4.x.\n\n2.25.0 (2020-11-11)\n-------------------\n\n**Improvements**\n\n- Added support for NETRC environment variable. (#5643)\n\n**Dependencies**\n\n- Requests now supports urllib3 v1.26.\n\n**Deprecations**\n\n- Requests v2.25.x will be the last release series with support for Python 3.5.\n- The `requests[security]` extra is officially deprecated and will be removed\n  in Requests v2.26.0.\n\n2.24.0 (2020-06-17)\n-------------------\n\n**Improvements**\n\n- pyOpenSSL TLS implementation is now only used if Python\n  either doesn't have an `ssl` module or doesn't support\n  SNI. Previously pyOpenSSL was unconditionally used if available.\n  This applies even if pyOpenSSL is installed via the\n  `requests[security]` extra (#5443)\n\n- Redirect resolution should now only occur when\n  `allow_redirects` is True. (#5492)\n\n- No longer perform unnecessary Content-Length calculation for\n  requests that won't use it. (#5496)\n\n2.23.0 (2020-02-19)\n-------------------\n\n**Improvements**\n\n- Remove defunct reference to `prefetch` in Session `__attrs__` (#5110)\n\n**Bugfixes**\n\n- Requests no longer outputs password in basic auth usage warning. (#5099)\n\n**Dependencies**\n\n- Pinning for `chardet` and `idna` now uses major version instead of minor.\n  This hopefully reduces the need for releases every time a dependency is updated.\n\n2.22.0 (2019-05-15)\n-------------------\n\n**Dependencies**\n\n- Requests now supports urllib3 v1.25.2.\n  (note: 1.25.0 and 1.25.1 are incompatible)\n\n**Deprecations**\n\n- Requests has officially stopped support for Python 3.4.\n\n2.21.0 (2018-12-10)\n-------------------\n\n**Dependencies**\n\n- Requests now supports idna v2.8.\n\n2.20.1 (2018-11-08)\n-------------------\n\n**Bugfixes**\n\n- Fixed bug with unintended Authorization header stripping for\n  redirects using default ports (http/80, https/443).\n\n2.20.0 (2018-10-18)\n-------------------\n\n**Bugfixes**\n\n-   Content-Type header parsing is now case-insensitive (e.g.\n    charset=utf8 v Charset=utf8).\n-   Fixed exception leak where certain redirect urls would raise\n    uncaught urllib3 exceptions.\n-   Requests removes Authorization header from requests redirected\n    from https to http on the same hostname. (CVE-2018-18074)\n-   `should_bypass_proxies` now handles URIs without hostnames (e.g.\n    files).\n\n**Dependencies**\n\n- Requests now supports urllib3 v1.24.\n\n**Deprecations**\n\n- Requests has officially stopped support for Python 2.6.\n\n2.19.1 (2018-06-14)\n-------------------\n\n**Bugfixes**\n\n-   Fixed issue where status\\_codes.py's `init` function failed trying\n    to append to a `__doc__` value of `None`.\n\n2.19.0 (2018-06-12)\n-------------------\n\n**Improvements**\n\n-   Warn user about possible slowdown when using cryptography version\n    &lt; 1.3.4\n-   Check for invalid host in proxy URL, before forwarding request to\n    adapter.\n-   Fragments are now properly maintained across redirects. (RFC7231\n    7.1.2)\n-   Removed use of cgi module to expedite library load time.\n-   Added support for SHA-256 and SHA-512 digest auth algorithms.\n-   Minor performance improvement to `Request.content`.\n-   Migrate to using collections.abc for 3.7 compatibility.\n\n**Bugfixes**\n\n-   Parsing empty `Link` headers with `parse_header_links()` no longer\n    return one bogus entry.\n-   Fixed issue where loading the default certificate bundle from a zip\n    archive would raise an `IOError`.\n-   Fixed issue with unexpected `ImportError` on windows system which do\n    not support `winreg` module.\n-   DNS resolution in proxy bypass no longer includes the username and\n    password in the request. This also fixes the issue of DNS queries\n    failing on macOS.\n-   Properly normalize adapter prefixes for url comparison.\n-   Passing `None` as a file pointer to the `files` param no longer\n    raises an exception.\n-   Calling `copy` on a `RequestsCookieJar` will now preserve the cookie\n    policy correctly.\n\n**Dependencies**\n\n-   We now support idna v2.7.\n-   We now support urllib3 v1.23.\n\n2.18.4 (2017-08-15)\n-------------------\n\n**Improvements**\n\n-   Error messages for invalid headers now include the header name for\n    easier debugging\n\n**Dependencies**\n\n-   We now support idna v2.6.\n\n2.18.3 (2017-08-02)\n-------------------\n\n**Improvements**\n\n-   Running `$ python -m requests.help` now includes the installed\n    version of idna.\n\n**Bugfixes**\n\n-   Fixed issue where Requests would raise `ConnectionError` instead of\n    `SSLError` when encountering SSL problems when using urllib3 v1.22.\n\n2.18.2 (2017-07-25)\n-------------------\n\n**Bugfixes**\n\n-   `requests.help` no longer fails on Python 2.6 due to the absence of\n    `ssl.OPENSSL_VERSION_NUMBER`.\n\n**Dependencies**\n\n-   We now support urllib3 v1.22.\n\n2.18.1 (2017-06-14)\n-------------------\n\n**Bugfixes**\n\n-   Fix an error in the packaging whereby the `*.whl` contained\n    incorrect data that regressed the fix in v2.17.3.\n\n2.18.0 (2017-06-14)\n-------------------\n\n**Improvements**\n\n-   `Response` is now a context manager, so can be used directly in a\n    `with` statement without first having to be wrapped by\n    `contextlib.closing()`.\n\n**Bugfixes**\n\n-   Resolve installation failure if multiprocessing is not available\n-   Resolve tests crash if multiprocessing is not able to determine the\n    number of CPU cores\n-   Resolve error swallowing in utils set\\_environ generator\n\n2.17.3 (2017-05-29)\n-------------------\n\n**Improvements**\n\n-   Improved `packages` namespace identity support, for monkeypatching\n    libraries.\n\n2.17.2 (2017-05-29)\n-------------------\n\n**Improvements**\n\n-   Improved `packages` namespace identity support, for monkeypatching\n    libraries.\n\n2.17.1 (2017-05-29)\n-------------------\n\n**Improvements**\n\n-   Improved `packages` namespace identity support, for monkeypatching\n    libraries.\n\n2.17.0 (2017-05-29)\n-------------------\n\n**Improvements**\n\n-   Removal of the 301 redirect cache. This improves thread-safety.\n\n2.16.5 (2017-05-28)\n-------------------\n\n-   Improvements to `$ python -m requests.help`.\n\n2.16.4 (2017-05-27)\n-------------------\n\n-   Introduction of the `$ python -m requests.help` command, for\n    debugging with maintainers!\n\n2.16.3 (2017-05-27)\n-------------------\n\n-   Further restored the `requests.packages` namespace for compatibility\n    reasons.\n\n2.16.2 (2017-05-27)\n-------------------\n\n-   Further restored the `requests.packages` namespace for compatibility\n    reasons.\n\nNo code modification (noted below) should be necessary any longer.\n\n2.16.1 (2017-05-27)\n-------------------\n\n-   Restored the `requests.packages` namespace for compatibility\n    reasons.\n-   Bugfix for `urllib3` version parsing.\n\n**Note**: code that was written to import against the\n`requests.packages` namespace previously will have to import code that\nrests at this module-level now.\n\nFor example:\n\n    from requests.packages.urllib3.poolmanager import PoolManager\n\nWill need to be re-written to be:\n\n    from requests.packages import urllib3\n    urllib3.poolmanager.PoolManager\n\nOr, even better:\n\n    from urllib3.poolmanager import PoolManager\n\n2.16.0 (2017-05-26)\n-------------------\n\n-   Unvendor ALL the things!\n\n2.15.1 (2017-05-26)\n-------------------\n\n-   Everyone makes mistakes.\n\n2.15.0 (2017-05-26)\n-------------------\n\n**Improvements**\n\n-   Introduction of the `Response.next` property, for getting the next\n    `PreparedResponse` from a redirect chain (when\n    `allow_redirects=False`).\n-   Internal refactoring of `__version__` module.\n\n**Bugfixes**\n\n-   Restored once-optional parameter for\n    `requests.utils.get_environ_proxies()`.\n\n2.14.2 (2017-05-10)\n-------------------\n\n**Bugfixes**\n\n-   Changed a less-than to an equal-to and an or in the dependency\n    markers to widen compatibility with older setuptools releases.\n\n2.14.1 (2017-05-09)\n-------------------\n\n**Bugfixes**\n\n-   Changed the dependency markers to widen compatibility with older pip\n    releases.\n\n2.14.0 (2017-05-09)\n-------------------\n\n**Improvements**\n\n-   It is now possible to pass `no_proxy` as a key to the `proxies`\n    dictionary to provide handling similar to the `NO_PROXY` environment\n    variable.\n-   When users provide invalid paths to certificate bundle files or\n    directories Requests now raises `IOError`, rather than failing at\n    the time of the HTTPS request with a fairly inscrutable certificate\n    validation error.\n-   The behavior of `SessionRedirectMixin` was slightly altered.\n    `resolve_redirects` will now detect a redirect by calling\n    `get_redirect_target(response)` instead of directly querying\n    `Response.is_redirect` and `Response.headers['location']`. Advanced\n    users will be able to process malformed redirects more easily.\n-   Changed the internal calculation of elapsed request time to have\n    higher resolution on Windows.\n-   Added `win_inet_pton` as conditional dependency for the `[socks]`\n    extra on Windows with Python 2.7.\n-   Changed the proxy bypass implementation on Windows: the proxy bypass\n    check doesn't use forward and reverse DNS requests anymore\n-   URLs with schemes that begin with `http` but are not `http` or\n    `https` no longer have their host parts forced to lowercase.\n\n**Bugfixes**\n\n-   Much improved handling of non-ASCII `Location` header values in\n    redirects. Fewer `UnicodeDecodeErrors` are encountered on Python 2,\n    and Python 3 now correctly understands that Latin-1 is unlikely to\n    be the correct encoding.\n-   If an attempt to `seek` file to find out its length fails, we now\n    appropriately handle that by aborting our content-length\n    calculations.\n-   Restricted `HTTPDigestAuth` to only respond to auth challenges made\n    on 4XX responses, rather than to all auth challenges.\n-   Fixed some code that was firing `DeprecationWarning` on Python 3.6.\n-   The dismayed person emoticon (`/o\\\\`) no longer has a big head. I'm\n    sure this is what you were all worrying about most.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to v1.21.1.\n-   Updated bundled chardet to v3.0.2.\n-   Updated bundled idna to v2.5.\n-   Updated bundled certifi to 2017.4.17.\n\n2.13.0 (2017-01-24)\n-------------------\n\n**Features**\n\n-   Only load the `idna` library when we've determined we need it. This\n    will save some memory for users.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.20.\n-   Updated bundled idna to 2.2.\n\n2.12.5 (2017-01-18)\n-------------------\n\n**Bugfixes**\n\n-   Fixed an issue with JSON encoding detection, specifically detecting\n    big-endian UTF-32 with BOM.\n\n2.12.4 (2016-12-14)\n-------------------\n\n**Bugfixes**\n\n-   Fixed regression from 2.12.2 where non-string types were rejected in\n    the basic auth parameters. While support for this behaviour has been\n    re-added, the behaviour is deprecated and will be removed in the\n    future.\n\n2.12.3 (2016-12-01)\n-------------------\n\n**Bugfixes**\n\n-   Fixed regression from v2.12.1 for URLs with schemes that begin with\n    \"http\". These URLs have historically been processed as though they\n    were HTTP-schemed URLs, and so have had parameters added. This was\n    removed in v2.12.2 in an overzealous attempt to resolve problems\n    with IDNA-encoding those URLs. This change was reverted: the other\n    fixes for IDNA-encoding have been judged to be sufficient to return\n    to the behaviour Requests had before v2.12.0.\n\n2.12.2 (2016-11-30)\n-------------------\n\n**Bugfixes**\n\n-   Fixed several issues with IDNA-encoding URLs that are technically\n    invalid but which are widely accepted. Requests will now attempt to\n    IDNA-encode a URL if it can but, if it fails, and the host contains\n    only ASCII characters, it will be passed through optimistically.\n    This will allow users to opt-in to using IDNA2003 themselves if they\n    want to, and will also allow technically invalid but still common\n    hostnames.\n-   Fixed an issue where URLs with leading whitespace would raise\n    `InvalidSchema` errors.\n-   Fixed an issue where some URLs without the HTTP or HTTPS schemes\n    would still have HTTP URL preparation applied to them.\n-   Fixed an issue where Unicode strings could not be used in basic\n    auth.\n-   Fixed an issue encountered by some Requests plugins where\n    constructing a Response object would cause `Response.content` to\n    raise an `AttributeError`.\n\n2.12.1 (2016-11-16)\n-------------------\n\n**Bugfixes**\n\n-   Updated setuptools 'security' extra for the new PyOpenSSL backend in\n    urllib3.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.19.1.\n\n2.12.0 (2016-11-15)\n-------------------\n\n**Improvements**\n\n-   Updated support for internationalized domain names from IDNA2003 to\n    IDNA2008. This updated support is required for several forms of IDNs\n    and is mandatory for .de domains.\n-   Much improved heuristics for guessing content lengths: Requests will\n    no longer read an entire `StringIO` into memory.\n-   Much improved logic for recalculating `Content-Length` headers for\n    `PreparedRequest` objects.\n-   Improved tolerance for file-like objects that have no `tell` method\n    but do have a `seek` method.\n-   Anything that is a subclass of `Mapping` is now treated like a\n    dictionary by the `data=` keyword argument.\n-   Requests now tolerates empty passwords in proxy credentials, rather\n    than stripping the credentials.\n-   If a request is made with a file-like object as the body and that\n    request is redirected with a 307 or 308 status code, Requests will\n    now attempt to rewind the body object so it can be replayed.\n\n**Bugfixes**\n\n-   When calling `response.close`, the call to `close` will be\n    propagated through to non-urllib3 backends.\n-   Fixed issue where the `ALL_PROXY` environment variable would be\n    preferred over scheme-specific variables like `HTTP_PROXY`.\n-   Fixed issue where non-UTF8 reason phrases got severely mangled by\n    falling back to decoding using ISO 8859-1 instead.\n-   Fixed a bug where Requests would not correctly correlate cookies set\n    when using custom Host headers if those Host headers did not use the\n    native string type for the platform.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.19.\n-   Updated bundled certifi certs to 2016.09.26.\n\n2.11.1 (2016-08-17)\n-------------------\n\n**Bugfixes**\n\n-   Fixed a bug when using `iter_content` with `decode_unicode=True` for\n    streamed bodies would raise `AttributeError`. This bug was\n    introduced in 2.11.\n-   Strip Content-Type and Transfer-Encoding headers from the header\n    block when following a redirect that transforms the verb from\n    POST/PUT to GET.\n\n2.11.0 (2016-08-08)\n-------------------\n\n**Improvements**\n\n-   Added support for the `ALL_PROXY` environment variable.\n-   Reject header values that contain leading whitespace or newline\n    characters to reduce risk of header smuggling.\n\n**Bugfixes**\n\n-   Fixed occasional `TypeError` when attempting to decode a JSON\n    response that occurred in an error case. Now correctly returns a\n    `ValueError`.\n-   Requests would incorrectly ignore a non-CIDR IP address in the\n    `NO_PROXY` environment variables: Requests now treats it as a\n    specific IP.\n-   Fixed a bug when sending JSON data that could cause us to encounter\n    obscure OpenSSL errors in certain network conditions (yes, really).\n-   Added type checks to ensure that `iter_content` only accepts\n    integers and `None` for chunk sizes.\n-   Fixed issue where responses whose body had not been fully consumed\n    would have the underlying connection closed but not returned to the\n    connection pool, which could cause Requests to hang in situations\n    where the `HTTPAdapter` had been configured to use a blocking\n    connection pool.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.16.\n-   Some previous releases accidentally accepted non-strings as\n    acceptable header values. This release does not.\n\n2.10.0 (2016-04-29)\n-------------------\n\n**New Features**\n\n-   SOCKS Proxy Support! (requires PySocks;\n    `$ pip install requests[socks]`)\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.15.1.\n\n2.9.2 (2016-04-29)\n------------------\n\n**Improvements**\n\n-   Change built-in CaseInsensitiveDict (used for headers) to use\n    OrderedDict as its underlying datastore.\n\n**Bugfixes**\n\n-   Don't use redirect\\_cache if allow\\_redirects=False\n-   When passed objects that throw exceptions from `tell()`, send them\n    via chunked transfer encoding instead of failing.\n-   Raise a ProxyError for proxy related connection issues.\n\n2.9.1 (2015-12-21)\n------------------\n\n**Bugfixes**\n\n-   Resolve regression introduced in 2.9.0 that made it impossible to\n    send binary strings as bodies in Python 3.\n-   Fixed errors when calculating cookie expiration dates in certain\n    locales.\n\n**Miscellaneous**\n\n-   Updated bundled urllib3 to 1.13.1.\n\n2.9.0 (2015-12-15)\n------------------\n\n**Minor Improvements** (Backwards compatible)\n\n-   The `verify` keyword argument now supports being passed a path to a\n    directory of CA certificates, not just a single-file bundle.\n-   Warnings are now emitted when sending files opened in text mode.\n-   Added the 511 Network Authentication Required status code to the\n    status code registry.\n\n**Bugfixes**\n\n-   For file-like objects that are not sought to the very beginning, we\n    now send the content length for the number of bytes we will actually\n    read, rather than the total size of the file, allowing partial file\n    uploads.\n-   When uploading file-like objects, if they are empty or have no\n    obvious content length we set `Transfer-Encoding: chunked` rather\n    than `Content-Length: 0`.\n-   We correctly receive the response in buffered mode when uploading\n    chunked bodies.\n-   We now handle being passed a query string as a bytestring on Python\n    3, by decoding it as UTF-8.\n-   Sessions are now closed in all cases (exceptional and not) when\n    using the functional API rather than leaking and waiting for the\n    garbage collector to clean them up.\n-   Correctly handle digest auth headers with a malformed `qop`\n    directive that contains no token, by treating it the same as if no\n    `qop` directive was provided at all.\n-   Minor performance improvements when removing specific cookies by\n    name.\n\n**Miscellaneous**\n\n-   Updated urllib3 to 1.13.\n\n2.8.1 (2015-10-13)\n------------------\n\n**Bugfixes**\n\n-   Update certificate bundle to match `certifi` 2015.9.6.2's weak\n    certificate bundle.\n-   Fix a bug in 2.8.0 where requests would raise `ConnectTimeout`\n    instead of `ConnectionError`\n-   When using the PreparedRequest flow, requests will now correctly\n    respect the `json` parameter. Broken in 2.8.0.\n-   When using the PreparedRequest flow, requests will now correctly\n    handle a Unicode-string method name on Python 2. Broken in 2.8.0.\n\n2.8.0 (2015-10-05)\n------------------\n\n**Minor Improvements** (Backwards Compatible)\n\n-   Requests now supports per-host proxies. This allows the `proxies`\n    dictionary to have entries of the form\n    `{'<scheme>://<hostname>': '<proxy>'}`. Host-specific proxies will\n    be used in preference to the previously-supported scheme-specific\n    ones, but the previous syntax will continue to work.\n-   `Response.raise_for_status` now prints the URL that failed as part\n    of the exception message.\n-   `requests.utils.get_netrc_auth` now takes an `raise_errors` kwarg,\n    defaulting to `False`. When `True`, errors parsing `.netrc` files\n    cause exceptions to be thrown.\n-   Change to bundled projects import logic to make it easier to\n    unbundle requests downstream.\n-   Changed the default User-Agent string to avoid leaking data on\n    Linux: now contains only the requests version.\n\n**Bugfixes**\n\n-   The `json` parameter to `post()` and friends will now only be used\n    if neither `data` nor `files` are present, consistent with the\n    documentation.\n-   We now ignore empty fields in the `NO_PROXY` environment variable.\n-   Fixed problem where `httplib.BadStatusLine` would get raised if\n    combining `stream=True` with `contextlib.closing`.\n-   Prevented bugs where we would attempt to return the same connection\n    back to the connection pool twice when sending a Chunked body.\n-   Miscellaneous minor internal changes.\n-   Digest Auth support is now thread safe.\n\n**Updates**\n\n-   Updated urllib3 to 1.12.\n\n2.7.0 (2015-05-03)\n------------------\n\nThis is the first release that follows our new release process. For\nmore, see [our\ndocumentation](https://requests.readthedocs.io/en/latest/community/release-process/).\n\n**Bugfixes**\n\n-   Updated urllib3 to 1.10.4, resolving several bugs involving chunked\n    transfer encoding and response framing.\n\n2.6.2 (2015-04-23)\n------------------\n\n**Bugfixes**\n\n-   Fix regression where compressed data that was sent as chunked data\n    was not properly decompressed. (\\#2561)\n\n2.6.1 (2015-04-22)\n------------------\n\n**Bugfixes**\n\n-   Remove VendorAlias import machinery introduced in v2.5.2.\n-   Simplify the PreparedRequest.prepare API: We no longer require the\n    user to pass an empty list to the hooks keyword argument. (c.f.\n    \\#2552)\n-   Resolve redirects now receives and forwards all of the original\n    arguments to the adapter. (\\#2503)\n-   Handle UnicodeDecodeErrors when trying to deal with a unicode URL\n    that cannot be encoded in ASCII. (\\#2540)\n-   Populate the parsed path of the URI field when performing Digest\n    Authentication. (\\#2426)\n-   Copy a PreparedRequest's CookieJar more reliably when it is not an\n    instance of RequestsCookieJar. (\\#2527)\n\n2.6.0 (2015-03-14)\n------------------\n\n**Bugfixes**\n\n-   CVE-2015-2296: Fix handling of cookies on redirect. Previously a\n    cookie without a host value set would use the hostname for the\n    redirected URL exposing requests users to session fixation attacks\n    and potentially cookie stealing. This was disclosed privately by\n    Matthew Daley of [BugFuzz](https://bugfuzz.com). This affects all\n    versions of requests from v2.1.0 to v2.5.3 (inclusive on both ends).\n-   Fix error when requests is an `install_requires` dependency and\n    `python setup.py test` is run. (\\#2462)\n-   Fix error when urllib3 is unbundled and requests continues to use\n    the vendored import location.\n-   Include fixes to `urllib3`'s header handling.\n-   Requests' handling of unvendored dependencies is now more\n    restrictive.\n\n**Features and Improvements**\n\n-   Support bytearrays when passed as parameters in the `files`\n    argument. (\\#2468)\n-   Avoid data duplication when creating a request with `str`, `bytes`,\n    or `bytearray` input to the `files` argument.\n\n2.5.3 (2015-02-24)\n------------------\n\n**Bugfixes**\n\n-   Revert changes to our vendored certificate bundle. For more context\n    see (\\#2455, \\#2456, and <https://bugs.python.org/issue23476>)\n\n2.5.2 (2015-02-23)\n------------------\n\n**Features and Improvements**\n\n-   Add sha256 fingerprint support.\n    ([shazow/urllib3\\#540](https://github.com/shazow/urllib3/pull/540))\n-   Improve the performance of headers.\n    ([shazow/urllib3\\#544](https://github.com/shazow/urllib3/pull/544))\n\n**Bugfixes**\n\n-   Copy pip's import machinery. When downstream redistributors remove\n    requests.packages.urllib3 the import machinery will continue to let\n    those same symbols work. Example usage in requests' documentation\n    and 3rd-party libraries relying on the vendored copies of urllib3\n    will work without having to fallback to the system urllib3.\n-   Attempt to quote parts of the URL on redirect if unquoting and then\n    quoting fails. (\\#2356)\n-   Fix filename type check for multipart form-data uploads. (\\#2411)\n-   Properly handle the case where a server issuing digest\n    authentication challenges provides both auth and auth-int\n    qop-values. (\\#2408)\n-   Fix a socket leak.\n    ([shazow/urllib3\\#549](https://github.com/shazow/urllib3/pull/549))\n-   Fix multiple `Set-Cookie` headers properly.\n    ([shazow/urllib3\\#534](https://github.com/shazow/urllib3/pull/534))\n-   Disable the built-in hostname verification.\n    ([shazow/urllib3\\#526](https://github.com/shazow/urllib3/pull/526))\n-   Fix the behaviour of decoding an exhausted stream.\n    ([shazow/urllib3\\#535](https://github.com/shazow/urllib3/pull/535))\n\n**Security**\n\n-   Pulled in an updated `cacert.pem`.\n-   Drop RC4 from the default cipher list.\n    ([shazow/urllib3\\#551](https://github.com/shazow/urllib3/pull/551))\n\n2.5.1 (2014-12-23)\n------------------\n\n**Behavioural Changes**\n\n-   Only catch HTTPErrors in raise\\_for\\_status (\\#2382)\n\n**Bugfixes**\n\n-   Handle LocationParseError from urllib3 (\\#2344)\n-   Handle file-like object filenames that are not strings (\\#2379)\n-   Unbreak HTTPDigestAuth handler. Allow new nonces to be negotiated\n    (\\#2389)\n\n2.5.0 (2014-12-01)\n------------------\n\n**Improvements**\n\n-   Allow usage of urllib3's Retry object with HTTPAdapters (\\#2216)\n-   The `iter_lines` method on a response now accepts a delimiter with\n    which to split the content (\\#2295)\n\n**Behavioural Changes**\n\n-   Add deprecation warnings to functions in requests.utils that will be\n    removed in 3.0 (\\#2309)\n-   Sessions used by the functional API are always closed (\\#2326)\n-   Restrict requests to HTTP/1.1 and HTTP/1.0 (stop accepting HTTP/0.9)\n    (\\#2323)\n\n**Bugfixes**\n\n-   Only parse the URL once (\\#2353)\n-   Allow Content-Length header to always be overridden (\\#2332)\n-   Properly handle files in HTTPDigestAuth (\\#2333)\n-   Cap redirect\\_cache size to prevent memory abuse (\\#2299)\n-   Fix HTTPDigestAuth handling of redirects after authenticating\n    successfully (\\#2253)\n-   Fix crash with custom method parameter to Session.request (\\#2317)\n-   Fix how Link headers are parsed using the regular expression library\n    (\\#2271)\n\n**Documentation**\n\n-   Add more references for interlinking (\\#2348)\n-   Update CSS for theme (\\#2290)\n-   Update width of buttons and sidebar (\\#2289)\n-   Replace references of Gittip with Gratipay (\\#2282)\n-   Add link to changelog in sidebar (\\#2273)\n\n2.4.3 (2014-10-06)\n------------------\n\n**Bugfixes**\n\n-   Unicode URL improvements for Python 2.\n-   Re-order JSON param for backwards compat.\n-   Automatically defrag authentication schemes from host/pass URIs.\n    ([\\#2249](https://github.com/psf/requests/issues/2249))\n\n2.4.2 (2014-10-05)\n------------------\n\n**Improvements**\n\n-   FINALLY! Add json parameter for uploads!\n    ([\\#2258](https://github.com/psf/requests/pull/2258))\n-   Support for bytestring URLs on Python 3.x\n    ([\\#2238](https://github.com/psf/requests/pull/2238))\n\n**Bugfixes**\n\n-   Avoid getting stuck in a loop\n    ([\\#2244](https://github.com/psf/requests/pull/2244))\n-   Multiple calls to iter\\* fail with unhelpful error.\n    ([\\#2240](https://github.com/psf/requests/issues/2240),\n    [\\#2241](https://github.com/psf/requests/issues/2241))\n\n**Documentation**\n\n-   Correct redirection introduction\n    ([\\#2245](https://github.com/psf/requests/pull/2245/))\n-   Added example of how to send multiple files in one request.\n    ([\\#2227](https://github.com/psf/requests/pull/2227/))\n-   Clarify how to pass a custom set of CAs\n    ([\\#2248](https://github.com/psf/requests/pull/2248/))\n\n2.4.1 (2014-09-09)\n------------------\n\n-   Now has a \"security\" package extras set,\n    `$ pip install requests[security]`\n-   Requests will now use Certifi if it is available.\n-   Capture and re-raise urllib3 ProtocolError\n-   Bugfix for responses that attempt to redirect to themselves forever\n    (wtf?).\n\n2.4.0 (2014-08-29)\n------------------\n\n**Behavioral Changes**\n\n-   `Connection: keep-alive` header is now sent automatically.\n\n**Improvements**\n\n-   Support for connect timeouts! Timeout now accepts a tuple (connect,\n    read) which is used to set individual connect and read timeouts.\n-   Allow copying of PreparedRequests without headers/cookies.\n-   Updated bundled urllib3 version.\n-   Refactored settings loading from environment -- new\n    Session.merge\\_environment\\_settings.\n-   Handle socket errors in iter\\_content.\n\n2.3.0 (2014-05-16)\n------------------\n\n**API Changes**\n\n-   New `Response` property `is_redirect`, which is true when the\n    library could have processed this response as a redirection (whether\n    or not it actually did).\n-   The `timeout` parameter now affects requests with both `stream=True`\n    and `stream=False` equally.\n-   The change in v2.0.0 to mandate explicit proxy schemes has been\n    reverted. Proxy schemes now default to `http://`.\n-   The `CaseInsensitiveDict` used for HTTP headers now behaves like a\n    normal dictionary when references as string or viewed in the\n    interpreter.\n\n**Bugfixes**\n\n-   No longer expose Authorization or Proxy-Authorization headers on\n    redirect. Fix CVE-2014-1829 and CVE-2014-1830 respectively.\n-   Authorization is re-evaluated each redirect.\n-   On redirect, pass url as native strings.\n-   Fall-back to autodetected encoding for JSON when Unicode detection\n    fails.\n-   Headers set to `None` on the `Session` are now correctly not sent.\n-   Correctly honor `decode_unicode` even if it wasn't used earlier in\n    the same response.\n-   Stop advertising `compress` as a supported Content-Encoding.\n-   The `Response.history` parameter is now always a list.\n-   Many, many `urllib3` bugfixes.\n\n2.2.1 (2014-01-23)\n------------------\n\n**Bugfixes**\n\n-   Fixes incorrect parsing of proxy credentials that contain a literal\n    or encoded '\\#' character.\n-   Assorted urllib3 fixes.\n\n2.2.0 (2014-01-09)\n------------------\n\n**API Changes**\n\n-   New exception: `ContentDecodingError`. Raised instead of `urllib3`\n    `DecodeError` exceptions.\n\n**Bugfixes**\n\n-   Avoid many many exceptions from the buggy implementation of\n    `proxy_bypass` on OS X in Python 2.6.\n-   Avoid crashing when attempting to get authentication credentials\n    from \\~/.netrc when running as a user without a home directory.\n-   Use the correct pool size for pools of connections to proxies.\n-   Fix iteration of `CookieJar` objects.\n-   Ensure that cookies are persisted over redirect.\n-   Switch back to using chardet, since it has merged with charade.\n\n2.1.0 (2013-12-05)\n------------------\n\n-   Updated CA Bundle, of course.\n-   Cookies set on individual Requests through a `Session` (e.g. via\n    `Session.get()`) are no longer persisted to the `Session`.\n-   Clean up connections when we hit problems during chunked upload,\n    rather than leaking them.\n-   Return connections to the pool when a chunked upload is successful,\n    rather than leaking it.\n-   Match the HTTPbis recommendation for HTTP 301 redirects.\n-   Prevent hanging when using streaming uploads and Digest Auth when a\n    401 is received.\n-   Values of headers set by Requests are now always the native string\n    type.\n-   Fix previously broken SNI support.\n-   Fix accessing HTTP proxies using proxy authentication.\n-   Unencode HTTP Basic usernames and passwords extracted from URLs.\n-   Support for IP address ranges for no\\_proxy environment variable\n-   Parse headers correctly when users override the default `Host:`\n    header.\n-   Avoid munging the URL in case of case-sensitive servers.\n-   Looser URL handling for non-HTTP/HTTPS urls.\n-   Accept unicode methods in Python 2.6 and 2.7.\n-   More resilient cookie handling.\n-   Make `Response` objects pickleable.\n-   Actually added MD5-sess to Digest Auth instead of pretending to like\n    last time.\n-   Updated internal urllib3.\n-   Fixed @Lukasa's lack of taste.\n\n2.0.1 (2013-10-24)\n------------------\n\n-   Updated included CA Bundle with new mistrusts and automated process\n    for the future\n-   Added MD5-sess to Digest Auth\n-   Accept per-file headers in multipart file POST messages.\n-   Fixed: Don't send the full URL on CONNECT messages.\n-   Fixed: Correctly lowercase a redirect scheme.\n-   Fixed: Cookies not persisted when set via functional API.\n-   Fixed: Translate urllib3 ProxyError into a requests ProxyError\n    derived from ConnectionError.\n-   Updated internal urllib3 and chardet.\n\n2.0.0 (2013-09-24)\n------------------\n\n**API Changes:**\n\n-   Keys in the Headers dictionary are now native strings on all Python\n    versions, i.e. bytestrings on Python 2, unicode on Python 3.\n-   Proxy URLs now *must* have an explicit scheme. A `MissingSchema`\n    exception will be raised if they don't.\n-   Timeouts now apply to read time if `Stream=False`.\n-   `RequestException` is now a subclass of `IOError`, not\n    `RuntimeError`.\n-   Added new method to `PreparedRequest` objects:\n    `PreparedRequest.copy()`.\n-   Added new method to `Session` objects: `Session.update_request()`.\n    This method updates a `Request` object with the data (e.g. cookies)\n    stored on the `Session`.\n-   Added new method to `Session` objects: `Session.prepare_request()`.\n    This method updates and prepares a `Request` object, and returns the\n    corresponding `PreparedRequest` object.\n-   Added new method to `HTTPAdapter` objects:\n    `HTTPAdapter.proxy_headers()`. This should not be called directly,\n    but improves the subclass interface.\n-   `httplib.IncompleteRead` exceptions caused by incorrect chunked\n    encoding will now raise a Requests `ChunkedEncodingError` instead.\n-   Invalid percent-escape sequences now cause a Requests `InvalidURL`\n    exception to be raised.\n-   HTTP 208 no longer uses reason phrase `\"im_used\"`. Correctly uses\n    `\"already_reported\"`.\n-   HTTP 226 reason added (`\"im_used\"`).\n\n**Bugfixes:**\n\n-   Vastly improved proxy support, including the CONNECT verb. Special\n    thanks to the many contributors who worked towards this improvement.\n-   Cookies are now properly managed when 401 authentication responses\n    are received.\n-   Chunked encoding fixes.\n-   Support for mixed case schemes.\n-   Better handling of streaming downloads.\n-   Retrieve environment proxies from more locations.\n-   Minor cookies fixes.\n-   Improved redirect behaviour.\n-   Improved streaming behaviour, particularly for compressed data.\n-   Miscellaneous small Python 3 text encoding bugs.\n-   `.netrc` no longer overrides explicit auth.\n-   Cookies set by hooks are now correctly persisted on Sessions.\n-   Fix problem with cookies that specify port numbers in their host\n    field.\n-   `BytesIO` can be used to perform streaming uploads.\n-   More generous parsing of the `no_proxy` environment variable.\n-   Non-string objects can be passed in data values alongside files.\n\n1.2.3 (2013-05-25)\n------------------\n\n-   Simple packaging fix\n\n1.2.2 (2013-05-23)\n------------------\n\n-   Simple packaging fix\n\n1.2.1 (2013-05-20)\n------------------\n\n-   301 and 302 redirects now change the verb to GET for all verbs, not\n    just POST, improving browser compatibility.\n-   Python 3.3.2 compatibility\n-   Always percent-encode location headers\n-   Fix connection adapter matching to be most-specific first\n-   new argument to the default connection adapter for passing a block\n    argument\n-   prevent a KeyError when there's no link headers\n\n1.2.0 (2013-03-31)\n------------------\n\n-   Fixed cookies on sessions and on requests\n-   Significantly change how hooks are dispatched - hooks now receive\n    all the arguments specified by the user when making a request so\n    hooks can make a secondary request with the same parameters. This is\n    especially necessary for authentication handler authors\n-   certifi support was removed\n-   Fixed bug where using OAuth 1 with body `signature_type` sent no\n    data\n-   Major proxy work thanks to @Lukasa including parsing of proxy\n    authentication from the proxy url\n-   Fix DigestAuth handling too many 401s\n-   Update vendored urllib3 to include SSL bug fixes\n-   Allow keyword arguments to be passed to `json.loads()` via the\n    `Response.json()` method\n-   Don't send `Content-Length` header by default on `GET` or `HEAD`\n    requests\n-   Add `elapsed` attribute to `Response` objects to time how long a\n    request took.\n-   Fix `RequestsCookieJar`\n-   Sessions and Adapters are now picklable, i.e., can be used with the\n    multiprocessing library\n-   Update charade to version 1.0.3\n\nThe change in how hooks are dispatched will likely cause a great deal of\nissues.\n\n1.1.0 (2013-01-10)\n------------------\n\n-   CHUNKED REQUESTS\n-   Support for iterable response bodies\n-   Assume servers persist redirect params\n-   Allow explicit content types to be specified for file data\n-   Make merge\\_kwargs case-insensitive when looking up keys\n\n1.0.3 (2012-12-18)\n------------------\n\n-   Fix file upload encoding bug\n-   Fix cookie behavior\n\n1.0.2 (2012-12-17)\n------------------\n\n-   Proxy fix for HTTPAdapter.\n\n1.0.1 (2012-12-17)\n------------------\n\n-   Cert verification exception bug.\n-   Proxy fix for HTTPAdapter.\n\n1.0.0 (2012-12-17)\n------------------\n\n-   Massive Refactor and Simplification\n-   Switch to Apache 2.0 license\n-   Swappable Connection Adapters\n-   Mountable Connection Adapters\n-   Mutable ProcessedRequest chain\n-   /s/prefetch/stream\n-   Removal of all configuration\n-   Standard library logging\n-   Make Response.json() callable, not property.\n-   Usage of new charade project, which provides python 2 and 3\n    simultaneous chardet.\n-   Removal of all hooks except 'response'\n-   Removal of all authentication helpers (OAuth, Kerberos)\n\nThis is not a backwards compatible change.\n\n0.14.2 (2012-10-27)\n-------------------\n\n-   Improved mime-compatible JSON handling\n-   Proxy fixes\n-   Path hack fixes\n-   Case-Insensitive Content-Encoding headers\n-   Support for CJK parameters in form posts\n\n0.14.1 (2012-10-01)\n-------------------\n\n-   Python 3.3 Compatibility\n-   Simply default accept-encoding\n-   Bugfixes\n\n0.14.0 (2012-09-02)\n-------------------\n\n-   No more iter\\_content errors if already downloaded.\n\n0.13.9 (2012-08-25)\n-------------------\n\n-   Fix for OAuth + POSTs\n-   Remove exception eating from dispatch\\_hook\n-   General bugfixes\n\n0.13.8 (2012-08-21)\n-------------------\n\n-   Incredible Link header support :)\n\n0.13.7 (2012-08-19)\n-------------------\n\n-   Support for (key, value) lists everywhere.\n-   Digest Authentication improvements.\n-   Ensure proxy exclusions work properly.\n-   Clearer UnicodeError exceptions.\n-   Automatic casting of URLs to strings (fURL and such)\n-   Bugfixes.\n\n0.13.6 (2012-08-06)\n-------------------\n\n-   Long awaited fix for hanging connections!\n\n0.13.5 (2012-07-27)\n-------------------\n\n-   Packaging fix\n\n0.13.4 (2012-07-27)\n-------------------\n\n-   GSSAPI/Kerberos authentication!\n-   App Engine 2.7 Fixes!\n-   Fix leaking connections (from urllib3 update)\n-   OAuthlib path hack fix\n-   OAuthlib URL parameters fix.\n\n0.13.3 (2012-07-12)\n-------------------\n\n-   Use simplejson if available.\n-   Do not hide SSLErrors behind Timeouts.\n-   Fixed param handling with urls containing fragments.\n-   Significantly improved information in User Agent.\n-   client certificates are ignored when verify=False\n\n0.13.2 (2012-06-28)\n-------------------\n\n-   Zero dependencies (once again)!\n-   New: Response.reason\n-   Sign querystring parameters in OAuth 1.0\n-   Client certificates no longer ignored when verify=False\n-   Add openSUSE certificate support\n\n0.13.1 (2012-06-07)\n-------------------\n\n-   Allow passing a file or file-like object as data.\n-   Allow hooks to return responses that indicate errors.\n-   Fix Response.text and Response.json for body-less responses.\n\n0.13.0 (2012-05-29)\n-------------------\n\n-   Removal of Requests.async in favor of\n    [grequests](https://github.com/kennethreitz/grequests)\n-   Allow disabling of cookie persistence.\n-   New implementation of safe\\_mode\n-   cookies.get now supports default argument\n-   Session cookies not saved when Session.request is called with\n    return\\_response=False\n-   Env: no\\_proxy support.\n-   RequestsCookieJar improvements.\n-   Various bug fixes.\n\n0.12.1 (2012-05-08)\n-------------------\n\n-   New `Response.json` property.\n-   Ability to add string file uploads.\n-   Fix out-of-range issue with iter\\_lines.\n-   Fix iter\\_content default size.\n-   Fix POST redirects containing files.\n\n0.12.0 (2012-05-02)\n-------------------\n\n-   EXPERIMENTAL OAUTH SUPPORT!\n-   Proper CookieJar-backed cookies interface with awesome dict-like\n    interface.\n-   Speed fix for non-iterated content chunks.\n-   Move `pre_request` to a more usable place.\n-   New `pre_send` hook.\n-   Lazily encode data, params, files.\n-   Load system Certificate Bundle if `certify` isn't available.\n-   Cleanups, fixes.\n\n0.11.2 (2012-04-22)\n-------------------\n\n-   Attempt to use the OS's certificate bundle if `certifi` isn't\n    available.\n-   Infinite digest auth redirect fix.\n-   Multi-part file upload improvements.\n-   Fix decoding of invalid %encodings in URLs.\n-   If there is no content in a response don't throw an error the second\n    time that content is attempted to be read.\n-   Upload data on redirects.\n\n0.11.1 (2012-03-30)\n-------------------\n\n-   POST redirects now break RFC to do what browsers do: Follow up with\n    a GET.\n-   New `strict_mode` configuration to disable new redirect behavior.\n\n0.11.0 (2012-03-14)\n-------------------\n\n-   Private SSL Certificate support\n-   Remove select.poll from Gevent monkeypatching\n-   Remove redundant generator for chunked transfer encoding\n-   Fix: Response.ok raises Timeout Exception in safe\\_mode\n\n0.10.8 (2012-03-09)\n-------------------\n\n-   Generate chunked ValueError fix\n-   Proxy configuration by environment variables\n-   Simplification of iter\\_lines.\n-   New trust\\_env configuration for disabling system/environment hints.\n-   Suppress cookie errors.\n\n0.10.7 (2012-03-07)\n-------------------\n\n-   encode\\_uri = False\n\n0.10.6 (2012-02-25)\n-------------------\n\n-   Allow '=' in cookies.\n\n0.10.5 (2012-02-25)\n-------------------\n\n-   Response body with 0 content-length fix.\n-   New async.imap.\n-   Don't fail on netrc.\n\n0.10.4 (2012-02-20)\n-------------------\n\n-   Honor netrc.\n\n0.10.3 (2012-02-20)\n-------------------\n\n-   HEAD requests don't follow redirects anymore.\n-   raise\\_for\\_status() doesn't raise for 3xx anymore.\n-   Make Session objects picklable.\n-   ValueError for invalid schema URLs.\n\n0.10.2 (2012-01-15)\n-------------------\n\n-   Vastly improved URL quoting.\n-   Additional allowed cookie key values.\n-   Attempted fix for \"Too many open files\" Error\n-   Replace unicode errors on first pass, no need for second pass.\n-   Append '/' to bare-domain urls before query insertion.\n-   Exceptions now inherit from RuntimeError.\n-   Binary uploads + auth fix.\n-   Bugfixes.\n\n0.10.1 (2012-01-23)\n-------------------\n\n-   PYTHON 3 SUPPORT!\n-   Dropped 2.5 Support. (*Backwards Incompatible*)\n\n0.10.0 (2012-01-21)\n-------------------\n\n-   `Response.content` is now bytes-only. (*Backwards Incompatible*)\n-   New `Response.text` is unicode-only.\n-   If no `Response.encoding` is specified and `chardet` is available,\n    `Response.text` will guess an encoding.\n-   Default to ISO-8859-1 (Western) encoding for \"text\" subtypes.\n-   Removal of decode\\_unicode. (*Backwards Incompatible*)\n-   New multiple-hooks system.\n-   New `Response.register_hook` for registering hooks within the\n    pipeline.\n-   `Response.url` is now Unicode.\n\n0.9.3 (2012-01-18)\n------------------\n\n-   SSL verify=False bugfix (apparent on windows machines).\n\n0.9.2 (2012-01-18)\n------------------\n\n-   Asynchronous async.send method.\n-   Support for proper chunk streams with boundaries.\n-   session argument for Session classes.\n-   Print entire hook tracebacks, not just exception instance.\n-   Fix response.iter\\_lines from pending next line.\n-   Fix but in HTTP-digest auth w/ URI having query strings.\n-   Fix in Event Hooks section.\n-   Urllib3 update.\n\n0.9.1 (2012-01-06)\n------------------\n\n-   danger\\_mode for automatic Response.raise\\_for\\_status()\n-   Response.iter\\_lines refactor\n\n0.9.0 (2011-12-28)\n------------------\n\n-   verify ssl is default.\n\n0.8.9 (2011-12-28)\n------------------\n\n-   Packaging fix.\n\n0.8.8 (2011-12-28)\n------------------\n\n-   SSL CERT VERIFICATION!\n-   Release of Cerifi: Mozilla's cert list.\n-   New 'verify' argument for SSL requests.\n-   Urllib3 update.\n\n0.8.7 (2011-12-24)\n------------------\n\n-   iter\\_lines last-line truncation fix\n-   Force safe\\_mode for async requests\n-   Handle safe\\_mode exceptions more consistently\n-   Fix iteration on null responses in safe\\_mode\n\n0.8.6 (2011-12-18)\n------------------\n\n-   Socket timeout fixes.\n-   Proxy Authorization support.\n\n0.8.5 (2011-12-14)\n------------------\n\n-   Response.iter\\_lines!\n\n0.8.4 (2011-12-11)\n------------------\n\n-   Prefetch bugfix.\n-   Added license to installed version.\n\n0.8.3 (2011-11-27)\n------------------\n\n-   Converted auth system to use simpler callable objects.\n-   New session parameter to API methods.\n-   Display full URL while logging.\n\n0.8.2 (2011-11-19)\n------------------\n\n-   New Unicode decoding system, based on over-ridable\n    Response.encoding.\n-   Proper URL slash-quote handling.\n-   Cookies with `[`, `]`, and `_` allowed.\n\n0.8.1 (2011-11-15)\n------------------\n\n-   URL Request path fix\n-   Proxy fix.\n-   Timeouts fix.\n\n0.8.0 (2011-11-13)\n------------------\n\n-   Keep-alive support!\n-   Complete removal of Urllib2\n-   Complete removal of Poster\n-   Complete removal of CookieJars\n-   New ConnectionError raising\n-   Safe\\_mode for error catching\n-   prefetch parameter for request methods\n-   OPTION method\n-   Async pool size throttling\n-   File uploads send real names\n-   Vendored in urllib3\n\n0.7.6 (2011-11-07)\n------------------\n\n-   Digest authentication bugfix (attach query data to path)\n\n0.7.5 (2011-11-04)\n------------------\n\n-   Response.content = None if there was an invalid response.\n-   Redirection auth handling.\n\n0.7.4 (2011-10-26)\n------------------\n\n-   Session Hooks fix.\n\n0.7.3 (2011-10-23)\n------------------\n\n-   Digest Auth fix.\n\n0.7.2 (2011-10-23)\n------------------\n\n-   PATCH Fix.\n\n0.7.1 (2011-10-23)\n------------------\n\n-   Move away from urllib2 authentication handling.\n-   Fully Remove AuthManager, AuthObject, &c.\n-   New tuple-based auth system with handler callbacks.\n\n0.7.0 (2011-10-22)\n------------------\n\n-   Sessions are now the primary interface.\n-   Deprecated InvalidMethodException.\n-   PATCH fix.\n-   New config system (no more global settings).\n\n0.6.6 (2011-10-19)\n------------------\n\n-   Session parameter bugfix (params merging).\n\n0.6.5 (2011-10-18)\n------------------\n\n-   Offline (fast) test suite.\n-   Session dictionary argument merging.\n\n0.6.4 (2011-10-13)\n------------------\n\n-   Automatic decoding of unicode, based on HTTP Headers.\n-   New `decode_unicode` setting.\n-   Removal of `r.read/close` methods.\n-   New `r.faw` interface for advanced response usage.\\*\n-   Automatic expansion of parameterized headers.\n\n0.6.3 (2011-10-13)\n------------------\n\n-   Beautiful `requests.async` module, for making async requests w/\n    gevent.\n\n0.6.2 (2011-10-09)\n------------------\n\n-   GET/HEAD obeys allow\\_redirects=False.\n\n0.6.1 (2011-08-20)\n------------------\n\n-   Enhanced status codes experience `\\o/`\n-   Set a maximum number of redirects (`settings.max_redirects`)\n-   Full Unicode URL support\n-   Support for protocol-less redirects.\n-   Allow for arbitrary request types.\n-   Bugfixes\n\n0.6.0 (2011-08-17)\n------------------\n\n-   New callback hook system\n-   New persistent sessions object and context manager\n-   Transparent Dict-cookie handling\n-   Status code reference object\n-   Removed Response.cached\n-   Added Response.request\n-   All args are kwargs\n-   Relative redirect support\n-   HTTPError handling improvements\n-   Improved https testing\n-   Bugfixes\n\n0.5.1 (2011-07-23)\n------------------\n\n-   International Domain Name Support!\n-   Access headers without fetching entire body (`read()`)\n-   Use lists as dicts for parameters\n-   Add Forced Basic Authentication\n-   Forced Basic is default authentication type\n-   `python-requests.org` default User-Agent header\n-   CaseInsensitiveDict lower-case caching\n-   Response.history bugfix\n\n0.5.0 (2011-06-21)\n------------------\n\n-   PATCH Support\n-   Support for Proxies\n-   HTTPBin Test Suite\n-   Redirect Fixes\n-   settings.verbose stream writing\n-   Querystrings for all methods\n-   URLErrors (Connection Refused, Timeout, Invalid URLs) are treated as\n    explicitly raised\n    `r.requests.get('hwe://blah'); r.raise_for_status()`\n\n0.4.1 (2011-05-22)\n------------------\n\n-   Improved Redirection Handling\n-   New 'allow\\_redirects' param for following non-GET/HEAD Redirects\n-   Settings module refactoring\n\n0.4.0 (2011-05-15)\n------------------\n\n-   Response.history: list of redirected responses\n-   Case-Insensitive Header Dictionaries!\n-   Unicode URLs\n\n0.3.4 (2011-05-14)\n------------------\n\n-   Urllib2 HTTPAuthentication Recursion fix (Basic/Digest)\n-   Internal Refactor\n-   Bytes data upload Bugfix\n\n0.3.3 (2011-05-12)\n------------------\n\n-   Request timeouts\n-   Unicode url-encoded data\n-   Settings context manager and module\n\n0.3.2 (2011-04-15)\n------------------\n\n-   Automatic Decompression of GZip Encoded Content\n-   AutoAuth Support for Tupled HTTP Auth\n\n0.3.1 (2011-04-01)\n------------------\n\n-   Cookie Changes\n-   Response.read()\n-   Poster fix\n\n0.3.0 (2011-02-25)\n------------------\n\n-   Automatic Authentication API Change\n-   Smarter Query URL Parameterization\n-   Allow file uploads and POST data together\n-\n\n    New Authentication Manager System\n\n    :   -   Simpler Basic HTTP System\n        -   Supports all built-in urllib2 Auths\n        -   Allows for custom Auth Handlers\n\n0.2.4 (2011-02-19)\n------------------\n\n-   Python 2.5 Support\n-   PyPy-c v1.4 Support\n-   Auto-Authentication tests\n-   Improved Request object constructor\n\n0.2.3 (2011-02-15)\n------------------\n\n-\n\n    New HTTPHandling Methods\n\n    :   -   Response.\\_\\_nonzero\\_\\_ (false if bad HTTP Status)\n        -   Response.ok (True if expected HTTP Status)\n        -   Response.error (Logged HTTPError if bad HTTP Status)\n        -   Response.raise\\_for\\_status() (Raises stored HTTPError)\n\n0.2.2 (2011-02-14)\n------------------\n\n-   Still handles request in the event of an HTTPError. (Issue \\#2)\n-   Eventlet and Gevent Monkeypatch support.\n-   Cookie Support (Issue \\#1)\n\n0.2.1 (2011-02-14)\n------------------\n\n-   Added file attribute to POST and PUT requests for multipart-encode\n    file uploads.\n-   Added Request.url attribute for context and redirects\n\n0.2.0 (2011-02-14)\n------------------\n\n-   Birth!\n\n0.0.1 (2011-02-13)\n------------------\n\n-   Frustration\n-   Conception\n",
      "scraped_at": 1756988939.2548797
    },
    {
      "repo": "requests/requests",
      "filename": "README.md",
      "path": "README.md",
      "content": "# Requests\n\n**Requests** is a simple, yet elegant, HTTP library.\n\n```python\n>>> import requests\n>>> r = requests.get('https://httpbin.org/basic-auth/user/pass', auth=('user', 'pass'))\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'application/json; charset=utf8'\n>>> r.encoding\n'utf-8'\n>>> r.text\n'{\"authenticated\": true, ...'\n>>> r.json()\n{'authenticated': True, ...}\n```\n\nRequests allows you to send HTTP/1.1 requests extremely easily. There\u2019s no need to manually add query strings to your URLs, or to form-encode your `PUT` & `POST` data \u2014 but nowadays, just use the `json` method!\n\nRequests is one of the most downloaded Python packages today, pulling in around `30M downloads / week`\u2014 according to GitHub, Requests is currently [depended upon](https://github.com/psf/requests/network/dependents?package_id=UGFja2FnZS01NzA4OTExNg%3D%3D) by `1,000,000+` repositories. You may certainly put your trust in this code.\n\n[![Downloads](https://static.pepy.tech/badge/requests/month)](https://pepy.tech/project/requests)\n[![Supported Versions](https://img.shields.io/pypi/pyversions/requests.svg)](https://pypi.org/project/requests)\n[![Contributors](https://img.shields.io/github/contributors/psf/requests.svg)](https://github.com/psf/requests/graphs/contributors)\n\n## Installing Requests and Supported Versions\n\nRequests is available on PyPI:\n\n```console\n$ python -m pip install requests\n```\n\nRequests officially supports Python 3.9+.\n\n## Supported Features & Best\u2013Practices\n\nRequests is ready for the demands of building robust and reliable HTTP\u2013speaking applications, for the needs of today.\n\n- Keep-Alive & Connection Pooling\n- International Domains and URLs\n- Sessions with Cookie Persistence\n- Browser-style TLS/SSL Verification\n- Basic & Digest Authentication\n- Familiar `dict`\u2013like Cookies\n- Automatic Content Decompression and Decoding\n- Multi-part File Uploads\n- SOCKS Proxy Support\n- Connection Timeouts\n- Streaming Downloads\n- Automatic honoring of `.netrc`\n- Chunked HTTP Requests\n\n## API Reference and User Guide available on [Read the Docs](https://requests.readthedocs.io)\n\n[![Read the Docs](https://raw.githubusercontent.com/psf/requests/main/ext/ss.png)](https://requests.readthedocs.io)\n\n## Cloning the repository\n\nWhen cloning the Requests repository, you may need to add the `-c\nfetch.fsck.badTimezone=ignore` flag to avoid an error about a bad commit timestamp (see\n[this issue](https://github.com/psf/requests/issues/2690) for more background):\n\n```shell\ngit clone -c fetch.fsck.badTimezone=ignore https://github.com/psf/requests.git\n```\n\nYou can also apply this setting to your global Git config:\n\n```shell\ngit config --global fetch.fsck.badTimezone ignore\n```\n\n---\n\n[![Kenneth Reitz](https://raw.githubusercontent.com/psf/requests/main/ext/kr.png)](https://kennethreitz.org) [![Python Software Foundation](https://raw.githubusercontent.com/psf/requests/main/ext/psf.png)](https://www.python.org/psf)\n",
      "scraped_at": 1756988940.2755282
    },
    {
      "repo": "requests/requests",
      "filename": "setup.py",
      "path": "setup.py",
      "content": "#!/usr/bin/env python\nimport os\nimport sys\nfrom codecs import open\n\nfrom setuptools import setup\n\nCURRENT_PYTHON = sys.version_info[:2]\nREQUIRED_PYTHON = (3, 9)\n\nif CURRENT_PYTHON < REQUIRED_PYTHON:\n    sys.stderr.write(\n        \"\"\"\n==========================\nUnsupported Python version\n==========================\nThis version of Requests requires at least Python {}.{}, but\nyou're trying to install it on Python {}.{}. To resolve this,\nconsider upgrading to a supported Python version.\n\nIf you can't upgrade your Python version, you'll need to\npin to an older version of Requests (<2.32.0).\n\"\"\".format(\n            *(REQUIRED_PYTHON + CURRENT_PYTHON)\n        )\n    )\n    sys.exit(1)\n\n\n# 'setup.py publish' shortcut.\nif sys.argv[-1] == \"publish\":\n    os.system(\"python setup.py sdist bdist_wheel\")\n    os.system(\"twine upload dist/*\")\n    sys.exit()\n\nrequires = [\n    \"charset_normalizer>=2,<4\",\n    \"idna>=2.5,<4\",\n    \"urllib3>=1.21.1,<3\",\n    \"certifi>=2017.4.17\",\n]\ntest_requirements = [\n    \"pytest-httpbin==2.1.0\",\n    \"pytest-cov\",\n    \"pytest-mock\",\n    \"pytest-xdist\",\n    \"PySocks>=1.5.6, !=1.5.7\",\n    \"pytest>=3\",\n]\n\nabout = {}\nhere = os.path.abspath(os.path.dirname(__file__))\nwith open(os.path.join(here, \"src\", \"requests\", \"__version__.py\"), \"r\", \"utf-8\") as f:\n    exec(f.read(), about)\n\nwith open(\"README.md\", \"r\", \"utf-8\") as f:\n    readme = f.read()\n\nsetup(\n    name=about[\"__title__\"],\n    version=about[\"__version__\"],\n    description=about[\"__description__\"],\n    long_description=readme,\n    long_description_content_type=\"text/markdown\",\n    author=about[\"__author__\"],\n    author_email=about[\"__author_email__\"],\n    url=about[\"__url__\"],\n    packages=[\"requests\"],\n    package_data={\"\": [\"LICENSE\", \"NOTICE\"]},\n    package_dir={\"\": \"src\"},\n    include_package_data=True,\n    python_requires=\">=3.9\",\n    install_requires=requires,\n    license=about[\"__license__\"],\n    zip_safe=False,\n    classifiers=[\n        \"Development Status :: 5 - Production/Stable\",\n        \"Environment :: Web Environment\",\n        \"Intended Audience :: Developers\",\n        \"License :: OSI Approved :: Apache Software License\",\n        \"Natural Language :: English\",\n        \"Operating System :: OS Independent\",\n        \"Programming Language :: Python\",\n        \"Programming Language :: Python :: 3\",\n        \"Programming Language :: Python :: 3.9\",\n        \"Programming Language :: Python :: 3.10\",\n        \"Programming Language :: Python :: 3.11\",\n        \"Programming Language :: Python :: 3.12\",\n        \"Programming Language :: Python :: 3.13\",\n        \"Programming Language :: Python :: 3.14\",\n        \"Programming Language :: Python :: 3 :: Only\",\n        \"Programming Language :: Python :: Implementation :: CPython\",\n        \"Programming Language :: Python :: Implementation :: PyPy\",\n        \"Topic :: Internet :: WWW/HTTP\",\n        \"Topic :: Software Development :: Libraries\",\n    ],\n    tests_require=test_requirements,\n    extras_require={\n        \"security\": [],\n        \"socks\": [\"PySocks>=1.5.6, !=1.5.7\"],\n        \"use_chardet_on_py3\": [\"chardet>=3.0.2,<6\"],\n    },\n    project_urls={\n        \"Documentation\": \"https://requests.readthedocs.io\",\n        \"Source\": \"https://github.com/psf/requests\",\n    },\n)\n",
      "scraped_at": 1756988941.2661805
    },
    {
      "repo": "aio-libs/aiohttp",
      "filename": "CODE_OF_CONDUCT.md",
      "path": "CODE_OF_CONDUCT.md",
      "content": "# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nIn the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.\n\n## Our Standards\n\nExamples of behavior that contributes to creating a positive environment include:\n\n* Using welcoming and inclusive language\n* Being respectful of differing viewpoints and experiences\n* Gracefully accepting constructive criticism\n* Focusing on what is best for the community\n* Showing empathy towards other community members\n\nExamples of unacceptable behavior by participants include:\n\n* The use of sexualized language or imagery and unwelcome sexual attention or advances\n* Trolling, insulting/derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or electronic address, without explicit permission\n* Other conduct which could reasonably be considered inappropriate in a professional setting\n\n## Our Responsibilities\n\nProject maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior.\n\nProject maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.\n\n## Scope\n\nThis Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at andrew.svetlov@gmail.com. The project team will review and investigate all complaints, and will respond in a way that it deems appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately.\n\nProject maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4, available at [http://contributor-covenant.org/version/1/4][version]\n\n[homepage]: http://contributor-covenant.org\n[version]: http://contributor-covenant.org/version/1/4/\n",
      "scraped_at": 1756988943.005572
    },
    {
      "repo": "aio-libs/aiohttp",
      "filename": "setup.py",
      "path": "setup.py",
      "content": "import os\nimport pathlib\nimport sys\n\nfrom setuptools import Extension, setup\n\nif sys.version_info < (3, 9):\n    raise RuntimeError(\"aiohttp 4.x requires Python 3.9+\")\n\n\nUSE_SYSTEM_DEPS = bool(\n    os.environ.get(\"AIOHTTP_USE_SYSTEM_DEPS\", os.environ.get(\"USE_SYSTEM_DEPS\"))\n)\nNO_EXTENSIONS: bool = bool(os.environ.get(\"AIOHTTP_NO_EXTENSIONS\"))\nHERE = pathlib.Path(__file__).parent\nIS_GIT_REPO = (HERE / \".git\").exists()\n\n\nif sys.implementation.name != \"cpython\":\n    NO_EXTENSIONS = True\n\n\nif (\n    not USE_SYSTEM_DEPS\n    and IS_GIT_REPO\n    and not (HERE / \"vendor/llhttp/README.md\").exists()\n):\n    print(\"Install submodules when building from git clone\", file=sys.stderr)\n    print(\"Hint:\", file=sys.stderr)\n    print(\"  git submodule update --init\", file=sys.stderr)\n    sys.exit(2)\n\n\n# NOTE: makefile cythonizes all Cython modules\n\nif USE_SYSTEM_DEPS:\n    import shlex\n\n    import pkgconfig\n\n    llhttp_sources = []\n    llhttp_kwargs = {\n        \"extra_compile_args\": shlex.split(pkgconfig.cflags(\"libllhttp\")),\n        \"extra_link_args\": shlex.split(pkgconfig.libs(\"libllhttp\")),\n    }\nelse:\n    llhttp_sources = [\n        \"vendor/llhttp/build/c/llhttp.c\",\n        \"vendor/llhttp/src/native/api.c\",\n        \"vendor/llhttp/src/native/http.c\",\n    ]\n    llhttp_kwargs = {\n        \"define_macros\": [(\"LLHTTP_STRICT_MODE\", 0)],\n        \"include_dirs\": [\"vendor/llhttp/build\"],\n    }\n\nextensions = [\n    Extension(\"aiohttp._websocket.mask\", [\"aiohttp/_websocket/mask.c\"]),\n    Extension(\n        \"aiohttp._http_parser\",\n        [\n            \"aiohttp/_http_parser.c\",\n            \"aiohttp/_find_header.c\",\n            *llhttp_sources,\n        ],\n        **llhttp_kwargs,\n    ),\n    Extension(\"aiohttp._http_writer\", [\"aiohttp/_http_writer.c\"]),\n    Extension(\"aiohttp._websocket.reader_c\", [\"aiohttp/_websocket/reader_c.c\"]),\n]\n\n\nbuild_type = \"Pure\" if NO_EXTENSIONS else \"Accelerated\"\nsetup_kwargs = {} if NO_EXTENSIONS else {\"ext_modules\": extensions}\n\nprint(\"*********************\", file=sys.stderr)\nprint(\"* {build_type} build *\".format_map(locals()), file=sys.stderr)\nprint(\"*********************\", file=sys.stderr)\nsetup(**setup_kwargs)\n",
      "scraped_at": 1756988944.0063827
    },
    {
      "repo": "urllib3/urllib3",
      "filename": "CODE_OF_CONDUCT.md",
      "path": "CODE_OF_CONDUCT.md",
      "content": "\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, religion, or sexual identity\nand orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the\n  overall community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or\n  advances of any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email\n  address, without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at @sethmlarson or @shazow.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series\nof actions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or\npermanent ban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior,  harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within\nthe community.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.0, available at\nhttps://www.contributor-covenant.org/version/2/0/code_of_conduct.html.\n\nCommunity Impact Guidelines were inspired by [Mozilla's code of conduct\nenforcement ladder](https://github.com/mozilla/diversity).\n\n[homepage]: https://www.contributor-covenant.org\n\nFor answers to common questions about this code of conduct, see the FAQ at\nhttps://www.contributor-covenant.org/faq. Translations are available at\nhttps://www.contributor-covenant.org/translations.\n",
      "scraped_at": 1756988945.671194
    },
    {
      "repo": "urllib3/urllib3",
      "filename": "README.md",
      "path": "README.md",
      "content": "<h1 align=\"center\">\n\n![urllib3](https://github.com/urllib3/urllib3/raw/main/docs/_static/banner_github.svg)\n\n</h1>\n\n<p align=\"center\">\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"PyPI Version\" src=\"https://img.shields.io/pypi/v/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://pypi.org/project/urllib3\"><img alt=\"Python Versions\" src=\"https://img.shields.io/pypi/pyversions/urllib3.svg?maxAge=86400\" /></a>\n  <a href=\"https://discord.gg/urllib3\"><img alt=\"Join our Discord\" src=\"https://img.shields.io/discord/756342717725933608?color=%237289da&label=discord\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions?query=workflow%3ACI\"><img alt=\"Coverage Status\" src=\"https://img.shields.io/badge/coverage-100%25-success\" /></a>\n  <a href=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml?query=branch%3Amain\"><img alt=\"Build Status on GitHub\" src=\"https://github.com/urllib3/urllib3/actions/workflows/ci.yml/badge.svg?branch:main&workflow:CI\" /></a>\n  <a href=\"https://urllib3.readthedocs.io\"><img alt=\"Documentation Status\" src=\"https://readthedocs.org/projects/urllib3/badge/?version=latest\" /></a><br>\n  <a href=\"https://deps.dev/pypi/urllib3\"><img alt=\"OpenSSF Scorecard\" src=\"https://api.securityscorecards.dev/projects/github.com/urllib3/urllib3/badge\" /></a>\n  <a href=\"https://slsa.dev\"><img alt=\"SLSA 3\" src=\"https://slsa.dev/images/gh-badge-level3.svg\" /></a>\n  <a href=\"https://bestpractices.coreinfrastructure.org/projects/6227\"><img alt=\"CII Best Practices\" src=\"https://bestpractices.coreinfrastructure.org/projects/6227/badge\" /></a>\n</p>\n\nurllib3 is a powerful, *user-friendly* HTTP client for Python. Much of the\nPython ecosystem already uses urllib3 and you should too.\nurllib3 brings many critical features that are missing from the Python\nstandard libraries:\n\n- Thread safety.\n- Connection pooling.\n- Client-side SSL/TLS verification.\n- File uploads with multipart encoding.\n- Helpers for retrying requests and dealing with HTTP redirects.\n- Support for gzip, deflate, brotli, and zstd encoding.\n- Proxy support for HTTP and SOCKS.\n- 100% test coverage.\n\nurllib3 is powerful and easy to use:\n\n```python3\n>>> import urllib3\n>>> resp = urllib3.request(\"GET\", \"http://httpbin.org/robots.txt\")\n>>> resp.status\n200\n>>> resp.data\nb\"User-agent: *\\nDisallow: /deny\\n\"\n```\n\n## Installing\n\nurllib3 can be installed with [pip](https://pip.pypa.io):\n\n```bash\n$ python -m pip install urllib3\n```\n\nAlternatively, you can grab the latest source code from [GitHub](https://github.com/urllib3/urllib3):\n\n```bash\n$ git clone https://github.com/urllib3/urllib3.git\n$ cd urllib3\n$ pip install .\n```\n\n\n## Documentation\n\nurllib3 has usage and reference documentation at [urllib3.readthedocs.io](https://urllib3.readthedocs.io).\n\n\n## Community\n\nurllib3 has a [community Discord channel](https://discord.gg/urllib3) for asking questions and\ncollaborating with other contributors. Drop by and say hello \ud83d\udc4b\n\n\n## Contributing\n\nurllib3 happily accepts contributions. Please see our\n[contributing documentation](https://urllib3.readthedocs.io/en/latest/contributing.html)\nfor some tips on getting started.\n\n\n## Security Disclosures\n\nTo report a security vulnerability, please use the\n[Tidelift security contact](https://tidelift.com/security).\nTidelift will coordinate the fix and disclosure with maintainers.\n\n\n## Maintainers\n\n- Lead: [@illia-v](https://github.com/illia-v) (Illia Volochii)\n- [@sethmlarson](https://github.com/sethmlarson) (Seth M. Larson)\n- [@pquentin](https://github.com/pquentin) (Quentin Pradet)\n- [@theacodes](https://github.com/theacodes) (Thea Flowers)\n- [@haikuginger](https://github.com/haikuginger) (Jess Shapiro)\n- [@lukasa](https://github.com/lukasa) (Cory Benfield)\n- [@sigmavirus24](https://github.com/sigmavirus24) (Ian Stapleton Cordasco)\n- [@shazow](https://github.com/shazow) (Andrey Petrov)\n\n\ud83d\udc4b\n\n\n## Sponsorship\n\nIf your company benefits from this library, please consider [sponsoring its\ndevelopment](https://urllib3.readthedocs.io/en/latest/sponsors.html).\n\n\n## For Enterprise\n\nProfessional support for urllib3 is available as part of the [Tidelift\nSubscription][1].  Tidelift gives software development teams a single source for\npurchasing and maintaining their software, with professional grade assurances\nfrom the experts who know it best, while seamlessly integrating with existing\ntools.\n\n[1]: https://tidelift.com/subscription/pkg/pypi-urllib3?utm_source=pypi-urllib3&utm_medium=referral&utm_campaign=readme\n",
      "scraped_at": 1756988946.6935472
    },
    {
      "repo": "urllib3/urllib3",
      "filename": "noxfile.py",
      "path": "noxfile.py",
      "content": "from __future__ import annotations\n\nimport os\nimport re\nimport shutil\nimport sys\nfrom pathlib import Path\n\nimport nox\n\nnox.options.error_on_missing_interpreters = True\nnox.options.default_venv_backend = \"uv\"\n\n\ndef tests_impl(\n    session: nox.Session,\n    extras: str = \"socks,brotli,zstd,h2\",\n    # hypercorn dependency h2 compares bytes and strings\n    # https://github.com/python-hyper/h2/issues/1236\n    byte_string_comparisons: bool = False,\n    integration: bool = False,\n    pytest_extra_args: list[str] = [],\n    dependency_group: str = \"dev\",\n) -> None:\n    # Retrieve sys info from the Python implementation under test\n    # to avoid enabling memray when nox runs under CPython but tests PyPy\n    session_python_info = session.run(\n        \"python\",\n        \"-c\",\n        \"import sys; print(sys.implementation.name, sys.version_info.releaselevel)\",\n        silent=True,\n    ).strip()  # type: ignore[union-attr] # mypy doesn't know that silent=True  will return a string\n    implementation_name, release_level = session_python_info.split(\" \")\n\n    # Install deps and the package itself.\n    session.run_install(\n        \"uv\",\n        \"sync\",\n        \"--frozen\",\n        \"--group\",\n        dependency_group,\n        *(f\"--extra={extra}\" for extra in (extras.split(\",\") if extras else ())),\n    )\n    # Show the uv version.\n    session.run(\"uv\", \"--version\")\n    # Print the Python version and bytesize.\n    session.run(\"python\", \"--version\")\n    session.run(\"python\", \"-c\", \"import struct; print(struct.calcsize('P') * 8)\")\n    # Print OpenSSL information.\n    session.run(\"python\", \"-m\", \"OpenSSL.debug\")\n\n    memray_supported = True\n    if implementation_name != \"cpython\" or release_level != \"final\":\n        memray_supported = False\n    elif sys.platform == \"win32\":\n        memray_supported = False\n\n    # Environment variables being passed to the pytest run.\n    pytest_session_envvars = {\n        \"PYTHONWARNINGS\": \"always::DeprecationWarning\",\n        \"COVERAGE_CORE\": \"sysmon\",\n    }\n\n    # Inspired from https://hynek.me/articles/ditch-codecov-python/\n    # We use parallel mode and then combine in a later CI step\n    session.run(\n        \"python\",\n        *((\"-bb\",) if byte_string_comparisons else ()),\n        \"-m\",\n        \"coverage\",\n        \"run\",\n        \"--parallel-mode\",\n        \"-m\",\n        \"pytest\",\n        *(\"--memray\", \"--hide-memray-summary\") if memray_supported else (),\n        \"-v\",\n        \"-ra\",\n        *((\"--integration\",) if integration else ()),\n        \"--tb=native\",\n        \"--durations=10\",\n        \"--strict-config\",\n        \"--strict-markers\",\n        \"--disable-socket\",\n        \"--allow-unix-socket\",\n        \"--allow-hosts=localhost,127.0.0.1,::1,127.0.0.0,240.0.0.0\",  # See `TARPIT_HOST`\n        *pytest_extra_args,\n        *(session.posargs or (\"test/\",)),\n        env=pytest_session_envvars,\n    )\n\n\n@nox.session(\n    python=[\n        \"3.9\",\n        \"3.10\",\n        \"3.11\",\n        \"3.12\",\n        \"3.13\",\n        \"3.14\",\n        \"pypy3.10\",\n        \"pypy3.11\",\n    ]\n)\ndef test(session: nox.Session) -> None:\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    tests_impl(session)\n\n\n@nox.session(python=\"3\")\ndef test_integration(session: nox.Session) -> None:\n    \"\"\"Run integration tests\"\"\"\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    tests_impl(session, integration=True)\n\n\n@nox.session(python=\"3\")\ndef test_brotlipy(session: nox.Session) -> None:\n    \"\"\"Check that if 'brotlipy' is installed instead of 'brotli' or\n    'brotlicffi' that we still don't blow up.\n    \"\"\"\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    session.install(\"brotlipy\")\n    tests_impl(session, extras=\"socks\", byte_string_comparisons=False)\n\n\ndef git_clone(session: nox.Session, git_url: str) -> None:\n    \"\"\"We either clone the target repository or if already exist\n    simply reset the state and pull.\n    \"\"\"\n    expected_directory = git_url.split(\"/\")[-1]\n\n    if expected_directory.endswith(\".git\"):\n        expected_directory = expected_directory[:-4]\n\n    if not os.path.isdir(expected_directory):\n        session.run(\"git\", \"clone\", \"--depth\", \"1\", git_url, external=True)\n    else:\n        session.run(\n            \"git\", \"-C\", expected_directory, \"reset\", \"--hard\", \"HEAD\", external=True\n        )\n        session.run(\"git\", \"-C\", expected_directory, \"pull\", external=True)\n\n\n@nox.session(venv_backend=\"virtualenv\")  # botocore fails with uv\ndef downstream_botocore(session: nox.Session) -> None:\n    root = os.getcwd()\n    tmp_dir = session.create_tmp()\n\n    session.cd(tmp_dir)\n    git_clone(session, \"https://github.com/boto/botocore\")\n    session.chdir(\"botocore\")\n    session.run(\"git\", \"rev-parse\", \"HEAD\", external=True)\n    session.run(\"python\", \"scripts/ci/install\")\n\n    session.cd(root)\n    session.install(\".\", silent=False)\n    session.cd(f\"{tmp_dir}/botocore\")\n\n    session.run(\"python\", \"-c\", \"import urllib3; print(urllib3.__version__)\")\n    session.run(\"python\", \"scripts/ci/run-tests\")\n\n\n@nox.session()\ndef downstream_requests(session: nox.Session) -> None:\n    root = os.getcwd()\n    tmp_dir = session.create_tmp()\n\n    session.cd(tmp_dir)\n    git_clone(session, \"https://github.com/psf/requests\")\n    session.chdir(\"requests\")\n    session.run(\"git\", \"rev-parse\", \"HEAD\", external=True)\n    session.install(\".[socks]\", silent=False)\n    session.install(\"-r\", \"requirements-dev.txt\", silent=False)\n\n    session.cd(root)\n    session.install(\".\", silent=False)\n    session.cd(f\"{tmp_dir}/requests\")\n\n    session.run(\"python\", \"-c\", \"import urllib3; print(urllib3.__version__)\")\n    session.run(\"pytest\", \"tests\")\n\n\n@nox.session()\ndef format(session: nox.Session) -> None:\n    \"\"\"Run code formatters.\"\"\"\n    lint(session)\n\n\n@nox.session(python=\"3.12\")\ndef lint(session: nox.Session) -> None:\n    session.install(\"pre-commit\")\n    session.run(\"pre-commit\", \"run\", \"--all-files\")\n\n    mypy(session)\n\n\n@nox.session(python=\"3.12\")\ndef pyodideconsole(session: nox.Session) -> None:\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    # build wheel into dist folder\n    # Run build and capture output\n    build_output = session.run(\"uv\", \"run\", \"-m\", \"build\", \"--wheel\", silent=True)\n    assert build_output\n\n    # Extract wheel name using regex\n    wheel_match = re.search(r\"urllib3-[^\\s]+\\.whl\", build_output)\n    assert wheel_match\n    wheel_name = wheel_match.group(0)\n\n    # Read template and replace wheel name\n    template_path = Path(\"test/contrib/emscripten/templates/pyodide-console.html\")\n    html_content = template_path.read_text()\n    html_content = html_content.replace(\"{urllib3_wheel_name}.whl\", wheel_name)\n\n    # Write modified content to dist/index.html\n    dist_path = Path(\"dist\")\n    (dist_path / \"index.html\").write_text(html_content)\n\n    session.run(\"python\", \"-m\", \"http.server\", \"-d\", \"dist\", \"-b\", \"localhost\")\n\n\n@nox.session(python=\"3.12\")\n@nox.parametrize(\n    \"runner\", [\"node\", \"firefox\", \"chrome\"], ids=[\"node\", \"firefox\", \"chrome\"]\n)\ndef emscripten(session: nox.Session, runner: str) -> None:\n    \"\"\"Test on Emscripten with Pyodide & Chrome / Firefox / Node.js\"\"\"\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    if runner == \"node\":\n        print(\n            \"Node version:\",\n            session.run(\"node\", \"--version\", silent=True, external=True),\n        )\n    # make sure we have a dist dir for pyodide\n    dist_dir = None\n    if \"PYODIDE_ROOT\" in os.environ:\n        # we have a pyodide build tree checked out\n        # use the dist directory from that\n        dist_dir = Path(os.environ[\"PYODIDE_ROOT\"]) / \"dist\"\n    else:\n        # we don't have a build tree\n        pyodide_version = \"0.28.1\"\n\n        pyodide_artifacts_path = Path(session.cache_dir) / f\"pyodide-{pyodide_version}\"\n        if not pyodide_artifacts_path.exists():\n            print(\"Fetching pyodide build artifacts\")\n            session.run(\n                \"curl\",\n                \"-L\",\n                f\"https://github.com/pyodide/pyodide/releases/download/{pyodide_version}/pyodide-{pyodide_version}.tar.bz2\",\n                \"--output-dir\",\n                session.cache_dir,\n                \"-O\",\n                external=True,\n            )\n            pyodide_artifacts_path.mkdir(parents=True)\n            session.run(\n                \"tar\",\n                \"-xjf\",\n                f\"{pyodide_artifacts_path}.tar.bz2\",\n                \"-C\",\n                str(pyodide_artifacts_path),\n                \"--strip-components\",\n                \"1\",\n                external=True,\n            )\n\n        dist_dir = pyodide_artifacts_path\n    session.run(\"uv\", \"run\", \"-m\", \"build\")\n    assert dist_dir is not None\n    assert dist_dir.exists()\n    tests_impl(\n        session,\n        extras=\"\",\n        pytest_extra_args=[\n            \"--runtime\",\n            f\"{runner}-no-host\",\n            \"--dist-dir\",\n            str(dist_dir),\n            \"test/contrib/emscripten\",\n            \"-v\",\n        ],\n        dependency_group=\"emscripten\",\n    )\n\n\n@nox.session(python=\"3.12\")\ndef mypy(session: nox.Session) -> None:\n    \"\"\"Run mypy.\"\"\"\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    session.run_install(\"uv\", \"sync\", \"--frozen\", \"--only-group\", \"mypy\")\n    session.install(\".\")\n    session.run(\"mypy\", \"--version\")\n    session.run(\n        \"mypy\",\n        \"-p\",\n        \"dummyserver\",\n        \"-m\",\n        \"noxfile\",\n        \"-p\",\n        \"urllib3\",\n        \"-p\",\n        \"test\",\n    )\n\n\n@nox.session\ndef docs(session: nox.Session) -> None:\n    session.env[\"UV_PROJECT_ENVIRONMENT\"] = session.virtualenv.location\n    session.run_install(\n        \"uv\",\n        \"sync\",\n        \"--frozen\",\n        \"--group\",\n        \"docs\",\n        \"--extra\",\n        \"socks\",\n        \"--extra\",\n        \"brotli\",\n        \"--extra\",\n        \"zstd\",\n    )\n\n    session.chdir(\"docs\")\n    if os.path.exists(\"_build\"):\n        shutil.rmtree(\"_build\")\n    session.run(\"sphinx-build\", \"-b\", \"html\", \"-W\", \".\", \"_build/html\")\n",
      "scraped_at": 1756988947.7072332
    },
    {
      "repo": "encode/httpx",
      "filename": "CHANGELOG.md",
      "path": "CHANGELOG.md",
      "content": "# Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/).\n\n## [UNRELEASED]\n\n### Removed\n\n* Drop support for Python 3.8\n\n## 0.28.1 (6th December, 2024)\n\n* Fix SSL case where `verify=False` together with client side certificates.\n \n## 0.28.0 (28th November, 2024)\n\nBe aware that the default *JSON request bodies now use a more compact representation*. This is generally considered a prefered style, tho may require updates to test suites.\n\nThe 0.28 release includes a limited set of deprecations...\n\n**Deprecations**:\n\nWe are working towards a simplified SSL configuration API.\n\n*For users of the standard `verify=True` or `verify=False` cases, or `verify=<ssl_context>` case this should require no changes. The following cases have been deprecated...*\n\n* The `verify` argument as a string argument is now deprecated and will raise warnings.\n* The `cert` argument is now deprecated and will raise warnings.\n\nOur revised [SSL documentation](docs/advanced/ssl.md) covers how to implement the same behaviour with a more constrained API.\n\n**The following changes are also included**:\n\n* The deprecated `proxies` argument has now been removed.\n* The deprecated `app` argument has now been removed.\n* JSON request bodies use a compact representation. (#3363)\n* Review URL percent escape sets, based on WHATWG spec. (#3371, #3373)\n* Ensure `certifi` and `httpcore` are only imported if required. (#3377)\n* Treat `socks5h` as a valid proxy scheme. (#3178)\n* Cleanup `Request()` method signature in line with `client.request()` and `httpx.request()`. (#3378)\n* Bugfix: When passing `params={}`, always strictly update rather than merge with an existing querystring. (#3364)\n\n## 0.27.2 (27th August, 2024)\n\n### Fixed\n\n* Reintroduced supposedly-private `URLTypes` shortcut. (#2673)\n\n## 0.27.1 (27th August, 2024)\n\n### Added\n\n* Support for `zstd` content decoding using the python `zstandard` package is added. Installable using `httpx[zstd]`. (#3139)\n\n### Fixed\n\n* Improved error messaging for `InvalidURL` exceptions. (#3250)\n* Fix `app` type signature in `ASGITransport`. (#3109)\n\n## 0.27.0 (21st February, 2024)\n\n### Deprecated\n\n* The `app=...` shortcut has been deprecated. Use the explicit style of `transport=httpx.WSGITransport()` or `transport=httpx.ASGITransport()` instead.\n\n### Fixed\n\n* Respect the `http1` argument while configuring proxy transports. (#3023)\n* Fix RFC 2069 mode digest authentication. (#3045)\n\n## 0.26.0 (20th December, 2023)\n\n### Added\n\n* The `proxy` argument was added. You should use the `proxy` argument instead of the deprecated `proxies`, or use `mounts=` for more complex configurations. (#2879)\n\n### Deprecated\n\n* The `proxies` argument is now deprecated. It will still continue to work, but it will be removed in the future. (#2879)\n\n### Fixed\n\n* Fix cases of double escaping of URL path components. Allow / as a safe character in the query portion. (#2990)\n* Handle `NO_PROXY` envvar cases when a fully qualified URL is supplied as the value. (#2741)\n* Allow URLs where username or password contains unescaped '@'. (#2986)\n* Ensure ASGI `raw_path` does not include URL query component. (#2999)\n* Ensure `Response.iter_text()` cannot yield empty strings. (#2998)\n\n## 0.25.2 (24th November, 2023)\n\n### Added\n\n* Add missing type hints to few `__init__()` methods. (#2938)\n\n## 0.25.1 (3rd November, 2023)\n\n### Added\n\n* Add support for Python 3.12. (#2854)\n* Add support for httpcore 1.0 (#2885)\n\n### Fixed\n\n* Raise `ValueError` on `Response.encoding` being set after `Response.text` has been accessed. (#2852)\n\n## 0.25.0 (11th September, 2023)\n\n### Removed\n\n* Drop support for Python 3.7. (#2813)\n\n### Added\n\n* Support HTTPS proxies. (#2845)\n* Change the type of `Extensions` from `Mapping[Str, Any]` to `MutableMapping[Str, Any]`. (#2803)\n* Add `socket_options` argument to `httpx.HTTPTransport` and `httpx.AsyncHTTPTransport` classes. (#2716)\n* The `Response.raise_for_status()` method now returns the response instance. For example: `data = httpx.get('...').raise_for_status().json()`. (#2776)\n\n### Fixed\n\n* Return `500` error response instead of exceptions when `raise_app_exceptions=False` is set on `ASGITransport`. (#2669)\n* Ensure all `WSGITransport` environs have a `SERVER_PROTOCOL`. (#2708)\n* Always encode forward slashes as `%2F` in query parameters (#2723)\n* Use Mozilla documentation instead of `httpstatuses.com` for HTTP error reference (#2768)\n\n## 0.24.1 (17th May, 2023)\n\n### Added\n\n* Provide additional context in some `InvalidURL` exceptions. (#2675)\n\n### Fixed\n\n* Fix optional percent-encoding behaviour. (#2671)\n* More robust checking for opening upload files in binary mode. (#2630)\n* Properly support IP addresses in `NO_PROXY` environment variable. (#2659)\n* Set default file for `NetRCAuth()` to `None` to use the stdlib default. (#2667)\n* Set logging request lines to INFO level for async requests, in line with sync requests. (#2656)\n* Fix which gen-delims need to be escaped for path/query/fragment components in URL. (#2701)\n\n## 0.24.0 (6th April, 2023)\n\n### Changed\n\n* The logging behaviour has been changed to be more in-line with other standard Python logging usages. We no longer have a custom `TRACE` log level, and we no longer use the `HTTPX_LOG_LEVEL` environment variable to auto-configure logging. We now have a significant amount of `DEBUG` logging available at the network level. Full documentation is available at https://www.python-httpx.org/logging/ (#2547, encode/httpcore#648)\n* The `Response.iter_lines()` method now matches the stdlib behaviour and does not include the newline characters. It also resolves a performance issue. (#2423)\n* Query parameter encoding switches from using + for spaces and %2F for forward slash, to instead using %20 for spaces and treating forward slash as a safe, unescaped character. This differs from `requests`, but is in line with browser behavior in Chrome, Safari, and Firefox. Both options are RFC valid. (#2543)\n* NetRC authentication is no longer automatically handled, but is instead supported by an explicit `httpx.NetRCAuth()` authentication class. See the documentation at https://www.python-httpx.org/advanced/authentication/#netrc-authentication (#2525)\n\n### Removed\n\n* The `rfc3986` dependancy has been removed. (#2252)\n\n## 0.23.3 (4th January, 2023)\n\n### Fixed\n\n* Version 0.23.2 accidentally included stricter type checking on query parameters. This shouldn've have been included in a minor version bump, and is now reverted. (#2523, #2539)\n\n## 0.23.2 (2nd January, 2023)\n\n### Added\n\n* Support digest auth nonce counting to avoid multiple auth requests. (#2463)\n\n### Fixed\n\n* Multipart file uploads where the file length cannot be determine now use chunked transfer encoding, rather than loading the entire file into memory in order to determine the `Content-Length`. (#2382)\n* Raise `TypeError` if content is passed a dict-instance. (#2495)\n* Partially revert the API breaking change in 0.23.1, which removed `RawURL`. We continue to expose a `url.raw` property which is now a plain named-tuple. This API is still expected to be deprecated, but we will do so with a major version bump. (#2481)\n\n## 0.23.1 (18th November, 2022)\n\n**Note**: The 0.23.1 release should have used a proper version bump, rather than a minor point release.\nThere are API surface area changes that may affect some users.\nSee the \"Removed\" section of these release notes for details.\n\n### Added\n\n* Support for Python 3.11. (#2420)\n* Allow setting an explicit multipart boundary in `Content-Type` header. (#2278)\n* Allow `tuple` or `list` for multipart values, not just `list`. (#2355)\n* Allow `str` content for multipart upload files. (#2400)\n* Support connection upgrades. See https://www.encode.io/httpcore/extensions/#upgrade-requests\n\n### Fixed\n\n* Don't drop empty query parameters. (#2354)\n\n### Removed\n\n* Upload files *must* always be opened in binary mode. (#2400)\n* Drop `.read`/`.aread` from `SyncByteStream`/`AsyncByteStream`. (#2407)\n* Drop `RawURL`. (#2241)\n\n## 0.23.0 (23rd May, 2022)\n\n### Changed\n\n* Drop support for Python 3.6. (#2097)\n* Use `utf-8` as the default character set, instead of falling back to `charset-normalizer` for auto-detection. To enable automatic character set detection, see [the documentation](https://www.python-httpx.org/advanced/text-encodings/#using-auto-detection). (#2165)\n\n### Fixed\n\n* Fix `URL.copy_with` for some oddly formed URL cases. (#2185)\n* Digest authentication should use case-insensitive comparison for determining which algorithm is being used. (#2204)\n* Fix console markup escaping in command line client. (#1866)\n* When files are used in multipart upload, ensure we always seek to the start of the file. (#2065)\n* Ensure that `iter_bytes` never yields zero-length chunks. (#2068)\n* Preserve `Authorization` header for redirects that are to the same origin, but are an `http`-to-`https` upgrade. (#2074)\n* When responses have binary output, don't print the output to the console in the command line client. Use output like `<16086 bytes of binary data>` instead. (#2076)\n* Fix display of `--proxies` argument in the command line client help. (#2125)\n* Close responses when task cancellations occur during stream reading. (#2156)\n* Fix type error on accessing `.request` on `HTTPError` exceptions. (#2158)\n\n## 0.22.0 (26th January, 2022)\n\n### Added\n\n* Support for [the SOCKS5 proxy protocol](https://www.python-httpx.org/advanced/proxies/#socks) via [the `socksio` package](https://github.com/sethmlarson/socksio). (#2034)\n* Support for custom headers in multipart/form-data requests (#1936)\n\n### Fixed\n\n* Don't perform unreliable close/warning on `__del__` with unclosed clients. (#2026)\n* Fix `Headers.update(...)` to correctly handle repeated headers (#2038)\n\n## 0.21.3 (6th January, 2022)\n\n### Fixed\n\n* Fix streaming uploads using `SyncByteStream` or `AsyncByteStream`. Regression in 0.21.2. (#2016)\n\n## 0.21.2 (5th January, 2022)\n\n### Fixed\n\n* HTTP/2 support for tunnelled proxy cases. (#2009)\n* Improved the speed of large file uploads. (#1948)\n\n## 0.21.1 (16th November, 2021)\n\n### Fixed\n\n* The `response.url` property is now correctly annotated as `URL`, instead of `Optional[URL]`. (#1940)\n\n## 0.21.0 (15th November, 2021)\n\nThe 0.21.0 release integrates against a newly redesigned `httpcore` backend.\n\nBoth packages ought to automatically update to the required versions, but if you are\nseeing any issues, you should ensure that you have `httpx==0.21.*` and `httpcore==0.14.*` installed.\n\n### Added\n\n* The command-line client will now display connection information when `-v/--verbose` is used.\n* The command-line client will now display server certificate information when `-v/--verbose` is used.\n* The command-line client is now able to properly detect if the outgoing request\nshould be formatted as HTTP/1.1 or HTTP/2, based on the result of the HTTP/2 negotiation.\n\n### Removed\n\n* Curio support is no longer currently included. Please get in touch if you require this, so that we can assess priorities.\n\n## 0.20.0 (13th October, 2021)\n\nThe 0.20.0 release adds an integrated command-line client, and also includes some\ndesign changes. The most notable of these is that redirect responses are no longer\nautomatically followed, unless specifically requested.\n\nThis design decision prioritises a more explicit approach to redirects, in order\nto avoid code that unintentionally issues multiple requests as a result of\nmisconfigured URLs.\n\nFor example, previously a client configured to send requests to `http://api.github.com/`\nwould end up sending every API request twice, as each request would be redirected to `https://api.github.com/`.\n\nIf you do want auto-redirect behaviour, you can enable this either by configuring\nthe client instance with `Client(follow_redirects=True)`, or on a per-request\nbasis, with `.get(..., follow_redirects=True)`.\n\nThis change is a classic trade-off between convenience and precision, with no \"right\"\nanswer. See [discussion #1785](https://github.com/encode/httpx/discussions/1785) for more\ncontext.\n\nThe other major design change is an update to the Transport API, which is the low-level\ninterface against which requests are sent. Previously this interface used only primitive\ndatastructures, like so...\n\n```python\n(status_code, headers, stream, extensions) = transport.handle_request(method, url, headers, stream, extensions)\ntry\n    ...\nfinally:\n    stream.close()\n```\n\nNow the interface is much simpler...\n\n```python\nresponse = transport.handle_request(request)\ntry\n    ...\nfinally:\n    response.close()\n```\n\n### Changed\n\n* The `allow_redirects` flag is now `follow_redirects` and defaults to `False`.\n* The `raise_for_status()` method will now raise an exception for any responses\n  except those with 2xx status codes. Previously only 4xx and 5xx status codes\n  would result in an exception.\n* The low-level transport API changes to the much simpler `response = transport.handle_request(request)`.\n* The `client.send()` method no longer accepts a `timeout=...` argument, but the\n  `client.build_request()` does. This required by the signature change of the\n  Transport API. The request timeout configuration is now stored on the request\n  instance, as `request.extensions['timeout']`.\n\n### Added\n\n* Added the `httpx` command-line client.\n* Response instances now include `.is_informational`, `.is_success`, `.is_redirect`, `.is_client_error`, and `.is_server_error`\n  properties for checking 1xx, 2xx, 3xx, 4xx, and 5xx response types. Note that the behaviour of `.is_redirect` is slightly different in that it now returns True for all 3xx responses, in order to allow for a consistent set of properties onto the different HTTP status code types. The `response.has_redirect_location` location may be used to determine responses with properly formed URL redirects.\n\n### Fixed\n\n* `response.iter_bytes()` no longer raises a ValueError when called on a response with no content. (Pull #1827)\n* The `'wsgi.error'` configuration now defaults to `sys.stderr`, and is corrected to be a `TextIO` interface, not a `BytesIO` interface. Additionally, the WSGITransport now accepts a `wsgi_error` configuration. (Pull #1828)\n* Follow the WSGI spec by properly closing the iterable returned by the application. (Pull #1830)\n\n## 0.19.0 (19th August, 2021)\n\n### Added\n\n* Add support for `Client(allow_redirects=<bool>)`. (Pull #1790)\n* Add automatic character set detection, when no `charset` is included in the response `Content-Type` header. (Pull #1791)\n\n### Changed\n\n* Event hooks are now also called for any additional redirect or auth requests/responses. (Pull #1806)\n* Strictly enforce that upload files must be opened in binary mode. (Pull #1736)\n* Strictly enforce that client instances can only be opened and closed once, and cannot be re-opened. (Pull #1800)\n* Drop `mode` argument from `httpx.Proxy(..., mode=...)`. (Pull #1795)\n\n## 0.18.2 (17th June, 2021)\n\n### Added\n\n* Support for Python 3.10. (Pull #1687)\n* Expose `httpx.USE_CLIENT_DEFAULT`, used as the default to `auth` and `timeout` parameters in request methods. (Pull #1634)\n* Support [HTTP/2 \"prior knowledge\"](https://python-hyper.org/projects/hyper-h2/en/v2.3.1/negotiating-http2.html#prior-knowledge), using `httpx.Client(http1=False, http2=True)`. (Pull #1624)\n\n### Fixed\n\n* Clean up some cases where warnings were being issued. (Pull #1687)\n* Prefer Content-Length over Transfer-Encoding: chunked for content=<file-like> cases. (Pull #1619)\n\n## 0.18.1 (29th April, 2021)\n\n### Changed\n\n* Update brotli support to use the `brotlicffi` package (Pull #1605)\n* Ensure that `Request(..., stream=...)` does not auto-generate any headers on the request instance. (Pull #1607)\n\n### Fixed\n\n* Pass through `timeout=...` in top-level httpx.stream() function. (Pull #1613)\n* Map httpcore transport close exceptions to httpx exceptions. (Pull #1606)\n\n## 0.18.0 (27th April, 2021)\n\nThe 0.18.x release series formalises our low-level Transport API, introducing the base classes `httpx.BaseTransport` and `httpx.AsyncBaseTransport`.\n\nSee the \"[Custom transports](https://www.python-httpx.org/advanced/transports/#custom-transports)\" documentation and the [`httpx.BaseTransport.handle_request()`](https://github.com/encode/httpx/blob/397aad98fdc8b7580a5fc3e88f1578b4302c6382/httpx/_transports/base.py#L77-L147) docstring for more complete details on implementing custom transports.\n\nPull request #1522 includes a checklist of differences from the previous `httpcore` transport API, for developers implementing custom transports.\n\nThe following API changes have been issuing deprecation warnings since 0.17.0 onwards, and are now fully deprecated...\n\n* You should now use httpx.codes consistently instead of httpx.StatusCodes.\n* Use limits=... instead of pool_limits=....\n* Use proxies={\"http://\": ...} instead of proxies={\"http\": ...} for scheme-specific mounting.\n\n### Changed\n\n* Transport instances now inherit from `httpx.BaseTransport` or `httpx.AsyncBaseTransport`,\n  and should implement either the `handle_request` method or `handle_async_request` method. (Pull #1522, #1550)\n* The `response.ext` property and `Response(ext=...)` argument are now named `extensions`. (Pull #1522)\n* The recommendation to not use `data=<bytes|str|bytes (a)iterator>` in favour of `content=<bytes|str|bytes (a)iterator>` has now been escalated to a deprecation warning. (Pull #1573)\n* Drop `Response(on_close=...)` from API, since it was a bit of leaking implementation detail. (Pull #1572)\n* When using a client instance, cookies should always be set on the client, rather than on a per-request basis. We prefer enforcing a stricter API here because it provides clearer expectations around cookie persistence, particularly when redirects occur. (Pull #1574)\n* The runtime exception `httpx.ResponseClosed` is now named `httpx.StreamClosed`. (#1584)\n* The `httpx.QueryParams` model now presents an immutable interface. There is a discussion on [the design and motivation here](https://github.com/encode/httpx/discussions/1599). Use `client.params = client.params.merge(...)` instead of `client.params.update(...)`. The basic query manipulation methods are `query.set(...)`, `query.add(...)`, and `query.remove()`. (#1600)\n\n### Added\n\n* The `Request` and `Response` classes can now be serialized using pickle. (#1579)\n* Handle `data={\"key\": [None|int|float|bool]}` cases. (Pull #1539)\n* Support `httpx.URL(**kwargs)`, for example `httpx.URL(scheme=\"https\", host=\"www.example.com\", path=\"/')`, or `httpx.URL(\"https://www.example.com/\", username=\"tom@gmail.com\", password=\"123 456\")`. (Pull #1601)\n* Support `url.copy_with(params=...)`. (Pull #1601)\n* Add `url.params` parameter, returning an immutable `QueryParams` instance. (Pull #1601)\n* Support query manipulation methods on the URL class. These are `url.copy_set_param()`, `url.copy_add_param()`, `url.copy_remove_param()`, `url.copy_merge_params()`. (Pull #1601)\n* The `httpx.URL` class now performs port normalization, so `:80` ports are stripped from `http` URLs and `:443` ports are stripped from `https` URLs. (Pull #1603)\n* The `URL.host` property returns unicode strings for internationalized domain names. The `URL.raw_host` property returns byte strings with IDNA escaping applied. (Pull #1590)\n\n### Fixed\n\n* Fix Content-Length for cases of `files=...` where unicode string is used as the file content. (Pull #1537)\n* Fix some cases of merging relative URLs against `Client(base_url=...)`. (Pull #1532)\n* The `request.content` attribute is now always available except for streaming content, which requires an explicit `.read()`. (Pull #1583)\n\n## 0.17.1 (March 15th, 2021)\n\n### Fixed\n\n* Type annotation on `CertTypes` allows `keyfile` and `password` to be optional. (Pull #1503)\n* Fix httpcore pinned version. (Pull #1495)\n\n## 0.17.0 (February 28th, 2021)\n\n### Added\n\n* Add `httpx.MockTransport()`, allowing to mock out a transport using pre-determined responses. (Pull #1401, Pull #1449)\n* Add `httpx.HTTPTransport()` and `httpx.AsyncHTTPTransport()` default transports. (Pull #1399)\n* Add mount API support, using `httpx.Client(mounts=...)`. (Pull #1362)\n* Add `chunk_size` parameter to `iter_raw()`, `iter_bytes()`, `iter_text()`. (Pull #1277)\n* Add `keepalive_expiry` parameter to `httpx.Limits()` configuration. (Pull #1398)\n* Add repr to `httpx.Cookies` to display available cookies. (Pull #1411)\n* Add support for `params=<tuple>` (previously only `params=<list>` was supported). (Pull #1426)\n\n### Fixed\n\n* Add missing `raw_path` to ASGI scope. (Pull #1357)\n* Tweak `create_ssl_context` defaults to use `trust_env=True`. (Pull #1447)\n* Properly URL-escape WSGI `PATH_INFO`. (Pull #1391)\n* Properly set default ports in WSGI transport. (Pull #1469)\n* Properly encode slashes when using `base_url`. (Pull #1407)\n* Properly map exceptions in `request.aclose()`. (Pull #1465)\n\n## 0.16.1 (October 8th, 2020)\n\n### Fixed\n\n* Support literal IPv6 addresses in URLs. (Pull #1349)\n* Force lowercase headers in ASGI scope dictionaries. (Pull #1351)\n\n## 0.16.0 (October 6th, 2020)\n\n### Changed\n\n* Preserve HTTP header casing. (Pull #1338, encode/httpcore#216, python-hyper/h11#104)\n* Drop `response.next()` and `response.anext()` methods in favour of `response.next_request` attribute. (Pull #1339)\n* Closed clients now raise a runtime error if attempting to send a request. (Pull #1346)\n\n### Added\n\n* Add Python 3.9 to officially supported versions.\n* Type annotate `__enter__`/`__exit__`/`__aenter__`/`__aexit__` in a way that supports subclasses of `Client` and `AsyncClient`. (Pull #1336)\n\n## 0.15.5 (October 1st, 2020)\n\n### Added\n\n* Add `response.next_request` (Pull #1334)\n\n## 0.15.4 (September 25th, 2020)\n\n### Added\n\n* Support direct comparisons between `Headers` and dicts or lists of two-tuples. Eg. `assert response.headers == {\"Content-Length\": 24}` (Pull #1326)\n\n### Fixed\n\n* Fix automatic `.read()` when `Response` instances are created with `content=<str>` (Pull #1324)\n\n## 0.15.3 (September 24th, 2020)\n\n### Fixed\n\n* Fixed connection leak in async client due to improper closing of response streams. (Pull #1316)\n\n## 0.15.2 (September 23nd, 2020)\n\n### Fixed\n\n* Fixed `response.elapsed` property. (Pull #1313)\n* Fixed client authentication interaction with `.stream()`. (Pull #1312)\n\n## 0.15.1 (September 23nd, 2020)\n\n### Fixed\n\n* ASGITransport now properly applies URL decoding to the `path` component, as-per the ASGI spec. (Pull #1307)\n\n## 0.15.0 (September 22nd, 2020)\n\n### Added\n\n* Added support for curio. (Pull https://github.com/encode/httpcore/pull/168)\n* Added support for event hooks. (Pull #1246)\n* Added support for authentication flows which require either sync or async I/O. (Pull #1217)\n* Added support for monitoring download progress with `response.num_bytes_downloaded`. (Pull #1268)\n* Added `Request(content=...)` for byte content, instead of overloading `Request(data=...)` (Pull #1266)\n* Added support for all URL components as parameter names when using `url.copy_with(...)`. (Pull #1285)\n* Neater split between automatically populated headers on `Request` instances, vs default `client.headers`. (Pull #1248)\n* Unclosed `AsyncClient` instances will now raise warnings if garbage collected. (Pull #1197)\n* Support `Response(content=..., text=..., html=..., json=...)` for creating usable response instances in code. (Pull #1265, #1297)\n* Support instantiating requests from the low-level transport API. (Pull #1293)\n* Raise errors on invalid URL types. (Pull #1259)\n\n### Changed\n\n* Cleaned up expected behaviour for URL escaping. `url.path` is now URL escaped. (Pull #1285)\n* Cleaned up expected behaviour for bytes vs str in URL components. `url.userinfo` and `url.query` are not URL escaped, and so return bytes. (Pull #1285)\n* Drop `url.authority` property in favour of `url.netloc`, since \"authority\" was semantically incorrect. (Pull #1285)\n* Drop `url.full_path` property in favour of `url.raw_path`, for better consistency with other parts of the API. (Pull #1285)\n* No longer use the `chardet` library for auto-detecting charsets, instead defaulting to a simpler approach when no charset is specified. (#1269)\n\n### Fixed\n\n* Swapped ordering of redirects and authentication flow. (Pull #1267)\n* `.netrc` lookups should use host, not host+port. (Pull #1298)\n\n### Removed\n\n* The `URLLib3Transport` class no longer exists. We've published it instead as an example of [a custom transport class](https://gist.github.com/florimondmanca/d56764d78d748eb9f73165da388e546e). (Pull #1182)\n* Drop `request.timer` attribute, which was being used internally to set `response.elapsed`. (Pull #1249)\n* Drop `response.decoder` attribute, which was being used internally. (Pull #1276)\n* `Request.prepare()` is now a private method. (Pull #1284)\n* The `Headers.getlist()` method had previously been deprecated in favour of `Headers.get_list()`. It is now fully removed.\n* The `QueryParams.getlist()` method had previously been deprecated in favour of `QueryParams.get_list()`. It is now fully removed.\n* The `URL.is_ssl` property had previously been deprecated in favour of `URL.scheme == \"https\"`. It is now fully removed.\n* The `httpx.PoolLimits` class had previously been deprecated in favour of `httpx.Limits`. It is now fully removed.\n* The `max_keepalive` setting had previously been deprecated in favour of the more explicit `max_keepalive_connections`. It is now fully removed.\n* The verbose `httpx.Timeout(5.0, connect_timeout=60.0)` style had previously been deprecated in favour of `httpx.Timeout(5.0, connect=60.0)`. It is now fully removed.\n* Support for instantiating a timeout config missing some defaults, such as `httpx.Timeout(connect=60.0)`, had previously been deprecated in favour of enforcing a more explicit style, such as `httpx.Timeout(5.0, connect=60.0)`. This is now strictly enforced.\n\n## 0.14.3 (September 2nd, 2020)\n\n### Added\n\n* `http.Response()` may now be instantiated without a `request=...` parameter. Useful for some unit testing cases. (Pull #1238)\n* Add `103 Early Hints` and `425 Too Early` status codes. (Pull #1244)\n\n### Fixed\n\n* `DigestAuth` now handles responses that include multiple 'WWW-Authenticate' headers. (Pull #1240)\n* Call into transport `__enter__`/`__exit__` or `__aenter__`/`__aexit__` when client is used in a context manager style. (Pull #1218)\n\n## 0.14.2 (August 24th, 2020)\n\n### Added\n\n* Support `client.get(..., auth=None)` to bypass the default authentication on a clients. (Pull #1115)\n* Support `client.auth = ...` property setter. (Pull #1185)\n* Support `httpx.get(..., proxies=...)` on top-level request functions. (Pull #1198)\n* Display instances with nicer import styles. (Eg. <httpx.ReadTimeout ...>) (Pull #1155)\n* Support `cookies=[(key, value)]` list-of-two-tuples style usage. (Pull #1211)\n\n### Fixed\n\n* Ensure that automatically included headers on a request may be modified. (Pull #1205)\n* Allow explicit `Content-Length` header on streaming requests. (Pull #1170)\n* Handle URL quoted usernames and passwords properly. (Pull #1159)\n* Use more consistent default for `HEAD` requests, setting `allow_redirects=True`. (Pull #1183)\n* If a transport error occurs while streaming the response, raise an `httpx` exception, not the underlying `httpcore` exception. (Pull #1190)\n* Include the underlying `httpcore` traceback, when transport exceptions occur. (Pull #1199)\n\n## 0.14.1 (August 11th, 2020)\n\n### Added\n\n* The `httpx.URL(...)` class now raises `httpx.InvalidURL` on invalid URLs, rather than exposing the underlying `rfc3986` exception. If a redirect response includes an invalid 'Location' header, then a `RemoteProtocolError` exception is raised, which will be associated with the request that caused it. (Pull #1163)\n\n### Fixed\n\n* Handling multiple `Set-Cookie` headers became broken in the 0.14.0 release, and is now resolved. (Pull #1156)\n\n## 0.14.0 (August 7th, 2020)\n\nThe 0.14 release includes a range of improvements to the public API, intended on preparing for our upcoming 1.0 release.\n\n* Our HTTP/2 support is now fully optional. **You now need to use `pip install httpx[http2]` if you want to include the HTTP/2 dependencies.**\n* Our HSTS support has now been removed. Rewriting URLs from `http` to `https` if the host is on the HSTS list can be beneficial in avoiding roundtrips to incorrectly formed URLs, but on balance we've decided to remove this feature, on the principle of least surprise. Most programmatic clients do not include HSTS support, and for now we're opting to remove our support for it.\n* Our exception hierarchy has been overhauled. Most users will want to stick with their existing `httpx.HTTPError` usage, but we've got a clearer overall structure now. See https://www.python-httpx.org/exceptions/ for more details.\n\nWhen upgrading you should be aware of the following public API changes. Note that deprecated usages will currently continue to function, but will issue warnings.\n\n* You should now use `httpx.codes` consistently instead of `httpx.StatusCodes`.\n* Usage of `httpx.Timeout()` should now always include an explicit default. Eg. `httpx.Timeout(None, pool=5.0)`.\n* When using `httpx.Timeout()`, we now have more concisely named keyword arguments. Eg. `read=5.0`, instead of `read_timeout=5.0`.\n* Use `httpx.Limits()` instead of `httpx.PoolLimits()`, and `limits=...` instead of `pool_limits=...`.\n* The `httpx.Limits(max_keepalive=...)` argument is now deprecated in favour of a more explicit `httpx.Limits(max_keepalive_connections=...)`.\n* Keys used with `Client(proxies={...})` should now be in the style of `{\"http://\": ...}`, rather than `{\"http\": ...}`.\n* The multidict methods `Headers.getlist()` and `QueryParams.getlist()` are deprecated in favour of more consistent `.get_list()` variants.\n* The `URL.is_ssl` property is deprecated in favour of `URL.scheme == \"https\"`.\n* The `URL.join(relative_url=...)` method is now `URL.join(url=...)`. This change does not support warnings for the deprecated usage style.\n\nOne notable aspect of the 0.14.0 release is that it tightens up the public API for `httpx`, by ensuring that several internal attributes and methods have now become strictly private.\n\nThe following previously had nominally public names on the client, but were all undocumented and intended solely for internal usage. They are all now replaced with underscored names, and should not be relied on or accessed.\n\nThese changes should not affect users who have been working from the `httpx` documentation.\n\n* `.merge_url()`, `.merge_headers()`, `.merge_cookies()`, `.merge_queryparams()`\n* `.build_auth()`, `.build_redirect_request()`\n* `.redirect_method()`, `.redirect_url()`, `.redirect_headers()`, `.redirect_stream()`\n* `.send_handling_redirects()`, `.send_handling_auth()`, `.send_single_request()`\n* `.init_transport()`, `.init_proxy_transport()`\n* `.proxies`, `.transport`, `.netrc`, `.get_proxy_map()`\n\nSee pull requests #997, #1065, #1071.\n\nSome areas of API which were already on the deprecation path, and were raising warnings or errors in 0.13.x have now been escalated to being fully removed.\n\n* Drop `ASGIDispatch`, `WSGIDispatch`, which have been replaced by `ASGITransport`, `WSGITransport`.\n* Drop `dispatch=...`` on client, which has been replaced by `transport=...``\n* Drop `soft_limit`, `hard_limit`, which have been replaced by `max_keepalive` and `max_connections`.\n* Drop `Response.stream` and` `Response.raw`, which have been replaced by ``.aiter_bytes` and `.aiter_raw`.\n* Drop `proxies=<transport instance>` in favor of `proxies=httpx.Proxy(...)`.\n\nSee pull requests #1057, #1058.\n\n### Added\n\n* Added dedicated exception class `httpx.HTTPStatusError` for `.raise_for_status()` exceptions. (Pull #1072)\n* Added `httpx.create_ssl_context()` helper function. (Pull #996)\n* Support for proxy exclusions like `proxies={\"https://www.example.com\": None}`. (Pull #1099)\n* Support `QueryParams(None)` and `client.params = None`. (Pull #1060)\n\n### Changed\n\n* Use `httpx.codes` consistently in favour of `httpx.StatusCodes` which is placed into deprecation. (Pull #1088)\n* Usage of `httpx.Timeout()` should now always include an explicit default. Eg. `httpx.Timeout(None, pool=5.0)`. (Pull #1085)\n* Switch to more concise `httpx.Timeout()` keyword arguments. Eg. `read=5.0`, instead of `read_timeout=5.0`. (Pull #1111)\n* Use `httpx.Limits()` instead of `httpx.PoolLimits()`, and `limits=...` instead of `pool_limits=...`. (Pull #1113)\n* Keys used with `Client(proxies={...})` should now be in the style of `{\"http://\": ...}`, rather than `{\"http\": ...}`. (Pull #1127)\n* The multidict methods `Headers.getlist` and `QueryParams.getlist` are deprecated in favour of more consistent `.get_list()` variants. (Pull #1089)\n* `URL.port` becomes `Optional[int]`. Now only returns a port if one is explicitly included in the URL string. (Pull #1080)\n* The `URL(..., allow_relative=[bool])` parameter no longer exists. All URL instances may be relative. (Pull #1073)\n* Drop unnecessary `url.full_path = ...` property setter. (Pull #1069)\n* The `URL.join(relative_url=...)` method is now `URL.join(url=...)`. (Pull #1129)\n* The `URL.is_ssl` property is deprecated in favour of `URL.scheme == \"https\"`. (Pull #1128)\n\n### Fixed\n\n* Add missing `Response.next()` method. (Pull #1055)\n* Ensure all exception classes are exposed as public API. (Pull #1045)\n* Support multiple items with an identical field name in multipart encodings. (Pull #777)\n* Skip HSTS preloading on single-label domains. (Pull #1074)\n* Fixes for `Response.iter_lines()`. (Pull #1033, #1075)\n* Ignore permission errors when accessing `.netrc` files. (Pull #1104)\n* Allow bare hostnames in `HTTP_PROXY` etc... environment variables. (Pull #1120)\n* Settings `app=...` or `transport=...` bypasses any environment based proxy defaults. (Pull #1122)\n* Fix handling of `.base_url` when a path component is included in the base URL. (Pull #1130)\n\n---\n\n## 0.13.3 (May 29th, 2020)\n\n### Fixed\n\n* Include missing keepalive expiry configuration. (Pull #1005)\n* Improved error message when URL redirect has a custom scheme. (Pull #1002)\n\n## 0.13.2 (May 27th, 2020)\n\n### Fixed\n\n* Include explicit \"Content-Length: 0\" on POST, PUT, PATCH if no request body is used. (Pull #995)\n* Add `http2` option to `httpx.Client`. (Pull #982)\n* Tighten up API typing in places. (Pull #992, #999)\n\n## 0.13.1 (May 22nd, 2020)\n\n### Fixed\n\n* Fix pool options deprecation warning. (Pull #980)\n* Include `httpx.URLLib3ProxyTransport` in top-level API. (Pull #979)\n\n## 0.13.0 (May 22nd, 2020)\n\nThis release switches to `httpcore` for all the internal networking, which means:\n\n* We're using the same codebase for both our sync and async clients.\n* HTTP/2 support is now available with the sync client.\n* We no longer have a `urllib3` dependency for our sync client, although there is still an *optional* `URLLib3Transport` class.\n\nIt also means we've had to remove our UDS support, since maintaining that would have meant having to push back our work towards a 1.0 release, which isn't a trade-off we wanted to make.\n\nWe also now have [a public \"Transport API\"](https://www.python-httpx.org/advanced/transports/#custom-transports), which you can use to implement custom transport implementations against. This formalises and replaces our previously private \"Dispatch API\".\n\n### Changed\n\n* Use `httpcore` for underlying HTTP transport. Drop `urllib3` requirement. (Pull #804, #967)\n* Rename pool limit options from `soft_limit`/`hard_limit` to `max_keepalive`/`max_connections`. (Pull #968)\n* The previous private \"Dispatch API\" has now been promoted to a public \"Transport API\". When customizing the transport use `transport=...`. The `ASGIDispatch` and `WSGIDispatch` class naming is deprecated in favour of `ASGITransport` and `WSGITransport`. (Pull #963)\n\n### Added\n\n* Added `URLLib3Transport` class for optional `urllib3` transport support. (Pull #804, #963)\n* Streaming multipart uploads. (Pull #857)\n* Logging via HTTPCORE_LOG_LEVEL and HTTPX_LOG_LEVEL environment variables\nand TRACE level logging. (Pull encode/httpcore#79)\n\n### Fixed\n\n* Performance improvement in brotli decoder. (Pull #906)\n* Proper warning level of deprecation notice in `Response.stream` and `Response.raw`. (Pull #908)\n* Fix support for generator based WSGI apps. (Pull #887)\n* Reuse of connections on HTTP/2 in close concurrency situations. (Pull encode/httpcore#81)\n* Honor HTTP/2 max concurrent streams settings (Pull encode/httpcore#89, encode/httpcore#90)\n* Fix bytes support in multipart uploads. (Pull #974)\n* Improve typing support for `files=...`. (Pull #976)\n\n### Removed\n\n* Dropped support for `Client(uds=...)` (Pull #804)\n\n## 0.13.0.dev2 (May 12th, 2020)\n\nThe 0.13.0.dev2 is a *pre-release* version. To install it, use `pip install httpx --pre`.\n\n### Added\n\n* Logging via HTTPCORE_LOG_LEVEL and HTTPX_LOG_LEVEL environment variables\nand TRACE level logging. (HTTPCore Pull #79)\n\n### Fixed\n\n* Reuse of connections on HTTP/2 in close concurrency situations. (HTTPCore Pull #81)\n* When using an `app=<ASGI app>` observe neater disconnect behaviour instead of sending empty body messages. (Pull #919)\n\n## 0.13.0.dev1 (May 6th, 2020)\n\nThe 0.13.0.dev1 is a *pre-release* version. To install it, use `pip install httpx --pre`.\n\n### Fixed\n\n* Passing `http2` flag to proxy dispatchers. (Pull #934)\n* Use [`httpcore` v0.8.3](https://github.com/encode/httpcore/releases/tag/0.8.3)\nwhich addresses problems in handling of headers when using proxies.\n\n## 0.13.0.dev0 (April 30th, 2020)\n\nThe 0.13.0.dev0 is a *pre-release* version. To install it, use `pip install httpx --pre`.\n\nThis release switches to `httpcore` for all the internal networking, which means:\n\n* We're using the same codebase for both our sync and async clients.\n* HTTP/2 support is now available with the sync client.\n* We no longer have a `urllib3` dependency for our sync client, although there is still an *optional* `URLLib3Dispatcher` class.\n\nIt also means we've had to remove our UDS support, since maintaining that would have meant having to push back our work towards a 1.0 release, which isn't a trade-off we wanted to make.\n\n### Changed\n\n* Use `httpcore` for underlying HTTP transport. Drop `urllib3` requirement. (Pull #804)\n\n### Added\n\n* Added `URLLib3Dispatcher` class for optional `urllib3` transport support. (Pull #804)\n* Streaming multipart uploads. (Pull #857)\n\n### Fixed\n\n* Performance improvement in brotli decoder. (Pull #906)\n* Proper warning level of deprecation notice in `Response.stream` and `Response.raw`. (Pull #908)\n* Fix support for generator based WSGI apps. (Pull #887)\n\n### Removed\n\n* Dropped support for `Client(uds=...)` (Pull #804)\n\n---\n\n## 0.12.1 (March 19th, 2020)\n\n### Fixed\n\n* Resolved packaging issue, where additional files were being included.\n\n## 0.12.0 (March 9th, 2020)\n\nThe 0.12 release tightens up the API expectations for `httpx` by switching to private module names to enforce better clarity around public API.\n\nAll imports of `httpx` should import from the top-level package only, such as `from httpx import Request`, rather than importing from privately namespaced modules such as `from httpx._models import Request`.\n\n### Added\n\n* Support making response body available to auth classes with `.requires_response_body`. (Pull #803)\n* Export `NetworkError` exception. (Pull #814)\n* Add support for `NO_PROXY` environment variable. (Pull #835)\n\n### Changed\n\n* Switched to private module names. (Pull #785)\n* Drop redirect looping detection and the `RedirectLoop` exception, instead using `TooManyRedirects`. (Pull #819)\n* Drop `backend=...` parameter on `AsyncClient`, in favour of always autodetecting `trio`/`asyncio`. (Pull #791)\n\n### Fixed\n\n* Support basic auth credentials in proxy URLs. (Pull #780)\n* Fix `httpx.Proxy(url, mode=\"FORWARD_ONLY\")` configuration. (Pull #788)\n* Fallback to setting headers as UTF-8 if no encoding is specified. (Pull #820)\n* Close proxy dispatches classes on client close. (Pull #826)\n* Support custom `cert` parameters even if `verify=False`. (Pull #796)\n* Don't support invalid dict-of-dicts form data in `data=...`. (Pull #811)\n\n---\n\n## 0.11.1 (January 17th, 2020)\n\n### Fixed\n\n* Fixed usage of `proxies=...` on `Client()`. (Pull #763)\n* Support both `zlib` and `deflate` style encodings on `Content-Encoding: deflate`. (Pull #758)\n* Fix for streaming a redirect response body with `allow_redirects=False`. (Pull #766)\n* Handle redirect with malformed Location headers missing host. (Pull #774)\n\n## 0.11.0 (January 9th, 2020)\n\nThe 0.11 release reintroduces our sync support, so that `httpx` now supports both a standard thread-concurrency API, and an async API.\n\nExisting async `httpx` users that are upgrading to 0.11 should ensure that:\n\n* Async codebases should always use a client instance to make requests, instead of the top-level API.\n* The async client is named as `httpx.AsyncClient()`, instead of `httpx.Client()`.\n* When instantiating proxy configurations use the `httpx.Proxy()` class, instead of the previous `httpx.HTTPProxy()`. This new configuration class works for configuring both sync and async clients.\n\nWe believe the API is now pretty much stable, and are aiming for a 1.0 release sometime on or before April 2020.\n\n### Changed\n\n- Top level API such as `httpx.get(url, ...)`, `httpx.post(url, ...)`, `httpx.request(method, url, ...)` becomes synchronous.\n- Added `httpx.Client()` for synchronous clients, with `httpx.AsyncClient` being used for async clients.\n- Switched to `proxies=httpx.Proxy(...)` for proxy configuration.\n- Network connection errors are wrapped in `httpx.NetworkError`, rather than exposing lower-level exception types directly.\n\n### Removed\n\n- The `request.url.origin` property and `httpx.Origin` class are no longer available.\n- The per-request `cert`, `verify`, and `trust_env` arguments are escalated from raising errors if used, to no longer being available. These arguments should be used on a per-client instance instead, or in the top-level API.\n- The `stream` argument has escalated from raising an error when used, to no longer being available. Use the `client.stream(...)` or `httpx.stream()` streaming API instead.\n\n### Fixed\n\n- Redirect loop detection matches against `(method, url)` rather than `url`. (Pull #734)\n\n---\n\n## 0.10.1 (December 31st, 2019)\n\n### Fixed\n\n- Fix issue with concurrent connection acquisition. (Pull #700)\n- Fix write error on closing HTTP/2 connections. (Pull #699)\n\n## 0.10.0 (December 29th, 2019)\n\nThe 0.10.0 release makes some changes that will allow us to support both sync and async interfaces.\n\nIn particular with streaming responses the `response.read()` method becomes `response.aread()`, and the `response.close()` method becomes `response.aclose()`.\n\nIf following redirects explicitly the `response.next()` method becomes `response.anext()`.\n\n### Fixed\n\n- End HTTP/2 streams immediately on no-body requests, rather than sending an empty body message. (Pull #682)\n- Improve typing for `Response.request`: switch from `Optional[Request]` to `Request`. (Pull #666)\n- `Response.elapsed` now reflects the entire download time. (Pull #687, #692)\n\n### Changed\n\n- Added `AsyncClient` as a synonym for `Client`. (Pull #680)\n- Switch to `response.aread()` for conditionally reading streaming responses. (Pull #674)\n- Switch to `response.aclose()` and `client.aclose()` for explicit closing. (Pull #674, #675)\n- Switch to `response.anext()` for resolving the next redirect response. (Pull #676)\n\n### Removed\n\n- When using a client instance, the per-request usage of `verify`, `cert`, and `trust_env` have now escalated from raising a warning to raising an error. You should set these arguments on the client instead. (Pull #617)\n- Removed the undocumented `request.read()`, since end users should not require it.\n\n---\n\n## 0.9.5 (December 20th, 2019)\n\n### Fixed\n\n- Fix Host header and HSTS rewrites when an explicit `:80` port is included in URL. (Pull #649)\n- Query Params on the URL string are merged with any `params=...` argument. (Pull #653)\n- More robust behavior when closing connections. (Pull #640)\n- More robust behavior when handling HTTP/2 headers with trailing whitespace. (Pull #637)\n- Allow any explicit `Content-Type` header to take precedence over the encoding default. (Pull #633)\n\n## 0.9.4 (December 12th, 2019)\n\n### Fixed\n\n- Added expiry to Keep-Alive connections, resolving issues with acquiring connections. (Pull #627)\n- Increased flow control windows on HTTP/2, resolving download speed issues. (Pull #629)\n\n## 0.9.3 (December 7th, 2019)\n\n### Fixed\n\n- Fixed HTTP/2 with autodetection backend. (Pull #614)\n\n## 0.9.2 (December 7th, 2019)\n\n* Released due to packaging build artifact.\n\n## 0.9.1 (December 6th, 2019)\n\n* Released due to packaging build artifact.\n\n## 0.9.0 (December 6th, 2019)\n\nThe 0.9 releases brings some major new features, including:\n\n* A new streaming API.\n* Autodetection of either asyncio or trio.\n* Nicer timeout configuration.\n* HTTP/2 support off by default, but can be enabled.\n\nWe've also removed all private types from the top-level package export.\n\nIn order to ensure you are only ever working with public API you should make\nsure to only import the top-level package eg. `import httpx`, rather than\nimporting modules within the package.\n\n### Added\n\n- Added concurrency backend autodetection. (Pull #585)\n- Added `Client(backend='trio')` and `Client(backend='asyncio')` API. (Pull #585)\n- Added `response.stream_lines()` API. (Pull #575)\n- Added `response.is_error` API. (Pull #574)\n- Added support for `timeout=Timeout(5.0, connect_timeout=60.0)` styles. (Pull #593)\n\n### Fixed\n\n- Requests or Clients with `timeout=None` now correctly always disable timeouts. (Pull #592)\n- Request 'Authorization' headers now have priority over `.netrc` authentication info. (Commit 095b691)\n- Files without a filename no longer set a Content-Type in multipart data. (Commit ed94950)\n\n### Changed\n\n- Added `httpx.stream()` API. Using `stream=True` now results in a warning. (Pull #600, #610)\n- HTTP/2 support is switched to \"off by default\", but can be enabled explicitly. (Pull #584)\n- Switched to `Client(http2=True)` API from `Client(http_versions=[\"HTTP/1.1\", \"HTTP/2\"])`. (Pull #586)\n- Removed all private types from the top-level package export. (Pull #608)\n- The SSL configuration settings of `verify`, `cert`, and `trust_env` now raise warnings if used per-request when using a Client instance. They should always be set on the Client instance itself. (Pull #597)\n- Use plain strings \"TUNNEL_ONLY\" or \"FORWARD_ONLY\" on the HTTPProxy `proxy_mode` argument. The `HTTPProxyMode` enum still exists, but its usage will raise warnings. (#610)\n- Pool timeouts are now on the timeout configuration, not the pool limits configuration. (Pull #563)\n- The timeout configuration is now named `httpx.Timeout(...)`, not `httpx.TimeoutConfig(...)`. The old version currently remains as a synonym for backwards compatibility.  (Pull #591)\n\n---\n\n## 0.8.0 (November 27, 2019)\n\n### Removed\n\n- The synchronous API has been removed, in order to allow us to fundamentally change how we approach supporting both sync and async variants. (See #588 for more details.)\n\n---\n\n## 0.7.8 (November 17, 2019)\n\n### Added\n\n- Add support for proxy tunnels for Python 3.6 + asyncio. (Pull #521)\n\n## 0.7.7 (November 15, 2019)\n\n### Fixed\n\n- Resolve an issue with cookies behavior on redirect requests. (Pull #529)\n\n### Added\n\n- Add request/response DEBUG logs. (Pull #502)\n- Use TRACE log level for low level info. (Pull #500)\n\n## 0.7.6 (November 2, 2019)\n\n### Removed\n\n- Drop `proxies` parameter from the high-level API. (Pull #485)\n\n### Fixed\n\n- Tweak multipart files: omit null filenames, add support for `str` file contents. (Pull #482)\n- Cache NETRC authentication per-client. (Pull #400)\n- Rely on `getproxies` for all proxy environment variables. (Pull #470)\n- Wait for the `asyncio` stream to close when closing a connection. (Pull #494)\n\n## 0.7.5 (October 10, 2019)\n\n### Added\n\n- Allow lists of values to be passed to `params`. (Pull #386)\n- `ASGIDispatch`, `WSGIDispatch` are now available in the `httpx.dispatch` namespace. (Pull #407)\n- `HTTPError` is now available in the `httpx` namespace.  (Pull #421)\n- Add support for `start_tls()` to the Trio concurrency backend. (Pull #467)\n\n### Fixed\n\n- Username and password are no longer included in the `Host` header when basic authentication\n  credentials are supplied via the URL. (Pull #417)\n\n### Removed\n\n- The `.delete()` function no longer has `json`, `data`, or `files` parameters\n  to match the expected semantics of the `DELETE` method. (Pull #408)\n- Removed the `trio` extra. Trio support is detected automatically. (Pull #390)\n\n## 0.7.4 (September 25, 2019)\n\n### Added\n\n- Add Trio concurrency backend. (Pull #276)\n- Add `params` parameter to `Client` for setting default query parameters. (Pull #372)\n- Add support for `SSL_CERT_FILE` and `SSL_CERT_DIR` environment variables. (Pull #307)\n- Add debug logging to calls into ASGI apps. (Pull #371)\n- Add debug logging to SSL configuration. (Pull #378)\n\n### Fixed\n\n- Fix a bug when using `Client` without timeouts in Python 3.6. (Pull #383)\n- Propagate `Client` configuration to HTTP proxies. (Pull #377)\n\n## 0.7.3 (September 20, 2019)\n\n### Added\n\n- HTTP Proxy support. (Pulls #259, #353)\n- Add Digest authentication. (Pull #332)\n- Add `.build_request()` method to `Client` and `AsyncClient`. (Pull #319)\n- Add `.elapsed` property on responses. (Pull #351)\n- Add support for `SSLKEYLOGFILE` in Python 3.8b4+. (Pull #301)\n\n### Removed\n\n- Drop NPN support for HTTP version negotiation. (Pull #314)\n\n### Fixed\n\n- Fix distribution of type annotations for mypy (Pull #361).\n- Set `Host` header when redirecting cross-origin. (Pull #321)\n- Drop `Content-Length` headers on `GET` redirects. (Pull #310)\n- Raise `KeyError` if header isn't found in `Headers`. (Pull #324)\n- Raise `NotRedirectResponse` in `response.next()` if there is no redirection to perform. (Pull #297)\n- Fix bug in calculating the HTTP/2 maximum frame size. (Pull #153)\n\n## 0.7.2 (August 28, 2019)\n\n- Enforce using `httpx.AsyncioBackend` for the synchronous client. (Pull #232)\n- `httpx.ConnectionPool` will properly release a dropped connection. (Pull #230)\n- Remove the `raise_app_exceptions` argument from `Client`. (Pull #238)\n- `DecodeError` will no longer be raised for an empty body encoded with Brotli. (Pull #237)\n- Added `http_versions` parameter to `Client`. (Pull #250)\n- Only use HTTP/1.1 on short-lived connections like `httpx.get()`. (Pull #284)\n- Convert `Client.cookies` and `Client.headers` when set as a property. (Pull #274)\n- Setting `HTTPX_DEBUG=1` enables debug logging on all requests. (Pull #277)\n\n## 0.7.1 (August 18, 2019)\n\n- Include files with source distribution to be installable. (Pull #233)\n\n## 0.7.0 (August 17, 2019)\n\n- Add the `trust_env` property to `BaseClient`. (Pull #187)\n- Add the `links` property to `BaseResponse`. (Pull #211)\n- Accept `ssl.SSLContext` instances into `SSLConfig(verify=...)`. (Pull #215)\n- Add `Response.stream_text()` with incremental encoding detection. (Pull #183)\n- Properly updated the `Host` header when a redirect changes the origin. (Pull #199)\n- Ignore invalid `Content-Encoding` headers. (Pull #196)\n- Use `~/.netrc` and `~/_netrc` files by default when `trust_env=True`. (Pull #189)\n- Create exception base class `HTTPError` with `request` and `response` properties. (Pull #162)\n- Add HSTS preload list checking within `BaseClient` to upgrade HTTP URLs to HTTPS. (Pull #184)\n- Switch IDNA encoding from IDNA 2003 to IDNA 2008. (Pull #161)\n- Expose base classes for alternate concurrency backends. (Pull #178)\n- Improve Multipart parameter encoding. (Pull #167)\n- Add the `headers` property to `BaseClient`. (Pull #159)\n- Add support for Google's `brotli` library. (Pull #156)\n- Remove deprecated TLS versions (TLSv1 and TLSv1.1) from default `SSLConfig`. (Pull #155)\n- Fix `URL.join(...)` to work similarly to RFC 3986 URL joining. (Pull #144)\n\n---\n\n## 0.6.8 (July 25, 2019)\n\n- Check for disconnections when searching for an available\n  connection in `ConnectionPool.keepalive_connections` (Pull #145)\n- Allow string comparison for `URL` objects (Pull #139)\n- Add HTTP status codes 418 and 451 (Pull #135)\n- Add support for client certificate passwords (Pull #118)\n- Enable post-handshake client cert authentication for TLSv1.3 (Pull #118)\n- Disable using `commonName` for hostname checking for OpenSSL 1.1.0+ (Pull #118)\n- Detect encoding for `Response.json()` (Pull #116)\n\n## 0.6.7 (July 8, 2019)\n\n- Check for connection aliveness on re-acquisition (Pull #111)\n\n## 0.6.6 (July 3, 2019)\n\n- Improve `USER_AGENT` (Pull #110)\n- Add `Connection: keep-alive` by default to HTTP/1.1 connections. (Pull #110)\n\n## 0.6.5 (June 27, 2019)\n\n- Include `Host` header by default. (Pull #109)\n- Improve HTTP protocol detection. (Pull #107)\n\n## 0.6.4 (June 25, 2019)\n\n- Implement read and write timeouts (Pull #104)\n\n## 0.6.3 (June 24, 2019)\n\n- Handle early connection closes (Pull #103)\n\n## 0.6.2 (June 23, 2019)\n\n- Use urllib3's `DEFAULT_CIPHERS` for the `SSLConfig` object. (Pull #100)\n\n## 0.6.1 (June 21, 2019)\n\n- Add support for setting a `base_url` on the `Client`.\n\n## 0.6.0 (June 21, 2019)\n\n- Honor `local_flow_control_window` for HTTP/2 connections (Pull #98)\n",
      "scraped_at": 1756988949.2703667
    },
    {
      "repo": "encode/httpx",
      "filename": "LICENSE.md",
      "path": "LICENSE.md",
      "content": "Copyright \u00a9 2019, [Encode OSS Ltd](https://www.encode.io/).\nAll rights reserved.\n\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\n* Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\n\n* Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\n\n* Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
      "scraped_at": 1756988950.2811108
    },
    {
      "repo": "encode/httpx",
      "filename": "README.md",
      "path": "README.md",
      "content": "<p align=\"center\">\n  <a href=\"https://www.python-httpx.org/\"><img width=\"350\" height=\"208\" src=\"https://raw.githubusercontent.com/encode/httpx/master/docs/img/butterfly.png\" alt='HTTPX'></a>\n</p>\n\n<p align=\"center\"><strong>HTTPX</strong> <em>- A next-generation HTTP client for Python.</em></p>\n\n<p align=\"center\">\n<a href=\"https://github.com/encode/httpx/actions\">\n    <img src=\"https://github.com/encode/httpx/workflows/Test%20Suite/badge.svg\" alt=\"Test Suite\">\n</a>\n<a href=\"https://pypi.org/project/httpx/\">\n    <img src=\"https://badge.fury.io/py/httpx.svg\" alt=\"Package version\">\n</a>\n</p>\n\nHTTPX is a fully featured HTTP client library for Python 3. It includes **an integrated command line client**, has support for both **HTTP/1.1 and HTTP/2**, and provides both **sync and async APIs**.\n\n---\n\nInstall HTTPX using pip:\n\n```shell\n$ pip install httpx\n```\n\nNow, let's get started:\n\n```pycon\n>>> import httpx\n>>> r = httpx.get('https://www.example.org/')\n>>> r\n<Response [200 OK]>\n>>> r.status_code\n200\n>>> r.headers['content-type']\n'text/html; charset=UTF-8'\n>>> r.text\n'<!doctype html>\\n<html>\\n<head>\\n<title>Example Domain</title>...'\n```\n\nOr, using the command-line client.\n\n```shell\n$ pip install 'httpx[cli]'  # The command line client is an optional dependency.\n```\n\nWhich now allows us to use HTTPX directly from the command-line...\n\n<p align=\"center\">\n  <img width=\"700\" src=\"docs/img/httpx-help.png\" alt='httpx --help'>\n</p>\n\nSending a request...\n\n<p align=\"center\">\n  <img width=\"700\" src=\"docs/img/httpx-request.png\" alt='httpx http://httpbin.org/json'>\n</p>\n\n## Features\n\nHTTPX builds on the well-established usability of `requests`, and gives you:\n\n* A broadly [requests-compatible API](https://www.python-httpx.org/compatibility/).\n* An integrated command-line client.\n* HTTP/1.1 [and HTTP/2 support](https://www.python-httpx.org/http2/).\n* Standard synchronous interface, but with [async support if you need it](https://www.python-httpx.org/async/).\n* Ability to make requests directly to [WSGI applications](https://www.python-httpx.org/advanced/transports/#wsgi-transport) or [ASGI applications](https://www.python-httpx.org/advanced/transports/#asgi-transport).\n* Strict timeouts everywhere.\n* Fully type annotated.\n* 100% test coverage.\n\nPlus all the standard features of `requests`...\n\n* International Domains and URLs\n* Keep-Alive & Connection Pooling\n* Sessions with Cookie Persistence\n* Browser-style SSL Verification\n* Basic/Digest Authentication\n* Elegant Key/Value Cookies\n* Automatic Decompression\n* Automatic Content Decoding\n* Unicode Response Bodies\n* Multipart File Uploads\n* HTTP(S) Proxy Support\n* Connection Timeouts\n* Streaming Downloads\n* .netrc Support\n* Chunked Requests\n\n## Installation\n\nInstall with pip:\n\n```shell\n$ pip install httpx\n```\n\nOr, to include the optional HTTP/2 support, use:\n\n```shell\n$ pip install httpx[http2]\n```\n\nHTTPX requires Python 3.9+.\n\n## Documentation\n\nProject documentation is available at [https://www.python-httpx.org/](https://www.python-httpx.org/).\n\nFor a run-through of all the basics, head over to the [QuickStart](https://www.python-httpx.org/quickstart/).\n\nFor more advanced topics, see the [Advanced Usage](https://www.python-httpx.org/advanced/) section, the [async support](https://www.python-httpx.org/async/) section, or the [HTTP/2](https://www.python-httpx.org/http2/) section.\n\nThe [Developer Interface](https://www.python-httpx.org/api/) provides a comprehensive API reference.\n\nTo find out about tools that integrate with HTTPX, see [Third Party Packages](https://www.python-httpx.org/third_party_packages/).\n\n## Contribute\n\nIf you want to contribute with HTTPX check out the [Contributing Guide](https://www.python-httpx.org/contributing/) to learn how to start.\n\n## Dependencies\n\nThe HTTPX project relies on these excellent libraries:\n\n* `httpcore` - The underlying transport implementation for `httpx`.\n  * `h11` - HTTP/1.1 support.\n* `certifi` - SSL certificates.\n* `idna` - Internationalized domain name support.\n* `sniffio` - Async library autodetection.\n\nAs well as these optional installs:\n\n* `h2` - HTTP/2 support. *(Optional, with `httpx[http2]`)*\n* `socksio` - SOCKS proxy support. *(Optional, with `httpx[socks]`)*\n* `rich` - Rich terminal support. *(Optional, with `httpx[cli]`)*\n* `click` - Command line client support. *(Optional, with `httpx[cli]`)*\n* `brotli` or `brotlicffi` - Decoding for \"brotli\" compressed responses. *(Optional, with `httpx[brotli]`)*\n* `zstandard` - Decoding for \"zstd\" compressed responses. *(Optional, with `httpx[zstd]`)*\n\nA huge amount of credit is due to `requests` for the API layout that\nmuch of this work follows, as well as to `urllib3` for plenty of design\ninspiration around the lower-level networking details.\n\n---\n\n<p align=\"center\"><i>HTTPX is <a href=\"https://github.com/encode/httpx/blob/master/LICENSE.md\">BSD licensed</a> code.<br/>Designed & crafted with care.</i><br/>&mdash; \ud83e\udd8b &mdash;</p>\n",
      "scraped_at": 1756988951.3016114
    },
    {
      "repo": "scrapy/scrapy",
      "filename": "CODE_OF_CONDUCT.md",
      "path": "CODE_OF_CONDUCT.md",
      "content": "\n# Contributor Covenant Code of Conduct\n\n## Our Pledge\n\nWe as members, contributors, and leaders pledge to make participation in our\ncommunity a harassment-free experience for everyone, regardless of age, body\nsize, visible or invisible disability, ethnicity, sex characteristics, gender\nidentity and expression, level of experience, education, socio-economic status,\nnationality, personal appearance, race, caste, color, religion, or sexual\nidentity and orientation.\n\nWe pledge to act and interact in ways that contribute to an open, welcoming,\ndiverse, inclusive, and healthy community.\n\n## Our Standards\n\nExamples of behavior that contributes to a positive environment for our\ncommunity include:\n\n* Demonstrating empathy and kindness toward other people\n* Being respectful of differing opinions, viewpoints, and experiences\n* Giving and gracefully accepting constructive feedback\n* Accepting responsibility and apologizing to those affected by our mistakes,\n  and learning from the experience\n* Focusing on what is best not just for us as individuals, but for the overall\n  community\n\nExamples of unacceptable behavior include:\n\n* The use of sexualized language or imagery, and sexual attention or advances of\n  any kind\n* Trolling, insulting or derogatory comments, and personal or political attacks\n* Public or private harassment\n* Publishing others' private information, such as a physical or email address,\n  without their explicit permission\n* Other conduct which could reasonably be considered inappropriate in a\n  professional setting\n\n## Enforcement Responsibilities\n\nCommunity leaders are responsible for clarifying and enforcing our standards of\nacceptable behavior and will take appropriate and fair corrective action in\nresponse to any behavior that they deem inappropriate, threatening, offensive,\nor harmful.\n\nCommunity leaders have the right and responsibility to remove, edit, or reject\ncomments, commits, code, wiki edits, issues, and other contributions that are\nnot aligned to this Code of Conduct, and will communicate reasons for moderation\ndecisions when appropriate.\n\n## Scope\n\nThis Code of Conduct applies within all community spaces, and also applies when\nan individual is officially representing the community in public spaces.\nExamples of representing our community include using an official e-mail address,\nposting via an official social media account, or acting as an appointed\nrepresentative at an online or offline event.\n\n## Enforcement\n\nInstances of abusive, harassing, or otherwise unacceptable behavior may be\nreported to the community leaders responsible for enforcement at\nopensource@zyte.com.\nAll complaints will be reviewed and investigated promptly and fairly.\n\nAll community leaders are obligated to respect the privacy and security of the\nreporter of any incident.\n\n## Enforcement Guidelines\n\nCommunity leaders will follow these Community Impact Guidelines in determining\nthe consequences for any action they deem in violation of this Code of Conduct:\n\n### 1. Correction\n\n**Community Impact**: Use of inappropriate language or other behavior deemed\nunprofessional or unwelcome in the community.\n\n**Consequence**: A private, written warning from community leaders, providing\nclarity around the nature of the violation and an explanation of why the\nbehavior was inappropriate. A public apology may be requested.\n\n### 2. Warning\n\n**Community Impact**: A violation through a single incident or series of\nactions.\n\n**Consequence**: A warning with consequences for continued behavior. No\ninteraction with the people involved, including unsolicited interaction with\nthose enforcing the Code of Conduct, for a specified period of time. This\nincludes avoiding interactions in community spaces as well as external channels\nlike social media. Violating these terms may lead to a temporary or permanent\nban.\n\n### 3. Temporary Ban\n\n**Community Impact**: A serious violation of community standards, including\nsustained inappropriate behavior.\n\n**Consequence**: A temporary ban from any sort of interaction or public\ncommunication with the community for a specified period of time. No public or\nprivate interaction with the people involved, including unsolicited interaction\nwith those enforcing the Code of Conduct, is allowed during this period.\nViolating these terms may lead to a permanent ban.\n\n### 4. Permanent Ban\n\n**Community Impact**: Demonstrating a pattern of violation of community\nstandards, including sustained inappropriate behavior, harassment of an\nindividual, or aggression toward or disparagement of classes of individuals.\n\n**Consequence**: A permanent ban from any sort of public interaction within the\ncommunity.\n\n## Attribution\n\nThis Code of Conduct is adapted from the [Contributor Covenant][homepage],\nversion 2.1, available at\n[https://www.contributor-covenant.org/version/2/1/code_of_conduct.html][v2.1].\n\nCommunity Impact Guidelines were inspired by\n[Mozilla's code of conduct enforcement ladder][Mozilla CoC].\n\nFor answers to common questions about this code of conduct, see the FAQ at\n[https://www.contributor-covenant.org/faq][FAQ]. Translations are available at\n[https://www.contributor-covenant.org/translations][translations].\n\n[homepage]: https://www.contributor-covenant.org\n[v2.1]: https://www.contributor-covenant.org/version/2/1/code_of_conduct.html\n[Mozilla CoC]: https://github.com/mozilla/diversity\n[FAQ]: https://www.contributor-covenant.org/faq\n[translations]: https://www.contributor-covenant.org/translations\n",
      "scraped_at": 1756988952.9015923
    },
    {
      "repo": "scrapy/scrapy",
      "filename": "CONTRIBUTING.md",
      "path": "CONTRIBUTING.md",
      "content": "The guidelines for contributing are available here:\nhttps://docs.scrapy.org/en/master/contributing.html\n\nPlease do not abuse the issue tracker for support questions.\nIf your issue topic can be rephrased to \"How to ...?\", please use the\nsupport channels to get it answered: https://scrapy.org/community/\n",
      "scraped_at": 1756988953.9212859
    },
    {
      "repo": "scrapy/scrapy",
      "filename": "INSTALL.md",
      "path": "INSTALL.md",
      "content": "For information about installing Scrapy see:\n\n* [Local docs](docs/intro/install.rst)\n* [Online docs](https://docs.scrapy.org/en/latest/intro/install.html)\n",
      "scraped_at": 1756988956.7395327
    },
    {
      "repo": "scrapy/scrapy",
      "filename": "SECURITY.md",
      "path": "SECURITY.md",
      "content": "# Security Policy\n\n## Supported Versions\n\n| Version | Supported          |\n| ------- | ------------------ |\n| 2.13.x     | :white_check_mark: |\n| < 2.13.x   | :x:                |\n\n## Reporting a Vulnerability\n\nPlease report the vulnerability using https://github.com/scrapy/scrapy/security/advisories/new.\n",
      "scraped_at": 1756988957.872999
    },
    {
      "repo": "scrapy/scrapy",
      "filename": "conftest.py",
      "path": "conftest.py",
      "content": "from __future__ import annotations\n\nfrom pathlib import Path\nfrom typing import TYPE_CHECKING\n\nimport pytest\nfrom twisted.web.http import H2_ENABLED\n\nfrom scrapy.utils.reactor import set_asyncio_event_loop_policy\nfrom tests.keys import generate_keys\nfrom tests.mockserver.http import MockServer\n\nif TYPE_CHECKING:\n    from collections.abc import Generator\n\n\ndef _py_files(folder):\n    return (str(p) for p in Path(folder).rglob(\"*.py\"))\n\n\ncollect_ignore = [\n    # may need extra deps\n    \"docs/_ext\",\n    # not a test, but looks like a test\n    \"scrapy/utils/testproc.py\",\n    \"scrapy/utils/testsite.py\",\n    \"tests/ftpserver.py\",\n    \"tests/mockserver.py\",\n    \"tests/pipelines.py\",\n    \"tests/spiders.py\",\n    # contains scripts to be run by tests/test_crawler.py::AsyncCrawlerProcessSubprocess\n    *_py_files(\"tests/AsyncCrawlerProcess\"),\n    # contains scripts to be run by tests/test_crawler.py::AsyncCrawlerRunnerSubprocess\n    *_py_files(\"tests/AsyncCrawlerRunner\"),\n    # contains scripts to be run by tests/test_crawler.py::CrawlerProcessSubprocess\n    *_py_files(\"tests/CrawlerProcess\"),\n    # contains scripts to be run by tests/test_crawler.py::CrawlerRunnerSubprocess\n    *_py_files(\"tests/CrawlerRunner\"),\n]\n\nbase_dir = Path(__file__).parent\nignore_file_path = base_dir / \"tests\" / \"ignores.txt\"\nwith ignore_file_path.open(encoding=\"utf-8\") as reader:\n    for line in reader:\n        file_path = line.strip()\n        if file_path and file_path[0] != \"#\":\n            collect_ignore.append(file_path)\n\nif not H2_ENABLED:\n    collect_ignore.extend(\n        (\n            \"scrapy/core/downloader/handlers/http2.py\",\n            *_py_files(\"scrapy/core/http2\"),\n        )\n    )\n\n\n@pytest.fixture(scope=\"session\")\ndef mockserver() -> Generator[MockServer]:\n    with MockServer() as mockserver:\n        yield mockserver\n\n\n@pytest.fixture(scope=\"session\")\ndef reactor_pytest(request) -> str:\n    return request.config.getoption(\"--reactor\")\n\n\n@pytest.fixture(autouse=True)\ndef only_asyncio(request, reactor_pytest):\n    if request.node.get_closest_marker(\"only_asyncio\") and reactor_pytest != \"asyncio\":\n        pytest.skip(\"This test is only run with --reactor=asyncio\")\n\n\n@pytest.fixture(autouse=True)\ndef only_not_asyncio(request, reactor_pytest):\n    if (\n        request.node.get_closest_marker(\"only_not_asyncio\")\n        and reactor_pytest == \"asyncio\"\n    ):\n        pytest.skip(\"This test is only run without --reactor=asyncio\")\n\n\n@pytest.fixture(autouse=True)\ndef requires_uvloop(request):\n    if not request.node.get_closest_marker(\"requires_uvloop\"):\n        return\n    try:\n        import uvloop  # noqa: PLC0415\n\n        del uvloop\n    except ImportError:\n        pytest.skip(\"uvloop is not installed\")\n\n\n@pytest.fixture(autouse=True)\ndef requires_botocore(request):\n    if not request.node.get_closest_marker(\"requires_botocore\"):\n        return\n    try:\n        import botocore  # noqa: PLC0415\n\n        del botocore\n    except ImportError:\n        pytest.skip(\"botocore is not installed\")\n\n\n@pytest.fixture(autouse=True)\ndef requires_boto3(request):\n    if not request.node.get_closest_marker(\"requires_boto3\"):\n        return\n    try:\n        import boto3  # noqa: PLC0415\n\n        del boto3\n    except ImportError:\n        pytest.skip(\"boto3 is not installed\")\n\n\ndef pytest_configure(config):\n    if config.getoption(\"--reactor\") == \"asyncio\":\n        # Needed on Windows to switch from proactor to selector for Twisted reactor compatibility.\n        # If we decide to run tests with both, we will need to add a new option and check it here.\n        set_asyncio_event_loop_policy()\n\n\n# Generate localhost certificate files, needed by some tests\ngenerate_keys()\n",
      "scraped_at": 1756988958.9836907
    }
  ],
  "documentation": [
    {
      "url": "https://docs.python.org/3/library/socket.html",
      "status": 200,
      "content": {
        "content": [
          "socket\u00e2\u0080\u0094 Low-level networking interface\u00c2\u00b6Source code:Lib/socket.pyThis module provides access to the BSDsocketinterface. It is available on\nall modern Unix systems, Windows, MacOS, and probably additional platforms.NoteSome behavior may be platform dependent, since calls are made to the operating\nsystem socket APIs.Availability: not WASI.This module does not work or is not available on WebAssembly. SeeWebAssembly platformsfor more information.The Python interface is a straightforward transliteration of the Unix system\ncall and library interface for sockets to Python\u00e2\u0080\u0099s object-oriented style: thesocket()function returns asocket objectwhose methods implement\nthe various socket system calls.  Parameter types are somewhat higher-level than\nin the C interface: as withread()andwrite()operations on Python\nfiles, buffer allocation on receive operations is automatic, and buffer length\nis implicit on send operations.See alsoModulesocketserverClasses that simplify writing network servers.ModulesslA TLS/SSL wrapper for socket objects.Socket families\u00c2\u00b6Depending on the system and the build options, various socket families\nare supported by this module.The address format required by a particular socket object is automatically\nselected based on the address family specified when the socket object was\ncreated.  Socket addresses are represented as follows:The address of anAF_UNIXsocket bound to a file system node\nis represented as a string, using the file system encoding and the'surrogateescape'error handler (seePEP 383).  An address in\nLinux\u00e2\u0080\u0099s abstract namespace is returned as abytes-like objectwith\nan initial null byte; note that sockets in this namespace can\ncommunicate with normal file system sockets, so programs intended to\nrun on Linux may need to deal with both types of address.  A string or\nbytes-like object can be used for either type of address when\npassing it as an argument.Changed in version 3.3:Previously,AF_UNIXsocket paths were assumed to use UTF-8\nencoding.Changed in version 3.5:Writablebytes-like objectis now accepted.A pair(host,port)is used for theAF_INETaddress family,\nwherehostis a string representing either a hostname in internet domain\nnotation like'daring.cwi.nl'or an IPv4 address like'100.50.200.5',\nandportis an integer.For IPv4 addresses, two special forms are accepted instead of a host\naddress:''representsINADDR_ANY, which is used to bind to all\ninterfaces, and the string'<broadcast>'representsINADDR_BROADCAST.  This behavior is not compatible with IPv6,\ntherefore, you may want to avoid these if you intend to support IPv6 with your\nPython programs.ForAF_INET6address family, a four-tuple(host,port,flowinfo,scope_id)is used, whereflowinfoandscope_idrepresent thesin6_flowinfoandsin6_scope_idmembers instructsockaddr_in6in C.  Forsocketmodule methods,flowinfoandscope_idcan be omitted just for\nbackward compatibility.  Note, however, omission ofscope_idcan cause problems\nin manipulating scoped IPv6 addresses.Changed in version 3.7:For multicast addresses (withscope_idmeaningful)addressmay not contain%scope_id(orzoneid) part. This information is superfluous and may\nbe safely omitted (recommended).AF_NETLINKsockets are represented as pairs(pid,groups).Linux-only support for TIPC is available using theAF_TIPCaddress family.  TIPC is an open, non-IP based networked protocol designed\nfor use in clustered computer environments.  Addresses are represented by a\ntuple, and the fields depend on the address type. The general tuple form is(addr_type,v1,v2,v3[,scope]), where:addr_typeis one ofTIPC_ADDR_NAMESEQ,TIPC_ADDR_NAME,\norTIPC_ADDR_ID.scopeis one ofTIPC_ZONE_SCOPE,TIPC_CLUSTER_SCOPE, andTIPC_NODE_SCOPE.Ifaddr_typeisTIPC_ADDR_NAME, thenv1is the server type,v2is\nthe port identifier, andv3should be 0.Ifaddr_typeisTIPC_ADDR_NAMESEQ, thenv1is the server type,v2is the lower port number, andv3is the upper port number.Ifaddr_typeisTIPC_ADDR_ID, thenv1is the node,v2is the\nreference, andv3should be set to 0.A tuple(interface,)is used for theAF_CANaddress family,\nwhereinterfaceis a string representing a network interface name like'can0'. The network interface name''can be used to receive packets\nfrom all network interfaces of this family.CAN_ISOTPprotocol require a tuple(interface,rx_addr,tx_addr)where both additional parameters are unsigned long integer that represent a\nCAN identifier (standard or extended).CAN_J1939protocol require a tuple(interface,name,pgn,addr)where additional parameters are 64-bit unsigned integer representing the\nECU name, a 32-bit unsigned integer representing the Parameter Group Number\n(PGN), and an 8-bit integer representing the address.A string or a tuple(id,unit)is used for theSYSPROTO_CONTROLprotocol of thePF_SYSTEMfamily. The string is the name of a\nkernel control using a dynamically assigned ID. The tuple can be used if ID\nand unit number of the kernel control are known or if a registered ID is\nused.Added in version 3.3.AF_BLUETOOTHsupports the following protocols and address\nformats:BTPROTO_L2CAPaccepts(bdaddr,psm)wherebdaddris\nthe Bluetooth address as a string andpsmis an integer.BTPROTO_RFCOMMaccepts(bdaddr,channel)wherebdaddris the Bluetooth address as a string andchannelis an integer.BTPROTO_HCIaccepts a format that depends on your OS.On Linux it accepts a tuple(device_id,)wheredevice_idis an integer specifying the number of the Bluetooth device.On FreeBSD, NetBSD and DragonFly BSD it acceptsbdaddrwherebdaddris the Bluetooth address as a string.Changed in version 3.2:NetBSD and DragonFlyBSD support added.Changed in version 3.13.3:FreeBSD support added.BTPROTO_SCOacceptsbdaddrwherebdaddris\nthe Bluetooth address as a string or abytesobject.\n(ex.'12:23:34:45:56:67'orb'12:23:34:45:56:67')\nThis protocol is not supported under FreeBSD.AF_ALGis a Linux-only socket based interface to Kernel\ncryptography. An algorithm socket is configured with a tuple of two to four\nelements(type,name[,feat[,mask]]), where:typeis the algorithm type as string, e.g.aead,hash,skcipherorrng.nameis the algorithm name and operation mode as string, e.g.sha256,hmac(sha256),cbc(aes)ordrbg_nopr_ctr_aes256.featandmaskare unsigned 32bit integers.Availability: Linux >= 2.6.38.Some algorithm types require more recent Kernels.Added in version 3.6.AF_VSOCKallows communication between virtual machines and\ntheir hosts. The sockets are represented as a(CID,port)tuple\nwhere the context ID or CID and port are integers.Availability: Linux >= 3.9Seevsock(7)Added in version 3.7.AF_PACKETis a low-level interface directly to network devices.\nThe addresses are represented by the tuple(ifname,proto[,pkttype[,hatype[,addr]]])where:ifname- String specifying the device name.proto- The Ethernet protocol number.\nMay beETH_P_ALLto capture all protocols,\none of theETHERTYPE_* constantsor any other Ethernet protocol number.pkttype- Optional integer specifying the packet type:PACKET_HOST(the default) - Packet addressed to the local host.PACKET_BROADCAST- Physical-layer broadcast packet.PACKET_MULTICAST- Packet sent to a physical-layer multicast address.PACKET_OTHERHOST- Packet to some other host that has been caught by\na device driver in promiscuous mode.PACKET_OUTGOING- Packet originating from the local host that is\nlooped back to a packet socket.hatype- Optional integer specifying the ARP hardware address type.addr- Optional bytes-like object specifying the hardware physical\naddress, whose interpretation depends on the device.Availability: Linux >= 2.2.AF_QIPCRTRis a Linux-only socket based interface for communicating\nwith services running on co-processors in Qualcomm platforms. The address\nfamily is represented as a(node,port)tuple where thenodeandportare non-negative integers.Availability: Linux >= 4.7.Added in version 3.8.IPPROTO_UDPLITEis a variant of UDP which allows you to specify\nwhat portion of a packet is covered with the checksum. It adds two socket\noptions that you can change.self.setsockopt(IPPROTO_UDPLITE,UDPLITE_SEND_CSCOV,length)will\nchange what portion of outgoing packets are covered by the checksum andself.setsockopt(IPPROTO_UDPLITE,UDPLITE_RECV_CSCOV,length)will\nfilter out packets which cover too little of their data. In both caseslengthshould be inrange(8,2**16,8).Such a socket should be constructed withsocket(AF_INET,SOCK_DGRAM,IPPROTO_UDPLITE)for IPv4 orsocket(AF_INET6,SOCK_DGRAM,IPPROTO_UDPLITE)for IPv6.Availability: Linux >= 2.6.20, FreeBSD >= 10.1Added in version 3.9.AF_HYPERVis a Windows-only socket based interface for communicating\nwith Hyper-V hosts and guests. The address family is represented as a(vm_id,service_id)tuple where thevm_idandservice_idare\nUUID strings.Thevm_idis the virtual machine identifier or a set of known VMID values\nif the target is not a specific virtual machine. Known VMID constants\ndefined onsocketare:HV_GUID_ZEROHV_GUID_BROADCASTHV_GUID_WILDCARD- Used to bind on itself and accept connections from\nall partitions.HV_GUID_CHILDREN- Used to bind on itself and accept connection from\nchild partitions.HV_GUID_LOOPBACK- Used as a target to itself.HV_GUID_PARENT- When used as a bind accepts connection from the parent\npartition. When used as an address target it will connect to the parent partition.Theservice_idis the service identifier of the registered service.Added in version 3.12.If you use a hostname in thehostportion of IPv4/v6 socket address, the\nprogram may show a nondeterministic behavior, as Python uses the first address\nreturned from the DNS resolution.  The socket address will be resolved\ndifferently into an actual IPv4/v6 address, depending on the results from DNS\nresolution and/or the host configuration.  For deterministic behavior use a\nnumeric address inhostportion.All errors raise exceptions.  The normal exceptions for invalid argument types\nand out-of-memory conditions can be raised. Errors\nrelated to socket or address semantics raiseOSErroror one of its\nsubclasses.Non-blocking mode is supported throughsetblocking().  A\ngeneralization of this based on timeouts is supported throughsettimeout().Module contents\u00c2\u00b6The modulesocketexports the following elements.Exceptions\u00c2\u00b6exceptionsocket.error\u00c2\u00b6A deprecated alias ofOSError.Changed in version 3.3:FollowingPEP 3151, this class was made an alias ofOSError.exceptionsocket.herror\u00c2\u00b6A subclass ofOSError, this exception is raised for\naddress-related errors, i.e. for functions that useh_errnoin the POSIX\nC API, includinggethostbyname_ex()andgethostbyaddr().\nThe accompanying value is a pair(h_errno,string)representing an\nerror returned by a library call.h_errnois a numeric value, whilestringrepresents the description ofh_errno, as returned by thehstrerror()C function.Changed in version 3.3:This class was made a subclass ofOSError.exceptionsocket.gaierror\u00c2\u00b6A subclass ofOSError, this exception is raised for\naddress-related errors bygetaddrinfo()andgetnameinfo().\nThe accompanying value is a pair(error,string)representing an error\nreturned by a library call.stringrepresents the description oferror, as returned by thegai_strerror()C function.  The\nnumericerrorvalue will match one of theEAI_*constants\ndefined in this module.Changed in version 3.3:This class was made a subclass ofOSError.exceptionsocket.timeout\u00c2\u00b6A deprecated alias ofTimeoutError.A subclass ofOSError, this exception is raised when a timeout\noccurs on a socket which has had timeouts enabled via a prior call tosettimeout()(or implicitly throughsetdefaulttimeout()).  The accompanying value is a string\nwhose value is currently always \u00e2\u0080\u009ctimed out\u00e2\u0080\u009d.Changed in version 3.3:This class was made a subclass ofOSError.Changed in version 3.10:This class was made an alias ofTimeoutError.Constants\u00c2\u00b6The AF_* and SOCK_* constants are nowAddressFamilyandSocketKindIntEnumcollections.Added in version 3.4.socket.AF_UNIX\u00c2\u00b6socket.AF_INET\u00c2\u00b6socket.AF_INET6\u00c2\u00b6These constants represent the address (and protocol) families, used for the\nfirst argument tosocket().  If theAF_UNIXconstant is not\ndefined then this protocol is unsupported.  More constants may be available\ndepending on the system.socket.AF_UNSPEC\u00c2\u00b6AF_UNSPECmeans thatgetaddrinfo()should return socket addresses for any\naddress family (either IPv4, IPv6, or any other) that can be used.socket.SOCK_STREAM\u00c2\u00b6socket.SOCK_DGRAM\u00c2\u00b6socket.SOCK_RAW\u00c2\u00b6socket.SOCK_RDM\u00c2\u00b6socket.SOCK_SEQPACKET\u00c2\u00b6These constants represent the socket types, used for the second argument tosocket().  More constants may be available depending on the system.\n(OnlySOCK_STREAMandSOCK_DGRAMappear to be generally\nuseful.)socket.SOCK_CLOEXEC\u00c2\u00b6socket.SOCK_NONBLOCK\u00c2\u00b6These two constants, if defined, can be combined with the socket types and\nallow you to set some flags atomically (thus avoiding possible race\nconditions and the need for separate calls).See alsoSecure File Descriptor Handlingfor a more thorough explanation.Availability: Linux >= 2.6.27.Added in version 3.2.SO_*socket.SOMAXCONN\u00c2\u00b6MSG_*SOL_*SCM_*IPPROTO_*IPPORT_*INADDR_*IP_*IPV6_*EAI_*AI_*NI_*TCP_*Many constants of these forms, documented in the Unix documentation on sockets\nand/or the IP protocol, are also defined in the socket module. They are\ngenerally used in arguments to thesetsockopt()andgetsockopt()methods of socket objects.  In most cases, only those symbols that are defined\nin the Unix header files are defined; for a few symbols, default values are\nprovided.Changed in version 3.6:SO_DOMAIN,SO_PROTOCOL,SO_PEERSEC,SO_PASSSEC,TCP_USER_TIMEOUT,TCP_CONGESTIONwere added.Changed in version 3.6.5:On Windows,TCP_FASTOPEN,TCP_KEEPCNTappear if run-time Windows\nsupports.Changed in version 3.7:TCP_NOTSENT_LOWATwas added.On Windows,TCP_KEEPIDLE,TCP_KEEPINTVLappear if run-time Windows\nsupports.Changed in version 3.10:IP_RECVTOSwas added.\n AddedTCP_KEEPALIVE. On MacOS this constant can be used in the same\n way thatTCP_KEEPIDLEis used on Linux.Changed in version 3.11:AddedTCP_CONNECTION_INFO. On MacOS this constant can be used in the\nsame way thatTCP_INFOis used on Linux and BSD.Changed in version 3.12:AddedSO_RTABLEandSO_USER_COOKIE. On OpenBSD\nand FreeBSD respectively those constants can be used in the same way thatSO_MARKis used on Linux. Also added missing TCP socket options from\nLinux:TCP_MD5SIG,TCP_THIN_LINEAR_TIMEOUTS,TCP_THIN_DUPACK,TCP_REPAIR,TCP_REPAIR_QUEUE,TCP_QUEUE_SEQ,TCP_REPAIR_OPTIONS,TCP_TIMESTAMP,TCP_CC_INFO,TCP_SAVE_SYN,TCP_SAVED_SYN,TCP_REPAIR_WINDOW,TCP_FASTOPEN_CONNECT,TCP_ULP,TCP_MD5SIG_EXT,TCP_FASTOPEN_KEY,TCP_FASTOPEN_NO_COOKIE,TCP_ZEROCOPY_RECEIVE,TCP_INQ,TCP_TX_DELAY.\nAddedIP_PKTINFO,IP_UNBLOCK_SOURCE,IP_BLOCK_SOURCE,IP_ADD_SOURCE_MEMBERSHIP,IP_DROP_SOURCE_MEMBERSHIP.Changed in version 3.13:AddedSO_BINDTOIFINDEX. On Linux this constant can be used in the\nsame way thatSO_BINDTODEVICEis used, but with the index of a\nnetwork interface instead of its name.socket.AF_CAN\u00c2\u00b6socket.PF_CAN\u00c2\u00b6SOL_CAN_*CAN_*Many constants of these forms, documented in the Linux documentation, are\nalso defined in the socket module.Availability: Linux >= 2.6.25, NetBSD >= 8.Added in version 3.3.Changed in version 3.11:NetBSD support was added.Changed in version 3.13.4:Restored missingCAN_RAW_ERR_FILTERon Linux.socket.CAN_BCM\u00c2\u00b6CAN_BCM_*CAN_BCM, in the CAN protocol family, is the broadcast manager (BCM) protocol.\nBroadcast manager constants, documented in the Linux documentation, are also\ndefined in the socket module.Availability: Linux >= 2.6.25.NoteTheCAN_BCM_CAN_FD_FRAMEflag is only available on Linux >= 4.8.Added in version 3.4.socket.CAN_RAW_FD_FRAMES\u00c2\u00b6Enables CAN FD support in a CAN_RAW socket. This is disabled by default.\nThis allows your application to send both CAN and CAN FD frames; however,\nyou must accept both CAN and CAN FD frames when reading from the socket.This constant is documented in the Linux documentation.Availability: Linux >= 3.6.Added in version 3.5.socket.CAN_RAW_JOIN_FILTERS\u00c2\u00b6Joins the applied CAN filters such that only CAN frames that match all\ngiven CAN filters are passed to user space.This constant is documented in the Linux documentation.Availability: Linux >= 4.1.Added in version 3.9.socket.CAN_ISOTP\u00c2\u00b6CAN_ISOTP, in the CAN protocol family, is the ISO-TP (ISO 15765-2) protocol.\nISO-TP constants, documented in the Linux documentation.Availability: Linux >= 2.6.25.Added in version 3.7.socket.CAN_J1939\u00c2\u00b6CAN_J1939, in the CAN protocol family, is the SAE J1939 protocol.\nJ1939 constants, documented in the Linux documentation.Availability: Linux >= 5.4.Added in version 3.9.socket.AF_DIVERT\u00c2\u00b6socket.PF_DIVERT\u00c2\u00b6These two constants, documented in the FreeBSD divert(4) manual page, are\nalso defined in the socket module.Availability: FreeBSD >= 14.0.Added in version 3.12.socket.AF_PACKET\u00c2\u00b6socket.PF_PACKET\u00c2\u00b6PACKET_*Many constants of these forms, documented in the Linux documentation, are\nalso defined in the socket module.Availability: Linux >= 2.2.socket.ETH_P_ALL\u00c2\u00b6ETH_P_ALLcan be used in thesocketconstructor asprotofor theAF_PACKETfamily in order to\ncapture every packet, regardless of protocol.For more information, see thepacket(7)manpage.Availability: Linux.Added in version 3.12.socket.AF_RDS\u00c2\u00b6socket.PF_RDS\u00c2\u00b6socket.SOL_RDS\u00c2\u00b6RDS_*Many constants of these forms, documented in the Linux documentation, are\nalso defined in the socket module.Availability: Linux >= 2.6.30.Added in version 3.3.socket.SIO_RCVALL\u00c2\u00b6socket.SIO_KEEPALIVE_VALS\u00c2\u00b6socket.SIO_LOOPBACK_FAST_PATH\u00c2\u00b6RCVALL_*Constants for Windows\u00e2\u0080\u0099 WSAIoctl(). The constants are used as arguments to theioctl()method of socket objects.Changed in version 3.6:SIO_LOOPBACK_FAST_PATHwas added.TIPC_*TIPC related constants, matching the ones exported by the C socket API. See\nthe TIPC documentation for more information.socket.AF_ALG\u00c2\u00b6socket.SOL_ALG\u00c2\u00b6ALG_*Constants for Linux Kernel cryptography.Availability: Linux >= 2.6.38.Added in version 3.6.socket.AF_VSOCK\u00c2\u00b6socket.IOCTL_VM_SOCKETS_GET_LOCAL_CID\u00c2\u00b6VMADDR*SO_VM*Constants for Linux host/guest communication.Availability: Linux >= 4.8.Added in version 3.7.socket.AF_LINK\u00c2\u00b6Availability: BSD, macOS.Added in version 3.4.socket.has_ipv6\u00c2\u00b6This constant contains a boolean value which indicates if IPv6 is supported on\nthis platform.socket.BDADDR_ANY\u00c2\u00b6socket.BDADDR_LOCAL\u00c2\u00b6These are string constants containing Bluetooth addresses with special\nmeanings. For example,BDADDR_ANYcan be used to indicate\nany address when specifying the binding socket withBTPROTO_RFCOMM.socket.HCI_FILTER\u00c2\u00b6socket.HCI_TIME_STAMP\u00c2\u00b6socket.HCI_DATA_DIR\u00c2\u00b6For use withBTPROTO_HCI.HCI_FILTERis only\navailable on Linux and FreeBSD.HCI_TIME_STAMPandHCI_DATA_DIRare only available on Linux.socket.AF_QIPCRTR\u00c2\u00b6Constant for Qualcomm\u00e2\u0080\u0099s IPC router protocol, used to communicate with\nservice providing remote processors.Availability: Linux >= 4.7.socket.SCM_CREDS2\u00c2\u00b6socket.LOCAL_CREDS\u00c2\u00b6socket.LOCAL_CREDS_PERSISTENT\u00c2\u00b6LOCAL_CREDS and LOCAL_CREDS_PERSISTENT can be used\nwith SOCK_DGRAM, SOCK_STREAM sockets, equivalent to\nLinux/DragonFlyBSD SO_PASSCRED, while LOCAL_CREDS\nsends the credentials at first read, LOCAL_CREDS_PERSISTENT\nsends for each read, SCM_CREDS2 must be then used for\nthe latter for the message type.Added in version 3.11.Availability: FreeBSD.socket.SO_INCOMING_CPU\u00c2\u00b6Constant to optimize CPU locality, to be used in conjunction withSO_REUSEPORT.Added in version 3.11.Availability: Linux >= 3.9socket.AF_HYPERV\u00c2\u00b6socket.HV_PROTOCOL_RAW\u00c2\u00b6socket.HVSOCKET_CONNECT_TIMEOUT\u00c2\u00b6socket.HVSOCKET_CONNECT_TIMEOUT_MAX\u00c2\u00b6socket.HVSOCKET_CONNECTED_SUSPEND\u00c2\u00b6socket.HVSOCKET_ADDRESS_FLAG_PASSTHRU\u00c2\u00b6socket.HV_GUID_ZERO\u00c2\u00b6socket.HV_GUID_WILDCARD\u00c2\u00b6socket.HV_GUID_BROADCAST\u00c2\u00b6socket.HV_GUID_CHILDREN\u00c2\u00b6socket.HV_GUID_LOOPBACK\u00c2\u00b6socket.HV_GUID_PARENT\u00c2\u00b6Constants for Windows Hyper-V sockets for host/guest communications.Availability: Windows.Added in version 3.12.socket.ETHERTYPE_ARP\u00c2\u00b6socket.ETHERTYPE_IP\u00c2\u00b6socket.ETHERTYPE_IPV6\u00c2\u00b6socket.ETHERTYPE_VLAN\u00c2\u00b6IEEE 802.3 protocol number.\nconstants.Availability: Linux, FreeBSD, macOS.Added in version 3.12.socket.SHUT_RD\u00c2\u00b6socket.SHUT_WR\u00c2\u00b6socket.SHUT_RDWR\u00c2\u00b6These constants are used by theshutdown()method of socket objects.Availability: not WASI.Functions\u00c2\u00b6Creating sockets\u00c2\u00b6The following functions all createsocket objects.classsocket.socket(family=AF_INET,type=SOCK_STREAM,proto=0,fileno=None)\u00c2\u00b6Create a new socket using the given address family, socket type and protocol\nnumber.  The address family should beAF_INET(the default),AF_INET6,AF_UNIX,AF_CAN,AF_PACKET,\norAF_RDS. The socket type should beSOCK_STREAM(the\ndefault),SOCK_DGRAM,SOCK_RAWor perhaps one of the otherSOCK_constants. The protocol number is usually zero and may be omitted\nor in the case where the address family isAF_CANthe protocol\nshould be one ofCAN_RAW,CAN_BCM,CAN_ISOTPorCAN_J1939.Iffilenois specified, the values forfamily,type, andprotoare\nauto-detected from the specified file descriptor.  Auto-detection can be\noverruled by calling the function with explicitfamily,type, orprotoarguments.  This only affects how Python represents e.g. the return value\nofsocket.getpeername()but not the actual OS resource.  Unlikesocket.fromfd(),filenowill return the same socket and not a\nduplicate. This may help close a detached socket usingsocket.close().The newly created socket isnon-inheritable.Raises anauditing eventsocket.__new__with argumentsself,family,type,protocol.Changed in version 3.3:The AF_CAN family was added.\nThe AF_RDS family was added.Changed in version 3.4:The CAN_BCM protocol was added.Changed in version 3.4:The returned socket is now non-inheritable.Changed in version 3.7:The CAN_ISOTP protocol was added.Changed in version 3.7:WhenSOCK_NONBLOCKorSOCK_CLOEXECbit flags are applied totypethey are cleared, andsocket.typewill not reflect them.  They are still passed\nto the underlying systemsocket()call.  Therefore,sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM|socket.SOCK_NONBLOCK)will still create a non-blocking socket on OSes that supportSOCK_NONBLOCK, butsock.typewill be set tosocket.SOCK_STREAM.Changed in version 3.9:The CAN_J1939 protocol was added.Changed in version 3.10:The IPPROTO_MPTCP protocol was added.socket.socketpair([family[,type[,proto]]])\u00c2\u00b6Build a pair of connected socket objects using the given address family, socket\ntype, and protocol number.  Address family, socket type, and protocol number are\nas for thesocket()function above. The default family isAF_UNIXif defined on the platform; otherwise, the default isAF_INET.The newly created sockets arenon-inheritable.Changed in version 3.2:The returned socket objects now support the whole socket API, rather\nthan a subset.Changed in version 3.4:The returned sockets are now non-inheritable.Changed in version 3.5:Windows support added.socket.create_connection(address,timeout=GLOBAL_DEFAULT,source_address=None,*,all_errors=False)\u00c2\u00b6Connect to a TCP service listening on the internetaddress(a 2-tuple(host,port)), and return the socket object.  This is a higher-level\nfunction thansocket.connect(): ifhostis a non-numeric hostname,\nit will try to resolve it for bothAF_INETandAF_INET6,\nand then try to connect to all possible addresses in turn until a\nconnection succeeds.  This makes it easy to write clients that are\ncompatible to both IPv4 and IPv6.Passing the optionaltimeoutparameter will set the timeout on the\nsocket instance before attempting to connect.  If notimeoutis\nsupplied, the global default timeout setting returned bygetdefaulttimeout()is used.If supplied,source_addressmust be a 2-tuple(host,port)for the\nsocket to bind to as its source address before connecting.  If host or port\nare \u00e2\u0080\u0098\u00e2\u0080\u0099 or 0 respectively the OS default behavior will be used.When a connection cannot be created, an exception is raised. By default,\nit is the exception from the last address in the list. Ifall_errorsisTrue, it is anExceptionGroupcontaining the errors of all\nattempts.Changed in version 3.2:source_addresswas added.Changed in version 3.11:all_errorswas added.socket.create_server(address,*,family=AF_INET,backlog=None,reuse_port=False,dualstack_ipv6=False)\u00c2\u00b6Convenience function which creates a TCP socket bound toaddress(a 2-tuple(host,port)) and returns the socket object.familyshould be eitherAF_INETorAF_INET6.backlogis the queue size passed tosocket.listen(); if not specified\n, a default reasonable value is chosen.reuse_portdictates whether to set theSO_REUSEPORTsocket option.Ifdualstack_ipv6is true,familyisAF_INET6and the platform\nsupports it the socket will be able to accept both IPv4 and IPv6 connections,\nelse it will raiseValueError. Most POSIX platforms and Windows are\nsupposed to support this functionality.\nWhen this functionality is enabled the address returned bysocket.getpeername()when an IPv4 connection occurs will be an IPv6\naddress represented as an IPv4-mapped IPv6 address.\nIfdualstack_ipv6is false it will explicitly disable this functionality\non platforms that enable it by default (e.g. Linux).\nThis parameter can be used in conjunction withhas_dualstack_ipv6():importsocketaddr=(\"\",8080)# all interfaces, port 8080ifsocket.has_dualstack_ipv6():s=socket.create_server(addr,family=socket.AF_INET6,dualstack_ipv6=True)else:s=socket.create_server(addr)NoteOn POSIX platforms theSO_REUSEADDRsocket option is set in order to\nimmediately reuse previous sockets which were bound on the sameaddressand remained in TIME_WAIT state.Added in version 3.8.socket.has_dualstack_ipv6()\u00c2\u00b6ReturnTrueif the platform supports creating a TCP socket which can\nhandle both IPv4 and IPv6 connections.Added in version 3.8.socket.fromfd(fd,family,type,proto=0)\u00c2\u00b6Duplicate the file descriptorfd(an integer as returned by a file object\u00e2\u0080\u0099sfileno()method) and build a socket object from the result.  Address\nfamily, socket type and protocol number are as for thesocket()function\nabove. The file descriptor should refer to a socket, but this is not checked \u00e2\u0080\u0094\nsubsequent operations on the object may fail if the file descriptor is invalid.\nThis function is rarely needed, but can be used to get or set socket options on\na socket passed to a program as standard input or output (such as a server\nstarted by the Unix inet daemon).  The socket is assumed to be in blocking mode.The newly created socket isnon-inheritable.Changed in version 3.4:The returned socket is now non-inheritable.socket.fromshare(data)\u00c2\u00b6Instantiate a socket from data obtained from thesocket.share()method.  The socket is assumed to be in blocking mode.Availability: Windows.Added in version 3.3.socket.SocketType\u00c2\u00b6This is a Python type object that represents the socket object type. It is the\nsame astype(socket(...)).Other functions\u00c2\u00b6Thesocketmodule also offers various network-related services:socket.close(fd)\u00c2\u00b6Close a socket file descriptor. This is likeos.close(), but for\nsockets. On some platforms (most noticeable Windows)os.close()does not work for socket file descriptors.Added in version 3.7.socket.getaddrinfo(host,port,family=AF_UNSPEC,type=0,proto=0,flags=0)\u00c2\u00b6This function wraps the C functiongetaddrinfoof the underlying system.Translate thehost/portargument into a sequence of 5-tuples that contain\nall the necessary arguments for creating a socket connected to that service.hostis a domain name, a string representation of an IPv4/v6 address\norNone.portis a string service name such as'http', a numeric\nport number orNone.  By passingNoneas the value ofhostandport, you can passNULLto the underlying C API.Thefamily,typeandprotoarguments can be optionally specified\nin order to provide options and limit the list of addresses returned.\nPass their default values (AF_UNSPEC, 0, and 0, respectively)\nto not limit the results. See the note below for details.Theflagsargument can be one or several of theAI_*constants,\nand will influence how results are computed and returned.\nFor example,AI_NUMERICHOSTwill disable domain name resolution\nand will raise an error ifhostis a domain name.The function returns a list of 5-tuples with the following structure:(family,type,proto,canonname,sockaddr)In these tuples,family,type,protoare all integers and are\nmeant to be passed to thesocket()function.canonnamewill be\na string representing the canonical name of thehostifAI_CANONNAMEis part of theflagsargument; elsecanonnamewill be empty.sockaddris a tuple describing a socket address, whose\nformat depends on the returnedfamily(a(address,port)2-tuple forAF_INET, a(address,port,flowinfo,scope_id)4-tuple forAF_INET6), and is meant to be passed to thesocket.connect()method.NoteIf you intend to use results fromgetaddrinfo()to create a socket\n(rather than, for example, retrievecanonname),\nconsider limiting the results bytype(e.g.SOCK_STREAMorSOCK_DGRAM) and/orproto(e.g.IPPROTO_TCPorIPPROTO_UDP) that your application can handle.The behavior with default values offamily,type,protoandflagsis system-specific.Many systems (for example, most Linux configurations) will return a sorted\nlist of all matching addresses.\nThese addresses should generally be tried in order until a connection succeeds\n(possibly tried in parallel, for example, using aHappy Eyeballsalgorithm).\nIn these cases, limiting thetypeand/orprotocan help eliminate\nunsuccessful or unusable connection attempts.Some systems will, however, only return a single address.\n(For example, this was reported on Solaris and AIX configurations.)\nOn these systems, limiting thetypeand/orprotohelps ensure that\nthis address is usable.Raises anauditing eventsocket.getaddrinfowith argumentshost,port,family,type,protocol.The following example fetches address information for a hypothetical TCP\nconnection toexample.orgon port 80 (results may differ on your\nsystem if IPv6 isn\u00e2\u0080\u0099t enabled):>>>socket.getaddrinfo(\"example.org\",80,proto=socket.IPPROTO_TCP)[(socket.AF_INET6, socket.SOCK_STREAM,6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),(socket.AF_INET, socket.SOCK_STREAM,6, '', ('93.184.216.34', 80))]Changed in version 3.2:parameters can now be passed using keyword arguments.Changed in version 3.7:for IPv6 multicast addresses, string representing an address will not\ncontain%scope_idpart.socket.getfqdn([name])\u00c2\u00b6Return a fully qualified domain name forname. Ifnameis omitted or empty,\nit is interpreted as the local host.  To find the fully qualified name, the\nhostname returned bygethostbyaddr()is checked, followed by aliases for the\nhost, if available.  The first name which includes a period is selected.  In\ncase no fully qualified domain name is available andnamewas provided,\nit is returned unchanged.  Ifnamewas empty or equal to'0.0.0.0',\nthe hostname fromgethostname()is returned.socket.gethostbyname(hostname)\u00c2\u00b6Translate a host name to IPv4 address format.  The IPv4 address is returned as a\nstring, such as'100.50.200.5'.  If the host name is an IPv4 address itself\nit is returned unchanged.  Seegethostbyname_ex()for a more complete\ninterface.gethostbyname()does not support IPv6 name resolution, andgetaddrinfo()should be used instead for IPv4/v6 dual stack support.Raises anauditing eventsocket.gethostbynamewith argumenthostname.Availability: not WASI.socket.gethostbyname_ex(hostname)\u00c2\u00b6Translate a host name to IPv4 address format, extended interface. Return a\n3-tuple(hostname,aliaslist,ipaddrlist)wherehostnameis the host\u00e2\u0080\u0099s\nprimary host name,aliaslistis a (possibly\nempty) list of alternative host names for the same address, andipaddrlistis\na list of IPv4 addresses for the same interface on the same host (often but not\nalways a single address).gethostbyname_ex()does not support IPv6 name\nresolution, andgetaddrinfo()should be used instead for IPv4/v6 dual\nstack support.Raises anauditing eventsocket.gethostbynamewith argumenthostname.Availability: not WASI.socket.gethostname()\u00c2\u00b6Return a string containing the hostname of the machine where  the Python\ninterpreter is currently executing.Raises anauditing eventsocket.gethostnamewith no arguments.Note:gethostname()doesn\u00e2\u0080\u0099t always return the fully qualified domain\nname; usegetfqdn()for that.Availability: not WASI.socket.gethostbyaddr(ip_address)\u00c2\u00b6Return a 3-tuple(hostname,aliaslist,ipaddrlist)wherehostnameis the\nprimary host name responding to the givenip_address,aliaslistis a\n(possibly empty) list of alternative host names for the same address, andipaddrlistis a list of IPv4/v6 addresses for the same interface on the same\nhost (most likely containing only a single address). To find the fully qualified\ndomain name, use the functiongetfqdn().gethostbyaddr()supports\nboth IPv4 and IPv6.Raises anauditing eventsocket.gethostbyaddrwith argumentip_address.Availability: not WASI.socket.getnameinfo(sockaddr,flags)\u00c2\u00b6Translate a socket addresssockaddrinto a 2-tuple(host,port). Depending\non the settings offlags, the result can contain a fully qualified domain name\nor numeric address representation inhost.  Similarly,portcan contain a\nstring port name or a numeric port number.For IPv6 addresses,%scope_idis appended to the host part ifsockaddrcontains meaningfulscope_id. Usually this happens for multicast addresses.For more information aboutflagsyou can consultgetnameinfo(3).Raises anauditing eventsocket.getnameinfowith argumentsockaddr.Availability: not WASI.socket.getprotobyname(protocolname)\u00c2\u00b6Translate an internet protocol name (for example,'icmp') to a constant\nsuitable for passing as the (optional) third argument to thesocket()function.  This is usually only needed for sockets opened in \u00e2\u0080\u009craw\u00e2\u0080\u009d mode\n(SOCK_RAW); for the normal socket modes, the correct protocol is chosen\nautomatically if the protocol is omitted or zero.Availability: not WASI.socket.getservbyname(servicename[,protocolname])\u00c2\u00b6Translate an internet service name and protocol name to a port number for that\nservice.  The optional protocol name, if given, should be'tcp'or'udp', otherwise any protocol will match.Raises anauditing eventsocket.getservbynamewith argumentsservicename,protocolname.Availability: not WASI.socket.getservbyport(port[,protocolname])\u00c2\u00b6Translate an internet port number and protocol name to a service name for that\nservice.  The optional protocol name, if given, should be'tcp'or'udp', otherwise any protocol will match.Raises anauditing eventsocket.getservbyportwith argumentsport,protocolname.Availability: not WASI.socket.ntohl(x)\u00c2\u00b6Convert 32-bit positive integers from network to host byte order.  On machines\nwhere the host byte order is the same as network byte order, this is a no-op;\notherwise, it performs a 4-byte swap operation.socket.ntohs(x)\u00c2\u00b6Convert 16-bit positive integers from network to host byte order.  On machines\nwhere the host byte order is the same as network byte order, this is a no-op;\notherwise, it performs a 2-byte swap operation.Changed in version 3.10:RaisesOverflowErrorifxdoes not fit in a 16-bit unsigned\ninteger.socket.htonl(x)\u00c2\u00b6Convert 32-bit positive integers from host to network byte order.  On machines\nwhere the host byte order is the same as network byte order, this is a no-op;\notherwise, it performs a 4-byte swap operation.socket.htons(x)\u00c2\u00b6Convert 16-bit positive integers from host to network byte order.  On machines\nwhere the host byte order is the same as network byte order, this is a no-op;\notherwise, it performs a 2-byte swap operation.Changed in version 3.10:RaisesOverflowErrorifxdoes not fit in a 16-bit unsigned\ninteger.socket.inet_aton(ip_string)\u00c2\u00b6Convert an IPv4 address from dotted-quad string format (for example,\n\u00e2\u0080\u0098123.45.67.89\u00e2\u0080\u0099) to 32-bit packed binary format, as a bytes object four characters in\nlength.  This is useful when conversing with a program that uses the standard C\nlibrary and needs objects of typein_addr, which is the C type\nfor the 32-bit packed binary this function returns.inet_aton()also accepts strings with less than three dots; see the\nUnix manual pageinet(3)for details.If the IPv4 address string passed to this function is invalid,OSErrorwill be raised. Note that exactly what is valid depends on\nthe underlying C implementation ofinet_aton().inet_aton()does not support IPv6, andinet_pton()should be used\ninstead for IPv4/v6 dual stack support.socket.inet_ntoa(packed_ip)\u00c2\u00b6Convert a 32-bit packed IPv4 address (abytes-like objectfour\nbytes in length) to its standard dotted-quad string representation (for example,\n\u00e2\u0080\u0098123.45.67.89\u00e2\u0080\u0099).  This is useful when conversing with a program that uses the\nstandard C library and needs objects of typein_addr, which\nis the C type for the 32-bit packed binary data this function takes as an\nargument.If the byte sequence passed to this function is not exactly 4 bytes in\nlength,OSErrorwill be raised.inet_ntoa()does not\nsupport IPv6, andinet_ntop()should be used instead for IPv4/v6 dual\nstack support.Changed in version 3.5:Writablebytes-like objectis now accepted.socket.inet_pton(address_family,ip_string)\u00c2\u00b6Convert an IP address from its family-specific string format to a packed,\nbinary format.inet_pton()is useful when a library or network protocol\ncalls for an object of typein_addr(similar toinet_aton()) orin6_addr.Supported values foraddress_familyare currentlyAF_INETandAF_INET6. If the IP address stringip_stringis invalid,OSErrorwill be raised. Note that exactly what is valid depends on\nboth the value ofaddress_familyand the underlying implementation ofinet_pton().Availability: Unix, Windows.Changed in version 3.4:Windows support addedsocket.inet_ntop(address_family,packed_ip)\u00c2\u00b6Convert a packed IP address (abytes-like objectof some number of\nbytes) to its standard, family-specific string representation (for\nexample,'7.10.0.5'or'5aef:2b::8').inet_ntop()is useful when a library or network protocol returns an\nobject of typein_addr(similar toinet_ntoa()) orin6_addr.Supported values foraddress_familyare currentlyAF_INETandAF_INET6. If the bytes objectpacked_ipis not the correct\nlength for the specified address family,ValueErrorwill be raised.OSErroris raised for errors from the call toinet_ntop().Availability: Unix, Windows.Changed in version 3.4:Windows support addedChanged in version 3.5:Writablebytes-like objectis now accepted.socket.CMSG_LEN(length)\u00c2\u00b6Return the total length, without trailing padding, of an ancillary\ndata item with associated data of the givenlength.  This value\ncan often be used as the buffer size forrecvmsg()to\nreceive a single item of ancillary data, butRFC 3542requires\nportable applications to useCMSG_SPACE()and thus include\nspace for padding, even when the item will be the last in the\nbuffer.  RaisesOverflowErroriflengthis outside the\npermissible range of values.Availability: Unix, not WASI.Most Unix platforms.Added in version 3.3.socket.CMSG_SPACE(length)\u00c2\u00b6Return the buffer size needed forrecvmsg()to\nreceive an ancillary data item with associated data of the givenlength, along with any trailing padding.  The buffer space needed\nto receive multiple items is the sum of theCMSG_SPACE()values for their associated data lengths.  RaisesOverflowErroriflengthis outside the permissible range\nof values.Note that some systems might support ancillary data without\nproviding this function.  Also note that setting the buffer size\nusing the results of this function may not precisely limit the\namount of ancillary data that can be received, since additional\ndata may be able to fit into the padding area.Availability: Unix, not WASI.most Unix platforms.Added in version 3.3.socket.getdefaulttimeout()\u00c2\u00b6Return the default timeout in seconds (float) for new socket objects. A value\nofNoneindicates that new socket objects have no timeout. When the socket\nmodule is first imported, the default isNone.socket.setdefaulttimeout(timeout)\u00c2\u00b6Set the default timeout in seconds (float) for new socket objects.  When\nthe socket module is first imported, the default isNone.  Seesettimeout()for possible values and their respective\nmeanings.socket.sethostname(name)\u00c2\u00b6Set the machine\u00e2\u0080\u0099s hostname toname.  This will raise anOSErrorif you don\u00e2\u0080\u0099t have enough rights.Raises anauditing eventsocket.sethostnamewith argumentname.Availability: Unix, not Android.Added in version 3.3.socket.if_nameindex()\u00c2\u00b6Return a list of network interface information\n(index int, name string) tuples.OSErrorif the system call fails.Availability: Unix, Windows, not WASI.Added in version 3.3.Changed in version 3.8:Windows support was added.NoteOn Windows network interfaces have different names in different contexts\n(all names are examples):UUID:{FB605B73-AAC2-49A6-9A2F-25416AEA0573}name:ethernet_32770friendly name:vEthernet(nat)description:Hyper-VVirtualEthernetAdapterThis function returns names of the second form from the list,ethernet_32770in this example case.socket.if_nametoindex(if_name)\u00c2\u00b6Return a network interface index number corresponding to an\ninterface name.OSErrorif no interface with the given name exists.Availability: Unix, Windows, not WASI.Added in version 3.3.Changed in version 3.8:Windows support was added.See also\u00e2\u0080\u009cInterface name\u00e2\u0080\u009d is a name as documented inif_nameindex().socket.if_indextoname(if_index)\u00c2\u00b6Return a network interface name corresponding to an\ninterface index number.OSErrorif no interface with the given index exists.Availability: Unix, Windows, not WASI.Added in version 3.3.Changed in version 3.8:Windows support was added.See also\u00e2\u0080\u009cInterface name\u00e2\u0080\u009d is a name as documented inif_nameindex().socket.send_fds(sock,buffers,fds[,flags[,address]])\u00c2\u00b6Send the list of file descriptorsfdsover anAF_UNIXsocketsock.\nThefdsparameter is a sequence of file descriptors.\nConsultsendmsg()for the documentation of these parameters.Availability: Unix, not WASI.Unix platforms supportingsendmsg()andSCM_RIGHTSmechanism.Added in version 3.9.socket.recv_fds(sock,bufsize,maxfds[,flags])\u00c2\u00b6Receive up tomaxfdsfile descriptors from anAF_UNIXsocketsock.\nReturn(msg,list(fds),flags,addr).\nConsultrecvmsg()for the documentation of these parameters.Availability: Unix, not WASI.Unix platforms supportingrecvmsg()andSCM_RIGHTSmechanism.Added in version 3.9.NoteAny truncated integers at the end of the list of file descriptors.Socket Objects\u00c2\u00b6Socket objects have the following methods.  Except formakefile(), these correspond to Unix system calls applicable\nto sockets.Changed in version 3.2:Support for thecontext managerprotocol was added.  Exiting the\ncontext manager is equivalent to callingclose().socket.accept()\u00c2\u00b6Accept a connection. The socket must be bound to an address and listening for\nconnections. The return value is a pair(conn,address)whereconnis anewsocket object usable to send and receive data on the connection, andaddressis the address bound to the socket on the other end of the connection.The newly created socket isnon-inheritable.Changed in version 3.4:The socket is now non-inheritable.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.bind(address)\u00c2\u00b6Bind the socket toaddress.  The socket must not already be bound. (The format\nofaddressdepends on the address family \u00e2\u0080\u0094 see above.)Raises anauditing eventsocket.bindwith argumentsself,address.Availability: not WASI.socket.close()\u00c2\u00b6Mark the socket closed.  The underlying system resource (e.g. a file\ndescriptor) is also closed when all file objects frommakefile()are closed.  Once that happens, all future operations on the socket\nobject will fail. The remote end will receive no more data (after\nqueued data is flushed).Sockets are automatically closed when they are garbage-collected, but\nit is recommended toclose()them explicitly, or to use awithstatement around them.Changed in version 3.6:OSErroris now raised if an error occurs when the underlyingclose()call is made.Noteclose()releases the resource associated with a connection but\ndoes not necessarily close the connection immediately.  If you want\nto close the connection in a timely fashion, callshutdown()beforeclose().socket.connect(address)\u00c2\u00b6Connect to a remote socket ataddress. (The format ofaddressdepends on the\naddress family \u00e2\u0080\u0094 see above.)If the connection is interrupted by a signal, the method waits until the\nconnection completes, or raise aTimeoutErroron timeout, if the\nsignal handler doesn\u00e2\u0080\u0099t raise an exception and the socket is blocking or has\na timeout. For non-blocking sockets, the method raises anInterruptedErrorexception if the connection is interrupted by a\nsignal (or the exception raised by the signal handler).Raises anauditing eventsocket.connectwith argumentsself,address.Changed in version 3.5:The method now waits until the connection completes instead of raising anInterruptedErrorexception if the connection is interrupted by a\nsignal, the signal handler doesn\u00e2\u0080\u0099t raise an exception and the socket is\nblocking or has a timeout (see thePEP 475for the rationale).Availability: not WASI.socket.connect_ex(address)\u00c2\u00b6Likeconnect(address), but return an error indicator instead of raising an\nexception for errors returned by the C-levelconnect()call (other\nproblems, such as \u00e2\u0080\u009chost not found,\u00e2\u0080\u009d can still raise exceptions).  The error\nindicator is0if the operation succeeded, otherwise the value of theerrnovariable.  This is useful to support, for example, asynchronous\nconnects.Raises anauditing eventsocket.connectwith argumentsself,address.Availability: not WASI.socket.detach()\u00c2\u00b6Put the socket object into closed state without actually closing the\nunderlying file descriptor.  The file descriptor is returned, and can\nbe reused for other purposes.Added in version 3.2.socket.dup()\u00c2\u00b6Duplicate the socket.The newly created socket isnon-inheritable.Changed in version 3.4:The socket is now non-inheritable.Availability: not WASI.socket.fileno()\u00c2\u00b6Return the socket\u00e2\u0080\u0099s file descriptor (a small integer), or -1 on failure. This\nis useful withselect.select().Under Windows the small integer returned by this method cannot be used where a\nfile descriptor can be used (such asos.fdopen()).  Unix does not have\nthis limitation.socket.get_inheritable()\u00c2\u00b6Get theinheritable flagof the socket\u00e2\u0080\u0099s file\ndescriptor or socket\u00e2\u0080\u0099s handle:Trueif the socket can be inherited in\nchild processes,Falseif it cannot.Added in version 3.4.socket.getpeername()\u00c2\u00b6Return the remote address to which the socket is connected.  This is useful to\nfind out the port number of a remote IPv4/v6 socket, for instance. (The format\nof the address returned depends on the address family \u00e2\u0080\u0094 see above.)  On some\nsystems this function is not supported.socket.getsockname()\u00c2\u00b6Return the socket\u00e2\u0080\u0099s own address.  This is useful to find out the port number of\nan IPv4/v6 socket, for instance. (The format of the address returned depends on\nthe address family \u00e2\u0080\u0094 see above.)socket.getsockopt(level,optname[,buflen])\u00c2\u00b6Return the value of the given socket option (see the Unix man pagegetsockopt(2)).  The needed symbolic constants (SO_* etc.)\nare defined in this module.  Ifbuflenis absent, an integer option is assumed\nand its integer value is returned by the function.  Ifbuflenis present, it\nspecifies the maximum length of the buffer used to receive the option in, and\nthis buffer is returned as a bytes object.  It is up to the caller to decode the\ncontents of the buffer (see the optional built-in modulestructfor a way\nto decode C structures encoded as byte strings).Availability: not WASI.socket.getblocking()\u00c2\u00b6ReturnTrueif socket is in blocking mode,Falseif in\nnon-blocking.This is equivalent to checkingsocket.gettimeout()!=0.Added in version 3.7.socket.gettimeout()\u00c2\u00b6Return the timeout in seconds (float) associated with socket operations,\norNoneif no timeout is set.  This reflects the last call tosetblocking()orsettimeout().socket.ioctl(control,option)\u00c2\u00b6Platform:WindowsTheioctl()method is a limited interface to the WSAIoctl system\ninterface.  Please refer to theWin32 documentationfor more\ninformation.On other platforms, the genericfcntl.fcntl()andfcntl.ioctl()functions may be used; they accept a socket object as their first argument.Currently only the following control codes are supported:SIO_RCVALL,SIO_KEEPALIVE_VALS, andSIO_LOOPBACK_FAST_PATH.Changed in version 3.6:SIO_LOOPBACK_FAST_PATHwas added.socket.listen([backlog])\u00c2\u00b6Enable a server to accept connections.  Ifbacklogis specified, it must\nbe at least 0 (if it is lower, it is set to 0); it specifies the number of\nunaccepted connections that the system will allow before refusing new\nconnections. If not specified, a default reasonable value is chosen.Availability: not WASI.Changed in version 3.5:Thebacklogparameter is now optional.socket.makefile(mode='r',buffering=None,*,encoding=None,errors=None,newline=None)\u00c2\u00b6Return afile objectassociated with the socket.  The exact returned\ntype depends on the arguments given tomakefile().  These arguments are\ninterpreted the same way as by the built-inopen()function, except\nthe only supportedmodevalues are'r'(default),'w','b', or\na combination of those.The socket must be in blocking mode; it can have a timeout, but the file\nobject\u00e2\u0080\u0099s internal buffer may end up in an inconsistent state if a timeout\noccurs.Closing the file object returned bymakefile()won\u00e2\u0080\u0099t close the\noriginal socket unless all other file objects have been closed andsocket.close()has been called on the socket object.NoteOn Windows, the file-like object created bymakefile()cannot be\nused where a file object with a file descriptor is expected, such as the\nstream arguments ofsubprocess.Popen().socket.recv(bufsize[,flags])\u00c2\u00b6Receive data from the socket.  The return value is a bytes object representing the\ndata received.  The maximum amount of data to be received at once is specified\nbybufsize. A returned empty bytes object indicates that the client has disconnected.\nSee the Unix manual pagerecv(2)for the meaning of the optional argumentflags; it defaults to zero.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.recvfrom(bufsize[,flags])\u00c2\u00b6Receive data from the socket.  The return value is a pair(bytes,address)wherebytesis a bytes object representing the data received andaddressis the\naddress of the socket sending the data.  See the Unix manual pagerecv(2)for the meaning of the optional argumentflags; it defaults\nto zero. (The format ofaddressdepends on the address family \u00e2\u0080\u0094 see above.)Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).Changed in version 3.7:For multicast IPv6 address, first item ofaddressdoes not contain%scope_idpart anymore. In order to get full IPv6 address usegetnameinfo().socket.recvmsg(bufsize[,ancbufsize[,flags]])\u00c2\u00b6Receive normal data (up tobufsizebytes) and ancillary data from\nthe socket.  Theancbufsizeargument sets the size in bytes of\nthe internal buffer used to receive the ancillary data; it defaults\nto 0, meaning that no ancillary data will be received.  Appropriate\nbuffer sizes for ancillary data can be calculated usingCMSG_SPACE()orCMSG_LEN(), and items which do not fit\ninto the buffer might be truncated or discarded.  Theflagsargument defaults to 0 and has the same meaning as forrecv().The return value is a 4-tuple:(data,ancdata,msg_flags,address).  Thedataitem is abytesobject holding the\nnon-ancillary data received.  Theancdataitem is a list of zero\nor more tuples(cmsg_level,cmsg_type,cmsg_data)representing\nthe ancillary data (control messages) received:cmsg_levelandcmsg_typeare integers specifying the protocol level and\nprotocol-specific type respectively, andcmsg_datais abytesobject holding the associated data.  Themsg_flagsitem is the bitwise OR of various flags indicating conditions on\nthe received message; see your system documentation for details.\nIf the receiving socket is unconnected,addressis the address of\nthe sending socket, if available; otherwise, its value is\nunspecified.On some systems,sendmsg()andrecvmsg()can be used to\npass file descriptors between processes over anAF_UNIXsocket.  When this facility is used (it is often restricted toSOCK_STREAMsockets),recvmsg()will return, in its\nancillary data, items of the form(socket.SOL_SOCKET,socket.SCM_RIGHTS,fds), wherefdsis abytesobject\nrepresenting the new file descriptors as a binary array of the\nnative Cinttype.  Ifrecvmsg()raises an\nexception after the system call returns, it will first attempt to\nclose any file descriptors received via this mechanism.Some systems do not indicate the truncated length of ancillary data\nitems which have been only partially received.  If an item appears\nto extend beyond the end of the buffer,recvmsg()will issue\naRuntimeWarning, and will return the part of it which is\ninside the buffer provided it has not been truncated before the\nstart of its associated data.On systems which support theSCM_RIGHTSmechanism, the\nfollowing function will receive up tomaxfdsfile descriptors,\nreturning the message data and a list containing the descriptors\n(while ignoring unexpected conditions such as unrelated control\nmessages being received).  See alsosendmsg().importsocket,arraydefrecv_fds(sock,msglen,maxfds):fds=array.array(\"i\")# Array of intsmsg,ancdata,flags,addr=sock.recvmsg(msglen,socket.CMSG_LEN(maxfds*fds.itemsize))forcmsg_level,cmsg_type,cmsg_datainancdata:ifcmsg_level==socket.SOL_SOCKETandcmsg_type==socket.SCM_RIGHTS:# Append data, ignoring any truncated integers at the end.fds.frombytes(cmsg_data[:len(cmsg_data)-(len(cmsg_data)%fds.itemsize)])returnmsg,list(fds)Availability: Unix.Most Unix platforms.Added in version 3.3.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.recvmsg_into(buffers[,ancbufsize[,flags]])\u00c2\u00b6Receive normal data and ancillary data from the socket, behaving asrecvmsg()would, but scatter the non-ancillary data into a\nseries of buffers instead of returning a new bytes object.  Thebuffersargument must be an iterable of objects that export\nwritable buffers (e.g.bytearrayobjects); these will be\nfilled with successive chunks of the non-ancillary data until it\nhas all been written or there are no more buffers.  The operating\nsystem may set a limit (sysconf()valueSC_IOV_MAX)\non the number of buffers that can be used.  Theancbufsizeandflagsarguments have the same meaning as forrecvmsg().The return value is a 4-tuple:(nbytes,ancdata,msg_flags,address), wherenbytesis the total number of bytes of\nnon-ancillary data written into the buffers, andancdata,msg_flagsandaddressare the same as forrecvmsg().Example:>>>importsocket>>>s1,s2=socket.socketpair()>>>b1=bytearray(b'----')>>>b2=bytearray(b'0123456789')>>>b3=bytearray(b'--------------')>>>s1.send(b'Mary had a little lamb')22>>>s2.recvmsg_into([b1,memoryview(b2)[2:9],b3])(22, [], 0, None)>>>[b1,b2,b3][bytearray(b'Mary'), bytearray(b'01 had a 9'), bytearray(b'little lamb---')]Availability: Unix.Most Unix platforms.Added in version 3.3.socket.recvfrom_into(buffer[,nbytes[,flags]])\u00c2\u00b6Receive data from the socket, writing it intobufferinstead of creating a\nnew bytestring.  The return value is a pair(nbytes,address)wherenbytesis\nthe number of bytes received andaddressis the address of the socket sending\nthe data.  See the Unix manual pagerecv(2)for the meaning of the\noptional argumentflags; it defaults to zero.  (The format ofaddressdepends on the address family \u00e2\u0080\u0094 see above.)socket.recv_into(buffer[,nbytes[,flags]])\u00c2\u00b6Receive up tonbytesbytes from the socket, storing the data into a buffer\nrather than creating a new bytestring.  Ifnbytesis not specified (or 0),\nreceive up to the size available in the given buffer.  Returns the number of\nbytes received.  See the Unix manual pagerecv(2)for the meaning\nof the optional argumentflags; it defaults to zero.socket.send(bytes[,flags])\u00c2\u00b6Send data to the socket.  The socket must be connected to a remote socket.  The\noptionalflagsargument has the same meaning as forrecv()above.\nReturns the number of bytes sent. Applications are responsible for checking that\nall data has been sent; if only some of the data was transmitted, the\napplication needs to attempt delivery of the remaining data. For further\ninformation on this topic, consult theSocket Programming HOWTO.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.sendall(bytes[,flags])\u00c2\u00b6Send data to the socket.  The socket must be connected to a remote socket.  The\noptionalflagsargument has the same meaning as forrecv()above.\nUnlikesend(), this method continues to send data frombytesuntil\neither all data has been sent or an error occurs.Noneis returned on\nsuccess.  On error, an exception is raised, and there is no way to determine how\nmuch data, if any, was successfully sent.Changed in version 3.5:The socket timeout is no longer reset each time data is sent successfully.\nThe socket timeout is now the maximum total duration to send all data.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.sendto(bytes,address)\u00c2\u00b6socket.sendto(bytes,flags,address)Send data to the socket.  The socket should not be connected to a remote socket,\nsince the destination socket is specified byaddress.  The optionalflagsargument has the same meaning as forrecv()above.  Return the number of\nbytes sent. (The format ofaddressdepends on the address family \u00e2\u0080\u0094 see\nabove.)Raises anauditing eventsocket.sendtowith argumentsself,address.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.sendmsg(buffers[,ancdata[,flags[,address]]])\u00c2\u00b6Send normal and ancillary data to the socket, gathering the\nnon-ancillary data from a series of buffers and concatenating it\ninto a single message.  Thebuffersargument specifies the\nnon-ancillary data as an iterable ofbytes-like objects(e.g.bytesobjects); the operating system may set a limit\n(sysconf()valueSC_IOV_MAX) on the number of buffers\nthat can be used.  Theancdataargument specifies the ancillary\ndata (control messages) as an iterable of zero or more tuples(cmsg_level,cmsg_type,cmsg_data), wherecmsg_levelandcmsg_typeare integers specifying the protocol level and\nprotocol-specific type respectively, andcmsg_datais a\nbytes-like object holding the associated data.  Note that\nsome systems (in particular, systems withoutCMSG_SPACE())\nmight support sending only one control message per call.  Theflagsargument defaults to 0 and has the same meaning as forsend().  Ifaddressis supplied and notNone, it sets a\ndestination address for the message.  The return value is the\nnumber of bytes of non-ancillary data sent.The following function sends the list of file descriptorsfdsover anAF_UNIXsocket, on systems which support theSCM_RIGHTSmechanism.  See alsorecvmsg().importsocket,arraydefsend_fds(sock,msg,fds):returnsock.sendmsg([msg],[(socket.SOL_SOCKET,socket.SCM_RIGHTS,array.array(\"i\",fds))])Availability: Unix, not WASI.Most Unix platforms.Raises anauditing eventsocket.sendmsgwith argumentsself,address.Added in version 3.3.Changed in version 3.5:If the system call is interrupted and the signal handler does not raise\nan exception, the method now retries the system call instead of raising\nanInterruptedErrorexception (seePEP 475for the rationale).socket.sendmsg_afalg([msg,]*,op[,iv[,assoclen[,flags]]])\u00c2\u00b6Specialized version ofsendmsg()forAF_ALGsocket.\nSet mode, IV, AEAD associated data length and flags forAF_ALGsocket.Availability: Linux >= 2.6.38.Added in version 3.6.socket.sendfile(file,offset=0,count=None)\u00c2\u00b6Send a file until EOF is reached by using high-performanceos.sendfileand return the total number of bytes which were sent.filemust be a regular file object opened in binary mode. Ifos.sendfileis not available (e.g. Windows) orfileis not a\nregular filesend()will be used instead.offsettells from where to\nstart reading the file. If specified,countis the total number of bytes\nto transmit as opposed to sending the file until EOF is reached. File\nposition is updated on return or also in case of error in which casefile.tell()can be used to figure out the number of\nbytes which were sent. The socket must be ofSOCK_STREAMtype.\nNon-blocking sockets are not supported.Added in version 3.5.socket.set_inheritable(inheritable)\u00c2\u00b6Set theinheritable flagof the socket\u00e2\u0080\u0099s file\ndescriptor or socket\u00e2\u0080\u0099s handle.Added in version 3.4.socket.setblocking(flag)\u00c2\u00b6Set blocking or non-blocking mode of the socket: ifflagis false, the\nsocket is set to non-blocking, else to blocking mode.This method is a shorthand for certainsettimeout()calls:sock.setblocking(True)is equivalent tosock.settimeout(None)sock.setblocking(False)is equivalent tosock.settimeout(0.0)Changed in version 3.7:The method no longer appliesSOCK_NONBLOCKflag onsocket.type.socket.settimeout(value)\u00c2\u00b6Set a timeout on blocking socket operations.  Thevalueargument can be a\nnonnegative floating-point number expressing seconds, orNone.\nIf a non-zero value is given, subsequent socket operations will raise atimeoutexception if the timeout periodvaluehas elapsed before\nthe operation has completed.  If zero is given, the socket is put in\nnon-blocking mode. IfNoneis given, the socket is put in blocking mode.For further information, please consult thenotes on socket timeouts.Changed in version 3.7:The method no longer togglesSOCK_NONBLOCKflag onsocket.type.socket.setsockopt(level,optname,value:int)\u00c2\u00b6socket.setsockopt(level,optname,value:buffer)socket.setsockopt(level,optname,None,optlen:int)Set the value of the given socket option (see the Unix manual pagesetsockopt(2)).  The needed symbolic constants are defined in this\nmodule (SO_* etc. <socket-unix-constants>).  The value can be an integer,Noneor abytes-like objectrepresenting a buffer. In the later\ncase it is up to the caller to ensure that the bytestring contains the\nproper bits (see the optional built-in modulestructfor a way to\nencode C structures as bytestrings). Whenvalueis set toNone,optlenargument is required. It\u00e2\u0080\u0099s equivalent to callsetsockopt()C\nfunction withoptval=NULLandoptlen=optlen.Changed in version 3.5:Writablebytes-like objectis now accepted.Changed in version 3.6:setsockopt(level, optname, None, optlen: int) form added.Availability: not WASI.socket.shutdown(how)\u00c2\u00b6Shut down one or both halves of the connection.  IfhowisSHUT_RD,\nfurther receives are disallowed.  IfhowisSHUT_WR, further sends\nare disallowed.  IfhowisSHUT_RDWR, further sends and receives are\ndisallowed.Availability: not WASI.socket.share(process_id)\u00c2\u00b6Duplicate a socket and prepare it for sharing with a target process.  The\ntarget process must be provided withprocess_id.  The resulting bytes object\ncan then be passed to the target process using some form of interprocess\ncommunication and the socket can be recreated there usingfromshare().\nOnce this method has been called, it is safe to close the socket since\nthe operating system has already duplicated it for the target process.Availability: Windows.Added in version 3.3.Note that there are no methodsread()orwrite(); userecv()andsend()withoutflagsargument instead.Socket objects also have these (read-only) attributes that correspond to the\nvalues given to thesocketconstructor.socket.family\u00c2\u00b6The socket family.socket.type\u00c2\u00b6The socket type.socket.proto\u00c2\u00b6The socket protocol.Notes on socket timeouts\u00c2\u00b6A socket object can be in one of three modes: blocking, non-blocking, or\ntimeout.  Sockets are by default always created in blocking mode, but this\ncan be changed by callingsetdefaulttimeout().Inblocking mode, operations block until complete or the system returns\nan error (such as connection timed out).Innon-blocking mode, operations fail (with an error that is unfortunately\nsystem-dependent) if they cannot be completed immediately: functions from theselectmodule can be used to know when and whether a socket is available\nfor reading or writing.Intimeout mode, operations fail if they cannot be completed within the\ntimeout specified for the socket (they raise atimeoutexception)\nor if the system returns an error.NoteAt the operating system level, sockets intimeout modeare internally set\nin non-blocking mode.  Also, the blocking and timeout modes are shared between\nfile descriptors and socket objects that refer to the same network endpoint.\nThis implementation detail can have visible consequences if e.g. you decide\nto use thefileno()of a socket.Timeouts and theconnectmethod\u00c2\u00b6Theconnect()operation is also subject to the timeout\nsetting, and in general it is recommended to callsettimeout()before callingconnect()or pass a timeout parameter tocreate_connection().  However, the system network stack may also\nreturn a connection timeout error of its own regardless of any Python socket\ntimeout setting.Timeouts and theacceptmethod\u00c2\u00b6Ifgetdefaulttimeout()is notNone, sockets returned by\ntheaccept()method inherit that timeout.  Otherwise, the\nbehaviour depends on settings of the listening socket:if the listening socket is inblocking modeor intimeout mode,\nthe socket returned byaccept()is inblocking mode;if the listening socket is innon-blocking mode, whether the socket\nreturned byaccept()is in blocking or non-blocking mode\nis operating system-dependent.  If you want to ensure cross-platform\nbehaviour, it is recommended you manually override this setting.Example\u00c2\u00b6Here are four minimal example programs using the TCP/IP protocol: a server that\nechoes all data that it receives back (servicing only one client), and a client\nusing it.  Note that a server must perform the sequencesocket(),bind(),listen(),accept()(possibly\nrepeating theaccept()to service more than one client), while a\nclient only needs the sequencesocket(),connect().  Also\nnote that the server does notsendall()/recv()on\nthe socket it is listening on but on the new socket returned byaccept().The first two examples support IPv4 only.# Echo server programimportsocketHOST=''# Symbolic name meaning all available interfacesPORT=50007# Arbitrary non-privileged portwithsocket.socket(socket.AF_INET,socket.SOCK_STREAM)ass:s.bind((HOST,PORT))s.listen(1)conn,addr=s.accept()withconn:print('Connected by',addr)whileTrue:data=conn.recv(1024)ifnotdata:breakconn.sendall(data)# Echo client programimportsocketHOST='daring.cwi.nl'# The remote hostPORT=50007# The same port as used by the serverwithsocket.socket(socket.AF_INET,socket.SOCK_STREAM)ass:s.connect((HOST,PORT))s.sendall(b'Hello, world')data=s.recv(1024)print('Received',repr(data))The next two examples are identical to the above two, but support both IPv4 and\nIPv6. The server side will listen to the first address family available (it\nshould listen to both instead). On most of IPv6-ready systems, IPv6 will take\nprecedence and the server may not accept IPv4 traffic. The client side will try\nto connect to all the addresses returned as a result of the name resolution, and\nsends traffic to the first one connected successfully.# Echo server programimportsocketimportsysHOST=None# Symbolic name meaning all available interfacesPORT=50007# Arbitrary non-privileged ports=Noneforresinsocket.getaddrinfo(HOST,PORT,socket.AF_UNSPEC,socket.SOCK_STREAM,0,socket.AI_PASSIVE):af,socktype,proto,canonname,sa=restry:s=socket.socket(af,socktype,proto)exceptOSErrorasmsg:s=Nonecontinuetry:s.bind(sa)s.listen(1)exceptOSErrorasmsg:s.close()s=NonecontinuebreakifsisNone:print('could not open socket')sys.exit(1)conn,addr=s.accept()withconn:print('Connected by',addr)whileTrue:data=conn.recv(1024)ifnotdata:breakconn.send(data)# Echo client programimportsocketimportsysHOST='daring.cwi.nl'# The remote hostPORT=50007# The same port as used by the servers=Noneforresinsocket.getaddrinfo(HOST,PORT,socket.AF_UNSPEC,socket.SOCK_STREAM):af,socktype,proto,canonname,sa=restry:s=socket.socket(af,socktype,proto)exceptOSErrorasmsg:s=Nonecontinuetry:s.connect(sa)exceptOSErrorasmsg:s.close()s=NonecontinuebreakifsisNone:print('could not open socket')sys.exit(1)withs:s.sendall(b'Hello, world')data=s.recv(1024)print('Received',repr(data))The next example shows how to write a very simple network sniffer with raw\nsockets on Windows. The example requires administrator privileges to modify\nthe interface:importsocket# the public network interfaceHOST=socket.gethostbyname(socket.gethostname())# create a raw socket and bind it to the public interfaces=socket.socket(socket.AF_INET,socket.SOCK_RAW,socket.IPPROTO_IP)s.bind((HOST,0))# Include IP headerss.setsockopt(socket.IPPROTO_IP,socket.IP_HDRINCL,1)# receive all packetss.ioctl(socket.SIO_RCVALL,socket.RCVALL_ON)# receive a packetprint(s.recvfrom(65565))# disabled promiscuous modes.ioctl(socket.SIO_RCVALL,socket.RCVALL_OFF)The next example shows how to use the socket interface to communicate to a CAN\nnetwork using the raw socket protocol. To use CAN with the broadcast\nmanager protocol instead, open a socket with:socket.socket(socket.AF_CAN,socket.SOCK_DGRAM,socket.CAN_BCM)After binding (CAN_RAW) or connecting (CAN_BCM) the socket, you\ncan use thesocket.send()andsocket.recv()operations (and\ntheir counterparts) on the socket object as usual.This last example might require special privileges:importsocketimportstruct# CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>)can_frame_fmt=\"=IB3x8s\"can_frame_size=struct.calcsize(can_frame_fmt)defbuild_can_frame(can_id,data):can_dlc=len(data)data=data.ljust(8,b'\\x00')returnstruct.pack(can_frame_fmt,can_id,can_dlc,data)defdissect_can_frame(frame):can_id,can_dlc,data=struct.unpack(can_frame_fmt,frame)return(can_id,can_dlc,data[:can_dlc])# create a raw socket and bind it to the 'vcan0' interfaces=socket.socket(socket.AF_CAN,socket.SOCK_RAW,socket.CAN_RAW)s.bind(('vcan0',))whileTrue:cf,addr=s.recvfrom(can_frame_size)print('Received: can_id=%x, can_dlc=%x, data=%s'%dissect_can_frame(cf))try:s.send(cf)exceptOSError:print('Error sending CAN frame')try:s.send(build_can_frame(0x01,b'\\x01\\x02\\x03'))exceptOSError:print('Error sending CAN frame')Running an example several times with too small delay between executions, could\nlead to this error:OSError:[Errno98]AddressalreadyinuseThis is because the previous execution has left the socket in aTIME_WAITstate, and can\u00e2\u0080\u0099t be immediately reused.There is asocketflag to set, in order to prevent this,socket.SO_REUSEADDR:s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)s.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1)s.bind((HOST,PORT))theSO_REUSEADDRflag tells the kernel to reuse a local socket inTIME_WAITstate, without waiting for its natural timeout to expire.See alsoFor an introduction to socket programming (in C), see the following papers:An Introductory 4.3BSD Interprocess Communication Tutorial, by Stuart SechrestAn Advanced 4.3BSD Interprocess Communication Tutorial, by Samuel J.  Leffler et\nal,both in the UNIX Programmer\u00e2\u0080\u0099s Manual, Supplementary Documents 1 (sections\nPS1:7 and PS1:8).  The platform-specific reference material for the various\nsocket-related system calls are also a valuable source of information on the\ndetails of socket semantics.  For Unix, refer to the manual pages; for Windows,\nsee the WinSock (or Winsock 2) specification.  For IPv6-ready APIs, readers may\nwant to refer toRFC 3493titled Basic Socket Interface Extensions for IPv6."
        ],
        "code_blocks": [
          "socket",
          "connect",
          "accept",
          "ssl",
          "socket",
          "socket",
          "socket()",
          "read()",
          "write()",
          "socketserver",
          "ssl",
          "AF_UNIX",
          "'surrogateescape'",
          "AF_UNIX",
          "(host,port)",
          "AF_INET",
          "'daring.cwi.nl'",
          "'100.50.200.5'",
          "''",
          "INADDR_ANY",
          "'<broadcast>'",
          "INADDR_BROADCAST",
          "AF_INET6",
          "(host,port,flowinfo,scope_id)",
          "sin6_flowinfo",
          "sin6_scope_id",
          "structsockaddr_in6",
          "socket",
          "%scope_id",
          "zoneid",
          "AF_NETLINK",
          "(pid,groups)",
          "AF_TIPC",
          "(addr_type,v1,v2,v3[,scope])",
          "TIPC_ADDR_NAMESEQ",
          "TIPC_ADDR_NAME",
          "TIPC_ADDR_ID",
          "TIPC_ZONE_SCOPE",
          "TIPC_CLUSTER_SCOPE",
          "TIPC_NODE_SCOPE",
          "TIPC_ADDR_NAME",
          "TIPC_ADDR_NAMESEQ",
          "TIPC_ADDR_ID",
          "(interface,)",
          "AF_CAN",
          "'can0'",
          "''",
          "CAN_ISOTP",
          "(interface,rx_addr,tx_addr)",
          "CAN_J1939",
          "(interface,name,pgn,addr)",
          "(id,unit)",
          "SYSPROTO_CONTROL",
          "PF_SYSTEM",
          "AF_BLUETOOTH",
          "BTPROTO_L2CAP",
          "(bdaddr,psm)",
          "bdaddr",
          "psm",
          "BTPROTO_RFCOMM",
          "(bdaddr,channel)",
          "bdaddr",
          "channel",
          "BTPROTO_HCI",
          "(device_id,)",
          "device_id",
          "bdaddr",
          "bdaddr",
          "BTPROTO_SCO",
          "bdaddr",
          "bdaddr",
          "bytes",
          "'12:23:34:45:56:67'",
          "b'12:23:34:45:56:67'",
          "AF_ALG",
          "(type,name[,feat[,mask]])",
          "aead",
          "hash",
          "skcipher",
          "rng",
          "sha256",
          "hmac(sha256)",
          "cbc(aes)",
          "drbg_nopr_ctr_aes256",
          "AF_VSOCK",
          "(CID,port)",
          "AF_PACKET",
          "(ifname,proto[,pkttype[,hatype[,addr]]])",
          "ETH_P_ALL",
          "PACKET_HOST",
          "PACKET_BROADCAST",
          "PACKET_MULTICAST",
          "PACKET_OTHERHOST",
          "PACKET_OUTGOING",
          "AF_QIPCRTR",
          "(node,port)",
          "IPPROTO_UDPLITE",
          "self.setsockopt(IPPROTO_UDPLITE,UDPLITE_SEND_CSCOV,length)",
          "self.setsockopt(IPPROTO_UDPLITE,UDPLITE_RECV_CSCOV,length)",
          "length",
          "range(8,2**16,8)",
          "socket(AF_INET,SOCK_DGRAM,IPPROTO_UDPLITE)",
          "socket(AF_INET6,SOCK_DGRAM,IPPROTO_UDPLITE)",
          "AF_HYPERV",
          "(vm_id,service_id)",
          "vm_id",
          "service_id",
          "vm_id",
          "socket",
          "HV_GUID_ZERO",
          "HV_GUID_BROADCAST",
          "HV_GUID_WILDCARD",
          "HV_GUID_CHILDREN",
          "HV_GUID_LOOPBACK",
          "HV_GUID_PARENT",
          "service_id",
          "OSError",
          "setblocking()",
          "settimeout()",
          "socket",
          "OSError",
          "OSError",
          "OSError",
          "gethostbyname_ex()",
          "gethostbyaddr()",
          "(h_errno,string)",
          "hstrerror()",
          "OSError",
          "OSError",
          "getaddrinfo()",
          "getnameinfo()",
          "(error,string)",
          "gai_strerror()",
          "EAI_*",
          "OSError",
          "TimeoutError",
          "OSError",
          "settimeout()",
          "setdefaulttimeout()",
          "OSError",
          "TimeoutError",
          "AddressFamily",
          "SocketKind",
          "IntEnum",
          "socket()",
          "AF_UNIX",
          "AF_UNSPEC",
          "getaddrinfo()",
          "socket()",
          "SOCK_STREAM",
          "SOCK_DGRAM",
          "setsockopt()",
          "getsockopt()",
          "SO_DOMAIN",
          "SO_PROTOCOL",
          "SO_PEERSEC",
          "SO_PASSSEC",
          "TCP_USER_TIMEOUT",
          "TCP_CONGESTION",
          "TCP_FASTOPEN",
          "TCP_KEEPCNT",
          "TCP_NOTSENT_LOWAT",
          "TCP_KEEPIDLE",
          "TCP_KEEPINTVL",
          "IP_RECVTOS",
          "TCP_KEEPALIVE",
          "TCP_KEEPIDLE",
          "TCP_CONNECTION_INFO",
          "TCP_INFO",
          "SO_RTABLE",
          "SO_USER_COOKIE",
          "SO_MARK",
          "TCP_MD5SIG",
          "TCP_THIN_LINEAR_TIMEOUTS",
          "TCP_THIN_DUPACK",
          "TCP_REPAIR",
          "TCP_REPAIR_QUEUE",
          "TCP_QUEUE_SEQ",
          "TCP_REPAIR_OPTIONS",
          "TCP_TIMESTAMP",
          "TCP_CC_INFO",
          "TCP_SAVE_SYN",
          "TCP_SAVED_SYN",
          "TCP_REPAIR_WINDOW",
          "TCP_FASTOPEN_CONNECT",
          "TCP_ULP",
          "TCP_MD5SIG_EXT",
          "TCP_FASTOPEN_KEY",
          "TCP_FASTOPEN_NO_COOKIE",
          "TCP_ZEROCOPY_RECEIVE",
          "TCP_INQ",
          "TCP_TX_DELAY",
          "IP_PKTINFO",
          "IP_UNBLOCK_SOURCE",
          "IP_BLOCK_SOURCE",
          "IP_ADD_SOURCE_MEMBERSHIP",
          "IP_DROP_SOURCE_MEMBERSHIP",
          "SO_BINDTOIFINDEX",
          "SO_BINDTODEVICE",
          "CAN_RAW_ERR_FILTER",
          "CAN_BCM_CAN_FD_FRAME",
          "ETH_P_ALL",
          "socket",
          "AF_PACKET",
          "ioctl()",
          "SIO_LOOPBACK_FAST_PATH",
          "BDADDR_ANY",
          "BTPROTO_RFCOMM",
          "BTPROTO_HCI",
          "HCI_FILTER",
          "HCI_TIME_STAMP",
          "HCI_DATA_DIR",
          "SO_REUSEPORT",
          "shutdown()",
          "AF_INET",
          "AF_INET6",
          "AF_UNIX",
          "AF_CAN",
          "AF_PACKET",
          "AF_RDS",
          "SOCK_STREAM",
          "SOCK_DGRAM",
          "SOCK_RAW",
          "SOCK_",
          "AF_CAN",
          "CAN_RAW",
          "CAN_BCM",
          "CAN_ISOTP",
          "CAN_J1939",
          "socket.getpeername()",
          "socket.fromfd()",
          "socket.close()",
          "socket.__new__",
          "self",
          "family",
          "type",
          "protocol",
          "SOCK_NONBLOCK",
          "SOCK_CLOEXEC",
          "socket.type",
          "socket()",
          "sock=socket.socket(socket.AF_INET,socket.SOCK_STREAM|socket.SOCK_NONBLOCK)",
          "SOCK_NONBLOCK",
          "sock.type",
          "socket.SOCK_STREAM",
          "socket()",
          "AF_UNIX",
          "AF_INET",
          "(host,port)",
          "socket.connect()",
          "AF_INET",
          "AF_INET6",
          "getdefaulttimeout()",
          "(host,port)",
          "True",
          "ExceptionGroup",
          "(host,port)",
          "AF_INET",
          "AF_INET6",
          "socket.listen()",
          "SO_REUSEPORT",
          "AF_INET6",
          "ValueError",
          "socket.getpeername()",
          "has_dualstack_ipv6()",
          "importsocketaddr=(\"\",8080)# all interfaces, port 8080ifsocket.has_dualstack_ipv6():s=socket.create_server(addr,family=socket.AF_INET6,dualstack_ipv6=True)else:s=socket.create_server(addr)",
          "SO_REUSEADDR",
          "True",
          "fileno()",
          "socket()",
          "socket.share()",
          "type(socket(...))",
          "socket",
          "os.close()",
          "os.close()",
          "getaddrinfo",
          "None",
          "'http'",
          "None",
          "None",
          "NULL",
          "AF_UNSPEC",
          "AI_*",
          "AI_NUMERICHOST",
          "(family,type,proto,canonname,sockaddr)",
          "socket()",
          "AI_CANONNAME",
          "(address,port)",
          "AF_INET",
          "(address,port,flowinfo,scope_id)",
          "AF_INET6",
          "socket.connect()",
          "getaddrinfo()",
          "SOCK_STREAM",
          "SOCK_DGRAM",
          "IPPROTO_TCP",
          "IPPROTO_UDP",
          "socket.getaddrinfo",
          "host",
          "port",
          "family",
          "type",
          "protocol",
          "example.org",
          ">>>socket.getaddrinfo(\"example.org\",80,proto=socket.IPPROTO_TCP)[(socket.AF_INET6, socket.SOCK_STREAM,6, '', ('2606:2800:220:1:248:1893:25c8:1946', 80, 0, 0)),(socket.AF_INET, socket.SOCK_STREAM,6, '', ('93.184.216.34', 80))]",
          "%scope_id",
          "gethostbyaddr()",
          "'0.0.0.0'",
          "gethostname()",
          "'100.50.200.5'",
          "gethostbyname_ex()",
          "gethostbyname()",
          "getaddrinfo()",
          "socket.gethostbyname",
          "hostname",
          "(hostname,aliaslist,ipaddrlist)",
          "gethostbyname_ex()",
          "getaddrinfo()",
          "socket.gethostbyname",
          "hostname",
          "socket.gethostname",
          "gethostname()",
          "getfqdn()",
          "(hostname,aliaslist,ipaddrlist)",
          "getfqdn()",
          "gethostbyaddr()",
          "socket.gethostbyaddr",
          "ip_address",
          "(host,port)",
          "%scope_id",
          "socket.getnameinfo",
          "sockaddr",
          "'icmp'",
          "socket()",
          "SOCK_RAW",
          "'tcp'",
          "'udp'",
          "socket.getservbyname",
          "servicename",
          "protocolname",
          "'tcp'",
          "'udp'",
          "socket.getservbyport",
          "port",
          "protocolname",
          "OverflowError",
          "OverflowError",
          "in_addr",
          "inet_aton()",
          "OSError",
          "inet_aton()",
          "inet_aton()",
          "inet_pton()",
          "in_addr",
          "OSError",
          "inet_ntoa()",
          "inet_ntop()",
          "inet_pton()",
          "in_addr",
          "inet_aton()",
          "in6_addr",
          "AF_INET",
          "AF_INET6",
          "OSError",
          "inet_pton()",
          "'7.10.0.5'",
          "'5aef:2b::8'",
          "inet_ntop()",
          "in_addr",
          "inet_ntoa()",
          "in6_addr",
          "AF_INET",
          "AF_INET6",
          "ValueError",
          "OSError",
          "inet_ntop()",
          "recvmsg()",
          "CMSG_SPACE()",
          "OverflowError",
          "recvmsg()",
          "CMSG_SPACE()",
          "OverflowError",
          "None",
          "None",
          "None",
          "settimeout()",
          "OSError",
          "socket.sethostname",
          "name",
          "OSError",
          "{FB605B73-AAC2-49A6-9A2F-25416AEA0573}",
          "ethernet_32770",
          "vEthernet(nat)",
          "Hyper-VVirtualEthernetAdapter",
          "ethernet_32770",
          "OSError",
          "if_nameindex()",
          "OSError",
          "if_nameindex()",
          "AF_UNIX",
          "sendmsg()",
          "sendmsg()",
          "SCM_RIGHTS",
          "AF_UNIX",
          "(msg,list(fds),flags,addr)",
          "recvmsg()",
          "recvmsg()",
          "SCM_RIGHTS",
          "makefile()",
          "close()",
          "(conn,address)",
          "InterruptedError",
          "socket.bind",
          "self",
          "address",
          "makefile()",
          "close()",
          "with",
          "OSError",
          "close()",
          "close()",
          "shutdown()",
          "close()",
          "TimeoutError",
          "InterruptedError",
          "socket.connect",
          "self",
          "address",
          "InterruptedError",
          "connect(address)",
          "connect()",
          "0",
          "errno",
          "socket.connect",
          "self",
          "address",
          "select.select()",
          "os.fdopen()",
          "True",
          "False",
          "struct",
          "True",
          "False",
          "socket.gettimeout()!=0",
          "None",
          "setblocking()",
          "settimeout()",
          "ioctl()",
          "fcntl.fcntl()",
          "fcntl.ioctl()",
          "SIO_RCVALL",
          "SIO_KEEPALIVE_VALS",
          "SIO_LOOPBACK_FAST_PATH",
          "SIO_LOOPBACK_FAST_PATH",
          "makefile()",
          "open()",
          "'r'",
          "'w'",
          "'b'",
          "makefile()",
          "socket.close()",
          "makefile()",
          "subprocess.Popen()",
          "InterruptedError",
          "(bytes,address)",
          "InterruptedError",
          "%scope_id",
          "getnameinfo()",
          "CMSG_SPACE()",
          "CMSG_LEN()",
          "recv()",
          "(data,ancdata,msg_flags,address)",
          "bytes",
          "(cmsg_level,cmsg_type,cmsg_data)",
          "bytes",
          "sendmsg()",
          "recvmsg()",
          "AF_UNIX",
          "SOCK_STREAM",
          "recvmsg()",
          "(socket.SOL_SOCKET,socket.SCM_RIGHTS,fds)",
          "bytes",
          "recvmsg()",
          "recvmsg()",
          "RuntimeWarning",
          "SCM_RIGHTS",
          "sendmsg()",
          "importsocket,arraydefrecv_fds(sock,msglen,maxfds):fds=array.array(\"i\")# Array of intsmsg,ancdata,flags,addr=sock.recvmsg(msglen,socket.CMSG_LEN(maxfds*fds.itemsize))forcmsg_level,cmsg_type,cmsg_datainancdata:ifcmsg_level==socket.SOL_SOCKETandcmsg_type==socket.SCM_RIGHTS:# Append data, ignoring any truncated integers at the end.fds.frombytes(cmsg_data[:len(cmsg_data)-(len(cmsg_data)%fds.itemsize)])returnmsg,list(fds)",
          "InterruptedError",
          "recvmsg()",
          "bytearray",
          "sysconf()",
          "SC_IOV_MAX",
          "recvmsg()",
          "(nbytes,ancdata,msg_flags,address)",
          "recvmsg()",
          ">>>importsocket>>>s1,s2=socket.socketpair()>>>b1=bytearray(b'----')>>>b2=bytearray(b'0123456789')>>>b3=bytearray(b'--------------')>>>s1.send(b'Mary had a little lamb')22>>>s2.recvmsg_into([b1,memoryview(b2)[2:9],b3])(22, [], 0, None)>>>[b1,b2,b3][bytearray(b'Mary'), bytearray(b'01 had a 9'), bytearray(b'little lamb---')]",
          "(nbytes,address)",
          "recv()",
          "InterruptedError",
          "recv()",
          "send()",
          "None",
          "InterruptedError",
          "recv()",
          "socket.sendto",
          "self",
          "address",
          "InterruptedError",
          "bytes",
          "sysconf()",
          "SC_IOV_MAX",
          "(cmsg_level,cmsg_type,cmsg_data)",
          "CMSG_SPACE()",
          "send()",
          "None",
          "AF_UNIX",
          "SCM_RIGHTS",
          "recvmsg()",
          "importsocket,arraydefsend_fds(sock,msg,fds):returnsock.sendmsg([msg],[(socket.SOL_SOCKET,socket.SCM_RIGHTS,array.array(\"i\",fds))])",
          "socket.sendmsg",
          "self",
          "address",
          "InterruptedError",
          "sendmsg()",
          "AF_ALG",
          "AF_ALG",
          "os.sendfile",
          "os.sendfile",
          "send()",
          "file.tell()",
          "SOCK_STREAM",
          "settimeout()",
          "sock.setblocking(True)",
          "sock.settimeout(None)",
          "sock.setblocking(False)",
          "sock.settimeout(0.0)",
          "SOCK_NONBLOCK",
          "socket.type",
          "None",
          "timeout",
          "None",
          "SOCK_NONBLOCK",
          "socket.type",
          "None",
          "struct",
          "None",
          "setsockopt()",
          "optval=NULL",
          "optlen=optlen",
          "SHUT_RD",
          "SHUT_WR",
          "SHUT_RDWR",
          "fromshare()",
          "read()",
          "write()",
          "recv()",
          "send()",
          "socket",
          "setdefaulttimeout()",
          "select",
          "timeout",
          "fileno()",
          "connect",
          "connect()",
          "settimeout()",
          "connect()",
          "create_connection()",
          "accept",
          "getdefaulttimeout()",
          "None",
          "accept()",
          "accept()",
          "accept()",
          "socket()",
          "bind()",
          "listen()",
          "accept()",
          "accept()",
          "socket()",
          "connect()",
          "sendall()",
          "recv()",
          "accept()",
          "# Echo server programimportsocketHOST=''# Symbolic name meaning all available interfacesPORT=50007# Arbitrary non-privileged portwithsocket.socket(socket.AF_INET,socket.SOCK_STREAM)ass:s.bind((HOST,PORT))s.listen(1)conn,addr=s.accept()withconn:print('Connected by',addr)whileTrue:data=conn.recv(1024)ifnotdata:breakconn.sendall(data)",
          "# Echo client programimportsocketHOST='daring.cwi.nl'# The remote hostPORT=50007# The same port as used by the serverwithsocket.socket(socket.AF_INET,socket.SOCK_STREAM)ass:s.connect((HOST,PORT))s.sendall(b'Hello, world')data=s.recv(1024)print('Received',repr(data))",
          "# Echo server programimportsocketimportsysHOST=None# Symbolic name meaning all available interfacesPORT=50007# Arbitrary non-privileged ports=Noneforresinsocket.getaddrinfo(HOST,PORT,socket.AF_UNSPEC,socket.SOCK_STREAM,0,socket.AI_PASSIVE):af,socktype,proto,canonname,sa=restry:s=socket.socket(af,socktype,proto)exceptOSErrorasmsg:s=Nonecontinuetry:s.bind(sa)s.listen(1)exceptOSErrorasmsg:s.close()s=NonecontinuebreakifsisNone:print('could not open socket')sys.exit(1)conn,addr=s.accept()withconn:print('Connected by',addr)whileTrue:data=conn.recv(1024)ifnotdata:breakconn.send(data)",
          "# Echo client programimportsocketimportsysHOST='daring.cwi.nl'# The remote hostPORT=50007# The same port as used by the servers=Noneforresinsocket.getaddrinfo(HOST,PORT,socket.AF_UNSPEC,socket.SOCK_STREAM):af,socktype,proto,canonname,sa=restry:s=socket.socket(af,socktype,proto)exceptOSErrorasmsg:s=Nonecontinuetry:s.connect(sa)exceptOSErrorasmsg:s.close()s=NonecontinuebreakifsisNone:print('could not open socket')sys.exit(1)withs:s.sendall(b'Hello, world')data=s.recv(1024)print('Received',repr(data))",
          "importsocket# the public network interfaceHOST=socket.gethostbyname(socket.gethostname())# create a raw socket and bind it to the public interfaces=socket.socket(socket.AF_INET,socket.SOCK_RAW,socket.IPPROTO_IP)s.bind((HOST,0))# Include IP headerss.setsockopt(socket.IPPROTO_IP,socket.IP_HDRINCL,1)# receive all packetss.ioctl(socket.SIO_RCVALL,socket.RCVALL_ON)# receive a packetprint(s.recvfrom(65565))# disabled promiscuous modes.ioctl(socket.SIO_RCVALL,socket.RCVALL_OFF)",
          "socket.socket(socket.AF_CAN,socket.SOCK_DGRAM,socket.CAN_BCM)",
          "CAN_RAW",
          "CAN_BCM",
          "socket.send()",
          "socket.recv()",
          "importsocketimportstruct# CAN frame packing/unpacking (see 'struct can_frame' in <linux/can.h>)can_frame_fmt=\"=IB3x8s\"can_frame_size=struct.calcsize(can_frame_fmt)defbuild_can_frame(can_id,data):can_dlc=len(data)data=data.ljust(8,b'\\x00')returnstruct.pack(can_frame_fmt,can_id,can_dlc,data)defdissect_can_frame(frame):can_id,can_dlc,data=struct.unpack(can_frame_fmt,frame)return(can_id,can_dlc,data[:can_dlc])# create a raw socket and bind it to the 'vcan0' interfaces=socket.socket(socket.AF_CAN,socket.SOCK_RAW,socket.CAN_RAW)s.bind(('vcan0',))whileTrue:cf,addr=s.recvfrom(can_frame_size)print('Received: can_id=%x, can_dlc=%x, data=%s'%dissect_can_frame(cf))try:s.send(cf)exceptOSError:print('Error sending CAN frame')try:s.send(build_can_frame(0x01,b'\\x01\\x02\\x03'))exceptOSError:print('Error sending CAN frame')",
          "OSError:[Errno98]Addressalreadyinuse",
          "TIME_WAIT",
          "socket",
          "socket.SO_REUSEADDR",
          "s=socket.socket(socket.AF_INET,socket.SOCK_STREAM)s.setsockopt(socket.SOL_SOCKET,socket.SO_REUSEADDR,1)s.bind((HOST,PORT))",
          "SO_REUSEADDR",
          "TIME_WAIT",
          "socket",
          "connect",
          "accept",
          "ssl",
          "socket"
        ]
      },
      "title": "socket \u00e2\u0080\u0094 Low-level networking interface \u2014 Python 3.13.7 documentation",
      "scraped_at": 1756988961.174517
    },
    {
      "url": "https://requests.readthedocs.io/en/latest/",
      "status": 200,
      "content": {
        "content": [
          "Requests: HTTP for Humans\u2122\u00b6Release v2.32.5. (Installation)Requestsis an elegant and simple HTTP library for Python, built for human beings.Behold, the power of Requests:>>>r=requests.get('https://api.github.com/user',auth=('user','pass'))>>>r.status_code200>>>r.headers['content-type']'application/json; charset=utf8'>>>r.encoding'utf-8'>>>r.text'{\"type\":\"User\"...'>>>r.json(){'private_gists': 419, 'total_private_repos': 77, ...}Seesimilar code, sans Requests.Requestsallows you to send HTTP/1.1 requests extremely easily.\nThere\u2019s no need to manually add query strings to your\nURLs, or to form-encode your POST data. Keep-alive and HTTP connection pooling\nare 100% automatic, thanks tourllib3.Beloved Features\u00b6Requests is ready for today\u2019s web.Keep-Alive & Connection PoolingInternational Domains and URLsSessions with Cookie PersistenceBrowser-style SSL VerificationAutomatic Content DecodingBasic/Digest AuthenticationElegant Key/Value CookiesAutomatic DecompressionUnicode Response BodiesHTTP(S) Proxy SupportMultipart File UploadsStreaming DownloadsConnection TimeoutsChunked Requests.netrcSupportRequests officially supports Python 3.9+, and runs great on PyPy.The User Guide\u00b6This part of the documentation, which is mostly prose, begins with some\nbackground information about Requests, then focuses on step-by-step\ninstructions for getting the most out of Requests.Installation of Requests$ python -m pip install requestsGet the Source CodeQuickstartMake a RequestPassing Parameters In URLsResponse ContentBinary Response ContentJSON Response ContentRaw Response ContentCustom HeadersMore complicated POST requestsPOST a Multipart-Encoded FileResponse Status CodesResponse HeadersCookiesRedirection and HistoryTimeoutsErrors and ExceptionsAdvanced UsageSession ObjectsRequest and Response ObjectsPrepared RequestsSSL Cert VerificationClient Side CertificatesCA CertificatesBody Content WorkflowKeep-AliveStreaming UploadsChunk-Encoded RequestsPOST Multiple Multipart-Encoded FilesEvent HooksCustom AuthenticationStreaming RequestsProxiesComplianceHTTP VerbsCustom VerbsLink HeadersTransport AdaptersBlocking Or Non-Blocking?Header OrderingTimeoutsAuthenticationBasic AuthenticationDigest AuthenticationOAuth 1 AuthenticationOAuth 2 and OpenID Connect AuthenticationOther AuthenticationNew Forms of AuthenticationThe Community Guide\u00b6This part of the documentation, which is mostly prose, details the\nRequests ecosystem and community.Recommended Packages and ExtensionsCertifi CA BundleCacheControlRequests-ToolbeltRequests-ThreadsRequests-OAuthlibBetamaxFrequently Asked QuestionsEncoded Data?Custom User-Agents?Why not Httplib2?Python 3 Support?Python 2 Support?What are \u201chostname doesn\u2019t match\u201d errors?IntegrationsArticles & TalksSupportStack OverflowFile an IssueSend a TweetVulnerability DisclosureRelease Process and RulesMajor ReleasesMinor ReleasesHotfix ReleasesReasoningCommunity UpdatesRelease HistoryThe API Documentation / Guide\u00b6If you are looking for information on a specific function, class, or method,\nthis part of the documentation is for you.Developer InterfaceMain InterfaceExceptionsRequest SessionsLower-Level ClassesLower-Lower-Level ClassesAuthenticationEncodingsCookiesStatus Code LookupMigrating to 1.xMigrating to 2.xThe Contributor Guide\u00b6If you want to contribute to the project, this part of the documentation is for\nyou.Contributor\u2019s GuideCode of ConductGet Early FeedbackContribution SuitabilityCode ContributionsSteps for Submitting CodeCode ReviewCode StyleNew ContributorsDocumentation ContributionsBug ReportsFeature RequestsAuthorsKeepers of the CrystalsPrevious Keepers of CrystalsPatches and SuggestionsThere are no more guides. You are now guideless.\nGood luck.Requests is an elegant and simple HTTP library for Python, built for\n  human beings.Useful LinksQuickstartAdvanced UsageAPI ReferenceRelease HistoryContributors GuideRecommended Packages and ExtensionsRequests @ GitHubRequests @ PyPIIssue TrackerQuick search"
        ],
        "code_blocks": []
      },
      "title": "Requests: HTTP for Humans\u2122 \u2014 Requests 2.32.5 documentation",
      "scraped_at": 1756988964.5331566
    },
    {
      "url": "https://aiohttp.readthedocs.io/en/stable/",
      "status": 200,
      "content": {
        "content": [
          "Welcome to AIOHTTP\u00b6Asynchronous HTTP Client/Server forasyncioand Python.Current version is 3.12.15.Key Features\u00b6Supports bothClientandHTTP Server.Supports bothServer WebSocketsandClient WebSocketsout-of-the-box\nwithout the Callback Hell.Web-server hasMiddlewares,Signalsand pluggable routing.Client supportsmiddlewarefor\ncustomizing request/response processing.Library Installation\u00b6$pipinstallaiohttpFor speeding up DNS resolving by client API you may installaiodnsas well.\nThis option is highly recommended:$pipinstallaiodnsInstalling all speedups in one command\u00b6The following will get youaiohttpalong withaiodnsandBrotliin one\nbundle.\nNo need to type separate commands anymore!$pipinstallaiohttp[speedups]Getting Started\u00b6Client example\u00b6importaiohttpimportasyncioasyncdefmain():asyncwithaiohttp.ClientSession()assession:asyncwithsession.get('http://python.org')asresponse:print(\"Status:\",response.status)print(\"Content-type:\",response.headers['content-type'])html=awaitresponse.text()print(\"Body:\",html[:15],\"...\")asyncio.run(main())This prints:Status: 200\nContent-type: text/html; charset=utf-8\nBody: <!doctype html> ...Coming fromrequests? Readwhy we need so many lines.Server example:\u00b6fromaiohttpimportwebasyncdefhandle(request):name=request.match_info.get('name',\"Anonymous\")text=\"Hello, \"+namereturnweb.Response(text=text)app=web.Application()app.add_routes([web.get('/',handle),web.get('/{name}',handle)])if__name__=='__main__':web.run_app(app)For more information please visitClientandServerpages.Development mode\u00b6When writing your code, we recommend enabling Python\u2019sdevelopment mode(python-Xdev). In addition to the extra features enabled for asyncio, aiohttp\nwill:Use a strict parser in the client code (which can help detect malformed responses\nfrom a server).Enable some additional checks (resulting in warnings in certain situations).What\u2019s new in aiohttp 3?\u00b6Go toWhat\u2019s new in aiohttp 3.0page for aiohttp 3.0 major release\nchanges.Tutorial\u00b6Polls tutorialSource code\u00b6The project is hosted onGitHubPlease feel free to file an issue on thebug trackerif you have found a bug\nor have some suggestion in order to improve the library.Dependencies\u00b6attrsmultidictyarlOptionalaiodnsfor fast DNS resolving. The\nlibrary is highly recommended.$pipinstallaiodnsOptionalBrotliorbrotlicffifor brotli (RFC 7932)\nclient compression support.$pipinstallBrotliCommunication channels\u00b6aio-libs Discussions:https://github.com/aio-libs/aiohttp/discussionsFeel free to post your questions and ideas here.Matrix:#aio-libs:matrix.orgWe supportStack Overflow.\nPlease addaiohttptag to your question there.Contributing\u00b6Please read theinstructions for contributorsbefore making a Pull Request.Authors and License\u00b6Theaiohttppackage is written mostly by Nikolay Kim and Andrew Svetlov.It\u2019sApache 2licensed and freely available.Feel free to improve this package and send a pull request toGitHub.Policy for Backward Incompatible Changes\u00b6aiohttpkeeps backward compatibility.After deprecating somePublic API(method, class, function argument,\netc.) the library guaranties the usage ofdeprecated APIis still\nallowed at least for a year and half after publishing new release with\ndeprecation.All deprecations are reflected in documentation and raisesDeprecationWarning.Sometimes we are forced to break the own rule for sake of very strong\nreason.  Most likely the reason is a critical bug which cannot be\nsolved without major API change, but we are working hard for keeping\nthese changes as rare as possible.Table Of Contents\u00b6ClientQuickstartAdvanced UsageClient Middleware CookbookReferenceTracing ReferenceThe aiohttp Request LifecycleServerTutorialQuickstartAdvanced UsageLow LevelReferenceLoggingTestingDeploymentUtilitiesAbstract Base ClassesWorking with MultipartMultipart referenceStreaming APICommon data structuresWebSocket utilitiesFAQAre there plans for an @app.route decorator like in Flask?Does aiohttp have a concept like Flask\u2019s \u201cblueprint\u201d or Django\u2019s \u201capp\u201d?How do I create a route that matches urls with a given prefix?Where do I put my database connection so handlers can access it?How can middleware store data for web handlers to use?Can a handler receive incoming events from different sources in parallel?How do I programmatically close a WebSocket server-side?How do I make a request from a specific IP address?What is the API stability and deprecation policy?How do I enable gzip compression globally for my entire application?How do I manage a ClientSession within a web server?How do I access database connections from a subapplication?How do I perform operations in a request handler after sending the response?How do I make sure my custom middleware response will behave correctly?Why is creating a ClientSession outside of an event loop dangerous?MiscellaneousEssaysGlossaryChangelogIndices and tablesWho uses aiohttp?Third-Party librariesBuilt with aiohttpPowered by aiohttpContributingInstructions for contributorsPreconditions for running aiohttp test suiteLLHTTPRun autoformatterRun aiohttp test suiteCode coverageOther toolsDocumentationSpell checkingPreparing a pull requestChangelog updateMaking a pull requestBackportingHow to become an aiohttp committer"
        ],
        "code_blocks": []
      },
      "title": "Welcome to AIOHTTP \u2014 aiohttp 3.12.15 documentation",
      "scraped_at": 1756988968.3360384
    }
  ],
  "tutorials": [
    {
      "url": "https://realpython.com/python-sockets/",
      "status": 200,
      "content": {
        "content": [],
        "code": []
      },
      "title": "Socket Programming in Python (Guide) \u2013 Real Python",
      "scraped_at": 1756988973.1191614,
      "code_examples": []
    },
    {
      "url": "https://realpython.com/api-integration-in-python/",
      "status": 200,
      "content": {
        "content": [],
        "code": []
      },
      "title": "Python and REST APIs: Interacting With Web Services \u2013 Real Python",
      "scraped_at": 1756988978.3569913,
      "code_examples": []
    }
  ]
}